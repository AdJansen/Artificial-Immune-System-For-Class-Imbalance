{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, cross_val_score, GridSearchCV, cross_validate\n",
    "\n",
    "# importing two different imputation methods that take into consideration all the features when predicting the missing values\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#multiclass imports\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.dummy import DummyClassifier #Will identify the maority calss base line, model needs to do better then the baseline\n",
    "\n",
    "from statistics import mean\n",
    "# to reduce randomness then you put the seed\n",
    "np.random.seed(42)\n",
    "\n",
    "from ArtificialImmuneSystem import *\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from tabulate import tabulate\n",
    "import time\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'Data\\hcv_data_split.csv'\n",
    "df = pd.read_csv(dataset)\n",
    "\n",
    "#df = df.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: \n",
      "(615, 14)\n",
      "\n",
      "Data size: \n",
      "8610\n",
      "\n",
      "Data ndim: \n",
      "2\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Old Class Distribution: Counter({0: 540, 1: 75})\n"
     ]
    }
   ],
   "source": [
    "print(f\"Data shape: \\n{df.shape}\\n\")\n",
    "print(f\"Data size: \\n{df.size}\\n\")\n",
    "print(f\"Data ndim: \\n{df.ndim}\\n\")\n",
    "print(\"_____________________________________________\\n\")\n",
    "print(f\"Old Class Distribution: {Counter(df['category'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features =df.copy()\n",
    "features = features.drop(['category'],axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score1: 0.8171434427460996\n",
      "score2: 0.7821741865885674\n",
      "score1: 0.8171434427460996\n",
      "score2: 0.8029844671906368\n",
      "score1: 0.8171434427460996\n",
      "score2: 0.6457842865420509\n",
      "score1: 0.8171434427460996\n",
      "score2: 0.8388682586216429\n",
      "score1: 0.8388682586216429\n",
      "score2: 0.5386372077675754\n",
      "score1: 0.8388682586216429\n",
      "score2: 0.7342368440770336\n",
      "score1: 0.8388682586216429\n",
      "score2: 0.7412184533511932\n",
      "score1: 0.8388682586216429\n",
      "score2: 0.7257088382745044\n",
      "score1: 0.8388682586216429\n",
      "score2: 0.7054455487844692\n",
      "score1: 0.8388682586216429\n",
      "score2: 0.6442899408284024\n",
      "score1: 0.8388682586216429\n",
      "score2: 0.8443557526484357\n",
      "score1: 0.8443557526484357\n",
      "score2: 0.5518890129481739\n",
      "score1: 0.8443557526484357\n",
      "score2: 0.5145109756764834\n",
      "score1: 0.8443557526484357\n",
      "score2: 0.5452372469872471\n",
      "score1: 0.8443557526484357\n",
      "score2: 0.5784316775890394\n",
      "score1: 0.8443557526484357\n",
      "score2: 0.3974975463666108\n",
      "score1: 0.8443557526484357\n",
      "score2: 0.5444932136876217\n",
      "score1: 0.8443557526484357\n",
      "score2: 0.5358322745159125\n",
      "score1: 0.8443557526484357\n",
      "score2: 0.6117783766219872\n",
      "score1: 0.8443557526484357\n",
      "score2: 0.6135800455448024\n",
      "score1: 0.8443557526484357\n",
      "score2: 0.5560410298098228\n",
      "score1: 0.8443557526484357\n",
      "score2: 0.6469151593747867\n",
      "score1: 0.8443557526484357\n",
      "score2: 0.4658761767755383\n",
      "score1: 0.8443557526484357\n",
      "score2: 0.5828989519252677\n",
      "score1: 0.8443557526484357\n",
      "score2: 0.6956291463122584\n",
      "score1: 0.8443557526484357\n",
      "score2: 0.5477306842472005\n",
      "score1: 0.8443557526484357\n",
      "score2: 0.5581623167156132\n",
      "score1: 0.8443557526484357\n",
      "score2: 0.523971561442779\n",
      "score1: 0.8443557526484357\n",
      "score2: 0.5267832929797194\n",
      "score1: 0.8443557526484357\n",
      "score2: 0.46432642848462236\n",
      "score1: 0.8443557526484357\n",
      "score2: 0.6553644771415982\n",
      "score1: 0.8443557526484357\n",
      "score2: 0.618004317617794\n",
      "score1: 0.8443557526484357\n",
      "score2: 0.5550660613878085\n",
      "score1: 0.8443557526484357\n",
      "score2: 0.6676987486594177\n",
      "score1: 0.8443557526484357\n",
      "score2: 0.6055649711407256\n",
      "score1: 0.8443557526484357\n",
      "score2: 0.6239428926935398\n",
      "score1: 0.8443557526484357\n",
      "score2: 0.5455207533849998\n",
      "score1: 0.8443557526484357\n",
      "score2: 0.5653510842516267\n",
      "score1: 0.8443557526484357\n",
      "score2: 0.5077790658114336\n",
      "score1: 0.8443557526484357\n",
      "score2: 0.6453920460839704\n",
      "score1: 0.8443557526484357\n",
      "score2: 0.5565980709910805\n",
      "score1: 0.8443557526484357\n",
      "score2: 0.479623023679285\n",
      "score1: 0.8443557526484357\n",
      "score2: 0.49439024527811715\n",
      "score1: 0.8443557526484357\n",
      "score2: 0.56508816266711\n",
      "score1: 0.8443557526484357\n",
      "score2: 0.6318094332788451\n",
      "score1: 0.8443557526484357\n",
      "score2: 0.5601198179363338\n",
      "score1: 0.8443557526484357\n",
      "score2: 0.6163239692023824\n",
      "score1: 0.8443557526484357\n",
      "score2: 0.6695926702204325\n",
      "score1: 0.8443557526484357\n",
      "score2: 0.6832509260434131\n",
      "score1: 0.8443557526484357\n",
      "score2: 0.5716832917900826\n",
      "score1: 0.8443557526484357\n",
      "score2: 0.6865115628431979\n",
      "score1: 0.8443557526484357\n",
      "score2: 0.4946769410636084\n",
      "score1: 0.8443557526484357\n",
      "score2: 0.5212522522522522\n",
      "score1: 0.8443557526484357\n",
      "score2: 0.4940704188720145\n",
      "score1: 0.8443557526484357\n",
      "score2: 0.583581306384154\n",
      "score1: 0.8443557526484357\n",
      "score2: 0.6730803943818467\n",
      "score1: 0.8443557526484357\n",
      "score2: 0.5547684963128632\n",
      "score1: 0.8443557526484357\n",
      "score2: 0.6947728164146298\n",
      "score1: 0.8443557526484357\n",
      "score2: 0.6877683036470302\n",
      "score1: 0.8443557526484357\n",
      "score2: 0.7863269478949508\n",
      "score1: 0.8443557526484357\n",
      "score2: 0.5420329731002601\n",
      "Best score GradientBoosting: \n",
      "0.9849749405368672\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score GradientBoosting AIS: \n",
      "0.9375\n",
      "\n",
      "Best score KNeighbors: \n",
      "0.9942235813795446\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score KNeighbors AIS: \n",
      "0.9293981481481481\n",
      "\n",
      "Best score Logistic Regression: \n",
      "0.9445506286102616\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score Logistic Regression AIS: \n",
      "0.9040626061841659\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score RandomForest: \n",
      "0.9849749405368672\n",
      "\n",
      "Best score RandomForest AIS: \n",
      "0.9513888888888888\n",
      "\n",
      "score1: 0.7657491388260309\n",
      "score2: 0.7925368211593614\n",
      "score1: 0.7925368211593614\n",
      "score2: 0.7822373169978224\n",
      "score1: 0.7925368211593614\n",
      "score2: 0.7960681204997335\n",
      "score1: 0.7925368211593614\n",
      "score2: 0.7572436737065061\n",
      "score1: 0.7925368211593614\n",
      "score2: 0.7717783501753741\n",
      "score1: 0.7925368211593614\n",
      "score2: 0.8106835523729545\n",
      "score1: 0.8106835523729545\n",
      "score2: 0.6421337420107454\n",
      "score1: 0.8106835523729545\n",
      "score2: 0.6528654470258853\n",
      "score1: 0.8106835523729545\n",
      "score2: 0.7240629572627982\n",
      "score1: 0.8106835523729545\n",
      "score2: 0.6974198007418956\n",
      "score1: 0.8106835523729545\n",
      "score2: 0.5101907205575085\n",
      "score1: 0.8106835523729545\n",
      "score2: 0.46304777411498205\n",
      "score1: 0.8106835523729545\n",
      "score2: 0.5428080411563054\n",
      "score1: 0.8106835523729545\n",
      "score2: 0.6153385400544964\n",
      "score1: 0.8106835523729545\n",
      "score2: 0.5592900494921723\n",
      "score1: 0.8106835523729545\n",
      "score2: 0.5131755412938974\n",
      "score1: 0.8106835523729545\n",
      "score2: 0.5145649901185201\n",
      "score1: 0.8106835523729545\n",
      "score2: 0.6342044289979878\n",
      "score1: 0.8106835523729545\n",
      "score2: 0.6038348839650458\n",
      "score1: 0.8106835523729545\n",
      "score2: 0.6322545287013968\n",
      "score1: 0.8106835523729545\n",
      "score2: 0.551613123526031\n",
      "score1: 0.8106835523729545\n",
      "score2: 0.5557087839023683\n",
      "score1: 0.8106835523729545\n",
      "score2: 0.6714922349833147\n",
      "score1: 0.8106835523729545\n",
      "score2: 0.6201402453943202\n",
      "score1: 0.8106835523729545\n",
      "score2: 0.5520618655176097\n",
      "score1: 0.8106835523729545\n",
      "score2: 0.4721968107306823\n",
      "score1: 0.8106835523729545\n",
      "score2: 0.638993616132689\n",
      "score1: 0.8106835523729545\n",
      "score2: 0.62497319538422\n",
      "score1: 0.8106835523729545\n",
      "score2: 0.6617092448269514\n",
      "score1: 0.8106835523729545\n",
      "score2: 0.624850717866196\n",
      "score1: 0.8106835523729545\n",
      "score2: 0.6463083918041875\n",
      "score1: 0.8106835523729545\n",
      "score2: 0.5537135256732415\n",
      "score1: 0.8106835523729545\n",
      "score2: 0.6213897410338488\n",
      "score1: 0.8106835523729545\n",
      "score2: 0.5976728421452562\n",
      "score1: 0.8106835523729545\n",
      "score2: 0.5938493169770975\n",
      "score1: 0.8106835523729545\n",
      "score2: 0.4811186030920376\n",
      "score1: 0.8106835523729545\n",
      "score2: 0.5699889196318145\n",
      "score1: 0.8106835523729545\n",
      "score2: 0.6208704825350662\n",
      "score1: 0.8106835523729545\n",
      "score2: 0.7096897153493529\n",
      "score1: 0.8106835523729545\n",
      "score2: 0.5145788828153008\n",
      "score1: 0.8106835523729545\n",
      "score2: 0.6536087868365209\n",
      "score1: 0.8106835523729545\n",
      "score2: 0.5902367166883296\n",
      "score1: 0.8106835523729545\n",
      "score2: 0.589600004110534\n",
      "score1: 0.8106835523729545\n",
      "score2: 0.6069156788885104\n",
      "score1: 0.8106835523729545\n",
      "score2: 0.6151058953690534\n",
      "score1: 0.8106835523729545\n",
      "score2: 0.5728796032180735\n",
      "score1: 0.8106835523729545\n",
      "score2: 0.6491758208328479\n",
      "score1: 0.8106835523729545\n",
      "score2: 0.6602168131012986\n",
      "score1: 0.8106835523729545\n",
      "score2: 0.6326462742695081\n",
      "score1: 0.8106835523729545\n",
      "score2: 0.5986975648014843\n",
      "score1: 0.8106835523729545\n",
      "score2: 0.6374790115008703\n",
      "score1: 0.8106835523729545\n",
      "score2: 0.5108274437534763\n",
      "score1: 0.8106835523729545\n",
      "score2: 0.5221845837179465\n",
      "score1: 0.8106835523729545\n",
      "score2: 0.5462817215419704\n",
      "score1: 0.8106835523729545\n",
      "score2: 0.6001846197802984\n",
      "score1: 0.8106835523729545\n",
      "score2: 0.49696537760593174\n",
      "Best score GradientBoosting: \n",
      "0.98711646975842\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score GradientBoosting AIS: \n",
      "0.9310527243872333\n",
      "\n",
      "Best score KNeighbors: \n",
      "0.9929796332216541\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score KNeighbors AIS: \n",
      "0.9158768294833362\n",
      "\n",
      "Best score Logistic Regression: \n",
      "0.9379739023099982\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score Logistic Regression AIS: \n",
      "0.9040843766531476\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score RandomForest: \n",
      "0.9906321636395697\n",
      "\n",
      "Best score RandomForest AIS: \n",
      "0.9544282313524952\n",
      "\n",
      "score1: 0.8353633340445675\n",
      "score2: 0.8719511080488271\n",
      "score1: 0.8719511080488271\n",
      "score2: 0.8089507727589013\n",
      "score1: 0.8719511080488271\n",
      "score2: 0.753019529922289\n",
      "score1: 0.8719511080488271\n",
      "score2: 0.8437965188603034\n",
      "score1: 0.8719511080488271\n",
      "score2: 0.8502221466450186\n",
      "score1: 0.8719511080488271\n",
      "score2: 0.8591332573911761\n",
      "score1: 0.8719511080488271\n",
      "score2: 0.7998239105248327\n",
      "score1: 0.8719511080488271\n",
      "score2: 0.8025816032646365\n",
      "score1: 0.8719511080488271\n",
      "score2: 0.8069416315575679\n",
      "score1: 0.8719511080488271\n",
      "score2: 0.8070005192443759\n",
      "score1: 0.8719511080488271\n",
      "score2: 0.863802976449308\n",
      "score1: 0.8719511080488271\n",
      "score2: 0.7835194041782808\n",
      "score1: 0.8719511080488271\n",
      "score2: 0.8054480664467402\n",
      "score1: 0.8719511080488271\n",
      "score2: 0.8426935175806823\n",
      "score1: 0.8719511080488271\n",
      "score2: 0.8132440036646976\n",
      "score1: 0.8719511080488271\n",
      "score2: 0.7386178909444325\n",
      "score1: 0.8719511080488271\n",
      "score2: 0.8550745500746333\n",
      "score1: 0.8719511080488271\n",
      "score2: 0.7139542966825054\n",
      "score1: 0.8719511080488271\n",
      "score2: 0.8429676082855005\n",
      "score1: 0.8719511080488271\n",
      "score2: 0.7881230308171225\n",
      "score1: 0.8719511080488271\n",
      "score2: 0.8403440996995407\n",
      "score1: 0.8719511080488271\n",
      "score2: 0.772931759328734\n",
      "score1: 0.8719511080488271\n",
      "score2: 0.8270713010166473\n",
      "score1: 0.8719511080488271\n",
      "score2: 0.8556211966330929\n",
      "score1: 0.8719511080488271\n",
      "score2: 0.7851951076202572\n",
      "score1: 0.8719511080488271\n",
      "score2: 0.7001678613463131\n",
      "score1: 0.8719511080488271\n",
      "score2: 0.7941332077797053\n",
      "score1: 0.8719511080488271\n",
      "score2: 0.8452360460167702\n",
      "score1: 0.8719511080488271\n",
      "score2: 0.8035196255921221\n",
      "score1: 0.8719511080488271\n",
      "score2: 0.8531357758585372\n",
      "score1: 0.8719511080488271\n",
      "score2: 0.8596307541046688\n",
      "score1: 0.8719511080488271\n",
      "score2: 0.7941203493229196\n",
      "score1: 0.8719511080488271\n",
      "score2: 0.8001321050518584\n",
      "score1: 0.8719511080488271\n",
      "score2: 0.8977700045611942\n",
      "score1: 0.8977700045611942\n",
      "score2: 0.5449614346493796\n",
      "score1: 0.8977700045611942\n",
      "score2: 0.6850414315762852\n",
      "score1: 0.8977700045611942\n",
      "score2: 0.6752402151656137\n",
      "score1: 0.8977700045611942\n",
      "score2: 0.7246989473550537\n",
      "score1: 0.8977700045611942\n",
      "score2: 0.7211075191675775\n",
      "score1: 0.8977700045611942\n",
      "score2: 0.6932342348324052\n",
      "score1: 0.8977700045611942\n",
      "score2: 0.49165439760720353\n",
      "score1: 0.8977700045611942\n",
      "score2: 0.6859096814982439\n",
      "score1: 0.8977700045611942\n",
      "score2: 0.6734162439361266\n",
      "score1: 0.8977700045611942\n",
      "score2: 0.7474998207724205\n",
      "score1: 0.8977700045611942\n",
      "score2: 0.698487808335544\n",
      "score1: 0.8977700045611942\n",
      "score2: 0.608552769279761\n",
      "score1: 0.8977700045611942\n",
      "score2: 0.5429770882712059\n",
      "score1: 0.8977700045611942\n",
      "score2: 0.6605487714072972\n",
      "score1: 0.8977700045611942\n",
      "score2: 0.5640069039379385\n",
      "score1: 0.8977700045611942\n",
      "score2: 0.702961841880248\n",
      "score1: 0.8977700045611942\n",
      "score2: 0.7102048680635481\n",
      "score1: 0.8977700045611942\n",
      "score2: 0.5824333863131166\n",
      "score1: 0.8977700045611942\n",
      "score2: 0.5710108610768492\n",
      "score1: 0.8977700045611942\n",
      "score2: 0.7383963739939929\n",
      "score1: 0.8977700045611942\n",
      "score2: 0.757007331728915\n",
      "score1: 0.8977700045611942\n",
      "score2: 0.6518285357100723\n",
      "score1: 0.8977700045611942\n",
      "score2: 0.4991348881116814\n",
      "score1: 0.8977700045611942\n",
      "score2: 0.7671758275217969\n",
      "score1: 0.8977700045611942\n",
      "score2: 0.6871756760786683\n",
      "score1: 0.8977700045611942\n",
      "score2: 0.7110398398057218\n",
      "score1: 0.8977700045611942\n",
      "score2: 0.6723383272822944\n",
      "score1: 0.8977700045611942\n",
      "score2: 0.5212669751231823\n",
      "score1: 0.8977700045611942\n",
      "score2: 0.5991676347018349\n",
      "score1: 0.8977700045611942\n",
      "score2: 0.5962658952925716\n",
      "score1: 0.8977700045611942\n",
      "score2: 0.6309911248853715\n",
      "score1: 0.8977700045611942\n",
      "score2: 0.5958437888553737\n",
      "score1: 0.8977700045611942\n",
      "score2: 0.7133613075878126\n",
      "score1: 0.8977700045611942\n",
      "score2: 0.5608167587639354\n",
      "score1: 0.8977700045611942\n",
      "score2: 0.6566909954108555\n",
      "score1: 0.8977700045611942\n",
      "score2: 0.715800608952278\n",
      "score1: 0.8977700045611942\n",
      "score2: 0.6769842436396913\n",
      "score1: 0.8977700045611942\n",
      "score2: 0.7415104290747275\n",
      "score1: 0.8977700045611942\n",
      "score2: 0.6356859893834683\n",
      "score1: 0.8977700045611942\n",
      "score2: 0.6303198339128434\n",
      "score1: 0.8977700045611942\n",
      "score2: 0.5790992786516845\n",
      "score1: 0.8977700045611942\n",
      "score2: 0.6322522490972444\n",
      "score1: 0.8977700045611942\n",
      "score2: 0.5214124288562371\n",
      "score1: 0.8977700045611942\n",
      "score2: 0.6985226935020353\n",
      "score1: 0.8977700045611942\n",
      "score2: 0.6511927935755836\n",
      "score1: 0.8977700045611942\n",
      "score2: 0.6612444440606595\n",
      "score1: 0.8977700045611942\n",
      "score2: 0.4750560492144663\n",
      "score1: 0.8977700045611942\n",
      "score2: 0.7028435775543842\n",
      "score1: 0.8977700045611942\n",
      "score2: 0.6240345154539095\n",
      "score1: 0.8977700045611942\n",
      "score2: 0.7279932353553024\n",
      "Best score GradientBoosting: \n",
      "0.9884577811756712\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score GradientBoosting AIS: \n",
      "0.9490953109072375\n",
      "\n",
      "Best score KNeighbors: \n",
      "0.995380988786952\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score KNeighbors AIS: \n",
      "0.9294618586476384\n",
      "\n",
      "Best score Logistic Regression: \n",
      "0.9342720013591573\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score Logistic Regression AIS: \n",
      "0.923919045191981\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score RandomForest: \n",
      "0.9896045701664968\n",
      "\n",
      "Best score RandomForest AIS: \n",
      "0.9583651885830785\n",
      "\n",
      "score1: 0.8181298834830925\n",
      "score2: 0.8605433739387227\n",
      "score1: 0.8605433739387227\n",
      "score2: 0.9112679915268724\n",
      "score1: 0.9112679915268724\n",
      "score2: 0.6694557453455433\n",
      "score1: 0.9112679915268724\n",
      "score2: 0.6798299574548174\n",
      "score1: 0.9112679915268724\n",
      "score2: 0.700736727158608\n",
      "score1: 0.9112679915268724\n",
      "score2: 0.5949611758681967\n",
      "score1: 0.9112679915268724\n",
      "score2: 0.6080890603999751\n",
      "score1: 0.9112679915268724\n",
      "score2: 0.3910445361595605\n",
      "score1: 0.9112679915268724\n",
      "score2: 0.7173772893772894\n",
      "score1: 0.9112679915268724\n",
      "score2: 0.6140613960706549\n",
      "score1: 0.9112679915268724\n",
      "score2: 0.6167814052048919\n",
      "score1: 0.9112679915268724\n",
      "score2: 0.5053741701808928\n",
      "score1: 0.9112679915268724\n",
      "score2: 0.5363120700300862\n",
      "score1: 0.9112679915268724\n",
      "score2: 0.5640160743414514\n",
      "score1: 0.9112679915268724\n",
      "score2: 0.6972763992280122\n",
      "score1: 0.9112679915268724\n",
      "score2: 0.7049071260480656\n",
      "score1: 0.9112679915268724\n",
      "score2: 0.6762597090698945\n",
      "score1: 0.9112679915268724\n",
      "score2: 0.7260727652863466\n",
      "score1: 0.9112679915268724\n",
      "score2: 0.6739874532642922\n",
      "score1: 0.9112679915268724\n",
      "score2: 0.6248670193157922\n",
      "score1: 0.9112679915268724\n",
      "score2: 0.5533105972000765\n",
      "score1: 0.9112679915268724\n",
      "score2: 0.39615016351317867\n",
      "score1: 0.9112679915268724\n",
      "score2: 0.7458302565815836\n",
      "score1: 0.9112679915268724\n",
      "score2: 0.6983088444820187\n",
      "score1: 0.9112679915268724\n",
      "score2: 0.6271139291599386\n",
      "score1: 0.9112679915268724\n",
      "score2: 0.6572447205630463\n",
      "score1: 0.9112679915268724\n",
      "score2: 0.6707431062500273\n",
      "score1: 0.9112679915268724\n",
      "score2: 0.6543355995950174\n",
      "score1: 0.9112679915268724\n",
      "score2: 0.6424556369243561\n",
      "score1: 0.9112679915268724\n",
      "score2: 0.4829772832369966\n",
      "score1: 0.9112679915268724\n",
      "score2: 0.6010161861947576\n",
      "score1: 0.9112679915268724\n",
      "score2: 0.6851170495374689\n",
      "score1: 0.9112679915268724\n",
      "score2: 0.6434002871446285\n",
      "score1: 0.9112679915268724\n",
      "score2: 0.6115968627217834\n",
      "score1: 0.9112679915268724\n",
      "score2: 0.6126450404643434\n",
      "score1: 0.9112679915268724\n",
      "score2: 0.7480008229280413\n",
      "score1: 0.9112679915268724\n",
      "score2: 0.6991713235436696\n",
      "score1: 0.9112679915268724\n",
      "score2: 0.6642696565238968\n",
      "score1: 0.9112679915268724\n",
      "score2: 0.5519856943590933\n",
      "score1: 0.9112679915268724\n",
      "score2: 0.6528710145568374\n",
      "score1: 0.9112679915268724\n",
      "score2: 0.6220686306000398\n",
      "score1: 0.9112679915268724\n",
      "score2: 0.6524627628011086\n",
      "score1: 0.9112679915268724\n",
      "score2: 0.3920287804663419\n",
      "score1: 0.9112679915268724\n",
      "score2: 0.48112067912788803\n",
      "score1: 0.9112679915268724\n",
      "score2: 0.5151793864725851\n",
      "score1: 0.9112679915268724\n",
      "score2: 0.6323967519617664\n",
      "score1: 0.9112679915268724\n",
      "score2: 0.4809647427155321\n",
      "score1: 0.9112679915268724\n",
      "score2: 0.6596667367783071\n",
      "score1: 0.9112679915268724\n",
      "score2: 0.6872443500848122\n",
      "score1: 0.9112679915268724\n",
      "score2: 0.5575316779725864\n",
      "score1: 0.9112679915268724\n",
      "score2: 0.7315733426937641\n",
      "score1: 0.9112679915268724\n",
      "score2: 0.5611006404627611\n",
      "Best score GradientBoosting: \n",
      "0.9953809887869521\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score GradientBoosting AIS: \n",
      "0.9398254332313966\n",
      "\n",
      "Best score KNeighbors: \n",
      "0.9942448182127082\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score KNeighbors AIS: \n",
      "0.9248216106014271\n",
      "\n",
      "Best score Logistic Regression: \n",
      "0.9734858137954469\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score Logistic Regression AIS: \n",
      "0.908819656812776\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score RandomForest: \n",
      "0.9942235813795446\n",
      "\n",
      "Best score RandomForest AIS: \n",
      "0.9606800033978933\n",
      "\n",
      "score1: 0.8474552271051354\n",
      "score2: 0.88131001878492\n",
      "score1: 0.88131001878492\n",
      "score2: 0.8204209414076388\n",
      "score1: 0.88131001878492\n",
      "score2: 0.6797368582469484\n",
      "score1: 0.88131001878492\n",
      "score2: 0.6078749049429713\n",
      "score1: 0.88131001878492\n",
      "score2: 0.7097019662107279\n",
      "score1: 0.88131001878492\n",
      "score2: 0.7034817579049697\n",
      "score1: 0.88131001878492\n",
      "score2: 0.7757991939036709\n",
      "score1: 0.88131001878492\n",
      "score2: 0.6996301133416345\n",
      "score1: 0.88131001878492\n",
      "score2: 0.6782245501955305\n",
      "score1: 0.88131001878492\n",
      "score2: 0.8268173552988791\n",
      "score1: 0.88131001878492\n",
      "score2: 0.7005475276250428\n",
      "score1: 0.88131001878492\n",
      "score2: 0.6423717130892105\n",
      "score1: 0.88131001878492\n",
      "score2: 0.7148193500201577\n",
      "score1: 0.88131001878492\n",
      "score2: 0.8179629591565609\n",
      "score1: 0.88131001878492\n",
      "score2: 0.760470182882079\n",
      "score1: 0.88131001878492\n",
      "score2: 0.7415779162741971\n",
      "score1: 0.88131001878492\n",
      "score2: 0.641728438458377\n",
      "score1: 0.88131001878492\n",
      "score2: 0.7900860663397278\n",
      "score1: 0.88131001878492\n",
      "score2: 0.5363466487868781\n",
      "score1: 0.88131001878492\n",
      "score2: 0.6662048257487194\n",
      "score1: 0.88131001878492\n",
      "score2: 0.7449156630790384\n",
      "score1: 0.88131001878492\n",
      "score2: 0.7578388108107872\n",
      "score1: 0.88131001878492\n",
      "score2: 0.7373430453063616\n",
      "score1: 0.88131001878492\n",
      "score2: 0.6593967209538378\n",
      "score1: 0.88131001878492\n",
      "score2: 0.5374699638891701\n",
      "score1: 0.88131001878492\n",
      "score2: 0.7209134159931466\n",
      "score1: 0.88131001878492\n",
      "score2: 0.8287190037574884\n",
      "score1: 0.88131001878492\n",
      "score2: 0.710148872445384\n",
      "score1: 0.88131001878492\n",
      "score2: 0.7639475814073898\n",
      "score1: 0.88131001878492\n",
      "score2: 0.7608542019755065\n",
      "score1: 0.88131001878492\n",
      "score2: 0.6851644234633294\n",
      "score1: 0.88131001878492\n",
      "score2: 0.7708087021398503\n",
      "score1: 0.88131001878492\n",
      "score2: 0.6152052394267269\n",
      "score1: 0.88131001878492\n",
      "score2: 0.8170200796689485\n",
      "score1: 0.88131001878492\n",
      "score2: 0.8395183453406483\n",
      "score1: 0.88131001878492\n",
      "score2: 0.6895379289927354\n",
      "score1: 0.88131001878492\n",
      "score2: 0.5848188379565942\n",
      "score1: 0.88131001878492\n",
      "score2: 0.7526785913668332\n",
      "score1: 0.88131001878492\n",
      "score2: 0.7274102446892914\n",
      "score1: 0.88131001878492\n",
      "score2: 0.7624225940327036\n",
      "score1: 0.88131001878492\n",
      "score2: 0.7239893923058364\n",
      "score1: 0.88131001878492\n",
      "score2: 0.7643937029566323\n",
      "score1: 0.88131001878492\n",
      "score2: 0.6612995979674166\n",
      "score1: 0.88131001878492\n",
      "score2: 0.7378435395123802\n",
      "score1: 0.88131001878492\n",
      "score2: 0.6818055172115051\n",
      "score1: 0.88131001878492\n",
      "score2: 0.7491979190594221\n",
      "score1: 0.88131001878492\n",
      "score2: 0.7558531871836649\n",
      "score1: 0.88131001878492\n",
      "score2: 0.7699899567511508\n",
      "score1: 0.88131001878492\n",
      "score2: 0.6615385361632165\n",
      "score1: 0.88131001878492\n",
      "score2: 0.6916924330222957\n",
      "score1: 0.88131001878492\n",
      "score2: 0.6277662111760307\n",
      "Best score GradientBoosting: \n",
      "0.9884259259259258\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score GradientBoosting AIS: \n",
      "0.9479166666666667\n",
      "\n",
      "Best score KNeighbors: \n",
      "0.9895833333333334\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score KNeighbors AIS: \n",
      "0.9270833333333334\n",
      "\n",
      "Best score Logistic Regression: \n",
      "0.9525462962962963\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score Logistic Regression AIS: \n",
      "0.9328703703703705\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score RandomForest: \n",
      "0.9895833333333333\n",
      "\n",
      "Best score RandomForest AIS: \n",
      "0.9513888888888888\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "dataAIS = []\n",
    "dataSMOTE = []\n",
    "dataBase = []\n",
    "data = []\n",
    "fold = 0\n",
    "\n",
    "for result in kf.split(df):\n",
    "    fold = fold+1\n",
    "\n",
    "    #Print the shape of the train and test set\n",
    "    data_train = df.iloc[result[0]]\n",
    "    data_test =  df.iloc[result[1]]\n",
    "\n",
    "    label_train = data_train.copy()\n",
    "    label_train = label_train.drop(['Age','Sex','ALB','ALP','ALT','AST','BIL','CHE','CHOL','CREA','GGT','PROT','split'],axis=1) #Drop all except category for the train df\n",
    " \n",
    "    label_test = data_test.copy()\n",
    "    label_test = label_test.drop(['Age','Sex','ALB','ALP','ALT','AST','BIL','CHE','CHOL','CREA','GGT','PROT','split'],axis=1) #Drop all except category for the train df\n",
    "   \n",
    "    train_df = data_train.copy()\n",
    "    train_df = train_df.drop(['category'],axis=1)\n",
    "    numerical_attribute_train = train_df.drop(['split','Sex'],axis=1)\n",
    "    \n",
    "    num_pipeline = Pipeline([\n",
    "        ('imputer', KNNImputer(n_neighbors=5)),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "    num_attribs = list(numerical_attribute_train)\n",
    "    cat_attribs = [\"Sex\"]\n",
    "\n",
    "    full_pipeline = ColumnTransformer([\n",
    "        (\"num\", num_pipeline, num_attribs),\n",
    "        (\"cat\", OneHotEncoder(), cat_attribs),\n",
    "    ])\n",
    "\n",
    "\n",
    "    data_prepared_train = pd.DataFrame(full_pipeline.fit_transform(train_df),columns=train_df.columns, index=train_df.index)\n",
    "    rejoin_train = pd.concat([data_prepared_train,label_train],axis=1)\n",
    "\n",
    "    test_df = data_test.drop(['category'],axis=1) #We chose KNN for the actual impuation\n",
    "    num_pipeline_test = Pipeline([\n",
    "        ('imputer', KNNImputer(n_neighbors=5)),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "    cat_attribs_test = ['split',\"Sex\"]\n",
    "    numerical_attr_test = test_df.drop(['Sex'],axis=1)\n",
    "    numerical_attr_test = list(numerical_attr_test)\n",
    "\n",
    "    full_pipeline_test = ColumnTransformer([\n",
    "        (\"num\", num_pipeline_test, numerical_attr_test),\n",
    "        (\"cat\", OneHotEncoder(), cat_attribs_test),\n",
    "    ])\n",
    "\n",
    "    data_prepared_test = pd.DataFrame(full_pipeline.fit_transform(test_df),columns=test_df.columns, index=test_df.index)\n",
    "    rejoin_test = pd.concat([data_prepared_test,label_test],axis=1)\n",
    "   \n",
    "    \n",
    "    data_train_AIS = rejoin_train.copy()\n",
    "    data_train_SMOTE = rejoin_train.copy()\n",
    "\n",
    "    data_train_AIS = data_train_AIS.drop(['split'],axis=1)\n",
    "    data_train_SMOTE = data_train_SMOTE.drop(['split'],axis=1)\n",
    "\n",
    "    data_train = rejoin_train.copy()\n",
    "    data_test = rejoin_test.copy()\n",
    "\n",
    "    data_train = data_train.drop(['split'],axis=1)\n",
    "    data_test = data_test.drop(['split'],axis=1)\n",
    "    #Create an oversampling object\n",
    "   \n",
    "    oversample = SMOTE()\n",
    "    \n",
    "\n",
    "\n",
    "    oversample_AIS = ArtificialImmuneSystem()\n",
    "    #Oversample and add to the dataframe to fix the class imbalance\n",
    "    logisticRegression = LogisticRegression()\n",
    "    st = time.time()\n",
    "    x_over, y_over = oversample.fit_resample(data_train_SMOTE.drop([\"category\"], axis=1), data_train_SMOTE.drop(data_train_SMOTE.columns[0:-1],axis=1))\n",
    "    elapsed_time_SMOTE = time.time() - st\n",
    "\n",
    "    st = time.time()\n",
    "    input_x_over_AIS, y_over_AIS = oversample_AIS.AIS_Resample(data_train_AIS.drop([\"category\"], axis=1), data_train_AIS.drop(data_train_AIS.columns[0:-1],axis=1), max_rounds = 200, stopping_cond = 50, model = logisticRegression,K_folds = 5,scorer = 'f1',min_change = 0.005, use_lof = False)\n",
    "    elapsed_time_AIS = time.time() - st\n",
    "\n",
    "    smote_df = pd.concat([x_over, y_over], axis=1)\n",
    "    ais_df = pd.concat([input_x_over_AIS, y_over_AIS], axis=1)\n",
    "\n",
    "    # print the dimensionality of the oversampled dataset\n",
    "    #print(f\"SMOTE Oversampled Data shape: \\n{smote_df.shape}\\n\")\n",
    "    #print(f\"SMOTE Oversampled Data size: \\n{smote_df.size}\\n\")\n",
    "    #print(f\"SMOTE Oversampled Data ndim: \\n{smote_df.ndim}\\n\")\n",
    "    #print(\"_____________________________________________\\n\")\n",
    "\n",
    "    # print the dimensionality of the oversampled dataset\n",
    "    #print(f\"AIS Oversampled Data shape: \\n{ais_df.shape}\\n\")\n",
    "    #print(f\"AIS Oversampled Data size: \\n{ais_df.size}\\n\")\n",
    "    #print(f\"AIS Oversampled Data ndim: \\n{ais_df.ndim}\\n\")\n",
    "    #print(\"_____________________________________________\\n\")\n",
    "\n",
    "\n",
    "    # print the new class distribution using a Counter\n",
    "    #print(f\"New SMOTE Class Distribution: {Counter(smote_df['5'])}\")\n",
    "    #print(f\"New AIS Class Distribution: {Counter(ais_df['5'])}\")\n",
    "    ## print the new class distribution using a Counter\n",
    "    #print(f\"Old Class Distribution: {Counter(data_train['5'])}\")\n",
    "\n",
    "    #print(\"_____________________________________________\\n\")\n",
    "\n",
    "    #labelTrainFlat = labels_train.values.ravel()\n",
    "\n",
    "    #Fit one vs rest Gradient Boosting classification\n",
    "    gradientBoosting = GradientBoostingClassifier()\n",
    "    gradientBoosting = gradientBoosting.fit(x_over, y_over.values.ravel())\n",
    "\n",
    "    gradientBoosting_AIS = GradientBoostingClassifier()\n",
    "    gradientBoosting_AIS = gradientBoosting.fit(input_x_over_AIS, y_over_AIS.values.ravel())\n",
    "\n",
    "    gradientBoosting_Base = gradientBoosting.fit(data_train.drop([\"category\"], axis=1), data_train.drop(data_train.columns[0:-1],axis=1).values.ravel())\n",
    "\n",
    "    #Fit RandomForestClassifier classification\n",
    "    randomForest = RandomForestClassifier()\n",
    "    randomForest = randomForest.fit(x_over,y_over.values.ravel())\n",
    "\n",
    "    randomForest = RandomForestClassifier()\n",
    "    randomForest_AIS  = randomForest.fit(input_x_over_AIS,y_over_AIS.values.ravel())\n",
    "\n",
    "    randomForest_Base = randomForest.fit(data_train.drop([\"category\"], axis=1), data_train.drop(data_train.columns[0:-1],axis=1).values.ravel())\n",
    "    #randomForest_Base  = randomForest.fit(data_train.drop([\"5\"], axis=1), data_train.drop(data_train_AIS.columns[0:-1]).values.ravel())\n",
    "\n",
    "    #Create a KNeighbors classification object\n",
    "    kNeighbors = KNeighborsClassifier()\n",
    "    kNeighbors = kNeighbors.fit(x_over,y_over.values.ravel())\n",
    "\n",
    "    kNeighbors = KNeighborsClassifier()\n",
    "    kNeighbors_AIS  = kNeighbors.fit(input_x_over_AIS,y_over_AIS.values.ravel())\n",
    "    kNeighbors_Base = kNeighbors.fit(data_train.drop([\"category\"], axis=1), data_train.drop(data_train.columns[0:-1],axis=1).values.ravel())\n",
    "    #kNeighbors_base  = kNeighbors.fit(data_train.drop([\"5\"], axis=1), data_train.drop(data_train_AIS.columns[0:-1]).values.ravel())\n",
    "\n",
    "    #Create an LogisticRegression object\n",
    "    logisticRegression = LogisticRegression(max_iter=5000)\n",
    "    logisticRegression = logisticRegression.fit(x_over,y_over.values.ravel())\n",
    "\n",
    "    logisticRegression = LogisticRegression(max_iter=5000)\n",
    "    logisticRegression_AIS  = logisticRegression.fit(input_x_over_AIS,y_over_AIS.values.ravel())\n",
    "    logisticRegression_Base = logisticRegression.fit(data_train.drop([\"category\"], axis=1), data_train.drop(data_train.columns[0:-1],axis=1).values.ravel())\n",
    "    #logisticRegression_Base  = logisticRegression.fit(data_train.drop([\"5\"], axis=1), data_train.drop(data_train_AIS.columns[0:-1]).values.ravel())\n",
    "\n",
    "    #Set the parameters of GradientBoosting for GridSearchCV\n",
    "    parametersGradientBoosting = [\n",
    "        {'learning_rate': [0.44,0.45,0.46],'min_samples_leaf': [5,6,7],'min_samples_split': [7,8,9,10], 'n_estimators': [57,58,59,60]}\n",
    "    ]\n",
    "\n",
    "    #Set the scoring parameters\n",
    "    scoringX = {\"roc_auc\": \"roc_auc\", \"bal_accuracy\": \"balanced_accuracy\"}\n",
    "\n",
    "    #Preform Gridsearch to find best parameters\n",
    "    grid_searchGradientBoosting = GridSearchCV(gradientBoosting, parametersGradientBoosting, cv=4, scoring = scoringX, return_train_score=True, n_jobs=-1, refit='bal_accuracy')\n",
    "    grid_searchGradientBoosting_AIS = GridSearchCV(gradientBoosting_AIS, parametersGradientBoosting, cv=4, scoring = scoringX, return_train_score=True, n_jobs=-1, refit='bal_accuracy')\n",
    "    #grid_searchGradientBoosting_Base = GridSearchCV(gradientBoosting_Base, parametersGradientBoosting, cv=4, scoring = scoringX, return_train_score=True, n_jobs=-1, refit='bal_accuracy')\n",
    "    #Fit the GradientBoosting \n",
    "    grid_searchGradientBoosting.fit(x_over, y_over.values.ravel())\n",
    "    grid_searchGradientBoosting_AIS.fit(input_x_over_AIS,y_over_AIS.values.ravel())\n",
    "  \n",
    "    \n",
    "\n",
    "    #Print GridSearchCV Results\n",
    "    \n",
    "    print(f\"Best score GradientBoosting: \\n{grid_searchGradientBoosting.best_score_}\\n\")\n",
    "    print(\"_____________________________________________\\n\")\n",
    "    \n",
    "    print(f\"Best score GradientBoosting AIS: \\n{grid_searchGradientBoosting_AIS.best_score_}\\n\")\n",
    "\n",
    "    #Set the parameters of KNeighbors for GridSearchCV\n",
    "    parametersKNeighbors = [\n",
    "        {'n_neighbors': [1,2,3],'weights':['uniform', 'distance'],'algorithm':['auto'], 'p': [1,2,3]}\n",
    "    ]\n",
    "\n",
    "    #Set the scoring parameters\n",
    "    scoringX = {\"roc_auc\": \"roc_auc\", \"bal_accuracy\": \"balanced_accuracy\"}\n",
    "\n",
    "    #Preform KNeighbors to find best parameters\n",
    "    grid_searchKNeighbors = GridSearchCV(kNeighbors, parametersKNeighbors, cv=4, scoring = scoringX, return_train_score=True, n_jobs=-1, refit='bal_accuracy')\n",
    "    grid_searchKNeighbors_AIS = GridSearchCV(kNeighbors_AIS, parametersKNeighbors, cv=4, scoring = scoringX, return_train_score=True, n_jobs=-1, refit='bal_accuracy')\n",
    "\n",
    "    #Fit the KNeighbors \n",
    "    grid_searchKNeighbors.fit(x_over, y_over.values.ravel())\n",
    "    grid_searchKNeighbors_AIS.fit(input_x_over_AIS,y_over_AIS.values.ravel())\n",
    "\n",
    "    #Print GridSearchCV Results\n",
    "   \n",
    "    print(f\"Best score KNeighbors: \\n{grid_searchKNeighbors.best_score_}\\n\")\n",
    "    print(\"_____________________________________________\\n\")\n",
    "   \n",
    "    print(f\"Best score KNeighbors AIS: \\n{grid_searchKNeighbors_AIS.best_score_}\\n\")\n",
    "    \n",
    "    #Set the parameters of LogisticRegression for GridSearchCV\n",
    "    parametersLogisticRegression = [\n",
    "        {'multi_class': ['ovr'],'penalty':['none','l2'], 'C': [1,2,3]}\n",
    "    ]\n",
    "    scoringX = {\"roc_auc\": \"roc_auc\", \"bal_accuracy\": \"balanced_accuracy\"}\n",
    "\n",
    "    #Preform LogisticRegression to find best parameters\n",
    "    grid_searchLogisticRegression = GridSearchCV(logisticRegression, parametersLogisticRegression, cv=4, scoring = scoringX, return_train_score=True, n_jobs=-1, refit='bal_accuracy')\n",
    "    grid_searchLogisticRegression_AIS = GridSearchCV(logisticRegression_AIS, parametersLogisticRegression, cv=4, scoring = scoringX, return_train_score=True, n_jobs=-1, refit='bal_accuracy')\n",
    "\n",
    "    #Fit the LogisticRegression \n",
    "    grid_searchLogisticRegression.fit(x_over, y_over.values.ravel())\n",
    "    grid_searchLogisticRegression_AIS.fit(input_x_over_AIS,y_over_AIS.values.ravel())\n",
    "\n",
    "    #Print LogisticRegression Results\n",
    "    \n",
    "    print(f\"Best score Logistic Regression: \\n{grid_searchLogisticRegression.best_score_}\\n\")\n",
    "    print(\"_____________________________________________\\n\")\n",
    "   \n",
    "    print(f\"Best score Logistic Regression AIS: \\n{grid_searchLogisticRegression_AIS.best_score_}\\n\")\n",
    "\n",
    "    #Set the parameters of RandomForest for GridSearchCV\n",
    "    parametersRandomForest = [\n",
    "        {'n_estimators': [145,150,155,190],'max_depth': [10,12], 'bootstrap': [True, False],\n",
    "        'min_samples_split': [0.05,2], 'max_features': ['auto']}\n",
    "    ]\n",
    "\n",
    "    #Preform Gridsearch to find best parameters\n",
    "    grid_searchRandomForest = GridSearchCV(randomForest, parametersRandomForest, cv=4, scoring = scoringX, return_train_score=True, n_jobs=-1, refit='bal_accuracy')\n",
    "    grid_searchRandomForest_AIS = GridSearchCV(randomForest_AIS, parametersRandomForest, cv=4, scoring = scoringX, return_train_score=True, n_jobs=-1, refit='bal_accuracy')\n",
    "\n",
    "    #Fit the RandomForest \n",
    "    grid_searchRandomForest.fit(x_over, y_over.values.ravel())\n",
    "    grid_searchRandomForest_AIS.fit(input_x_over_AIS,y_over_AIS.values.ravel())\n",
    "\n",
    "    #Print GridSearchCV Results\n",
    "\n",
    "    print(f\"Best score RandomForest: \\n{grid_searchRandomForest.best_score_}\\n\")\n",
    "\n",
    "    print(f\"Best score RandomForest AIS: \\n{grid_searchRandomForest_AIS.best_score_}\\n\")\n",
    "\n",
    "    #Get the results for all classifiers \n",
    "    cross_val_resultsGB = grid_searchGradientBoosting.cv_results_\n",
    "    cross_val_resultsRF = grid_searchRandomForest.cv_results_\n",
    "    cross_val_resultsLR = grid_searchLogisticRegression.cv_results_\n",
    "    cross_val_resultsKN = grid_searchKNeighbors.cv_results_\n",
    "\n",
    "    cross_val_resultsGB_AIS = grid_searchGradientBoosting_AIS.cv_results_\n",
    "    cross_val_resultsRF_AIS = grid_searchRandomForest_AIS.cv_results_\n",
    "    cross_val_resultsLR_AIS = grid_searchLogisticRegression_AIS.cv_results_\n",
    "    cross_val_resultsKN_AIS = grid_searchKNeighbors_AIS.cv_results_\n",
    "\n",
    "\n",
    "    #Print the results of all classiifiers\n",
    "    #GBC\n",
    "    mean_test_roc_aucGB = mean(cross_val_resultsGB['mean_test_roc_auc'])\n",
    "    mean_test_bal_accuracyGB = mean(cross_val_resultsGB['mean_test_bal_accuracy'])\n",
    "    \n",
    "    mean_test_roc_aucGB_AIS = mean(cross_val_resultsGB_AIS['mean_test_roc_auc'])\n",
    "    mean_test_bal_accuracyGB_AIS = mean(cross_val_resultsGB_AIS['mean_test_bal_accuracy'])\n",
    "   \n",
    "    #RFC\n",
    "    mean_test_roc_aucRF = mean(cross_val_resultsRF['mean_test_roc_auc'])\n",
    "    mean_test_bal_accuracyRF = mean(cross_val_resultsRF['mean_test_bal_accuracy'])\n",
    "    \n",
    "    mean_test_roc_aucRF_AIS = mean(cross_val_resultsRF_AIS['mean_test_roc_auc'])\n",
    "    mean_test_bal_accuracyRF_AIS = mean(cross_val_resultsRF_AIS['mean_test_bal_accuracy'])\n",
    "    #LRC\n",
    "    mean_test_roc_aucLR = mean(cross_val_resultsLR['mean_test_roc_auc'])\n",
    "    mean_test_bal_accuracyLR = mean(cross_val_resultsLR['mean_test_bal_accuracy'])\n",
    "    \n",
    "    mean_test_roc_aucLR_AIS = mean(cross_val_resultsLR_AIS['mean_test_roc_auc'])\n",
    "    mean_test_bal_accuracyLR_AIS = mean(cross_val_resultsLR_AIS['mean_test_bal_accuracy'])\n",
    "\n",
    "    #KNC\n",
    "    mean_test_roc_aucKN = mean(cross_val_resultsKN['mean_test_roc_auc'])\n",
    "    mean_test_bal_accuracyKN = mean(cross_val_resultsKN['mean_test_bal_accuracy'])\n",
    "    \n",
    "    mean_test_roc_aucKN_AIS = mean(cross_val_resultsKN_AIS['mean_test_roc_auc'])\n",
    "    mean_test_bal_accuracyKN_AIS = mean(cross_val_resultsKN_AIS['mean_test_bal_accuracy'])\n",
    "\n",
    "    predictions_test_over_GB = grid_searchGradientBoosting.best_estimator_.predict(data_test.drop([\"category\"],axis=1))\n",
    "    predictions_test_over_RF = grid_searchRandomForest.best_estimator_.predict(data_test.drop([\"category\"],axis=1))\n",
    "    predictions_test_over_LR = grid_searchLogisticRegression.best_estimator_.predict(data_test.drop([\"category\"],axis=1))\n",
    "    predictions_test_over_KN = grid_searchKNeighbors.best_estimator_.predict(data_test.drop([\"category\"],axis=1))\n",
    "\n",
    "    predictions_test_over_GB_AIS = grid_searchGradientBoosting_AIS.best_estimator_.predict(data_test.drop([\"category\"],axis=1))\n",
    "    predictions_test_over_RF_AIS = grid_searchRandomForest_AIS.best_estimator_.predict(data_test.drop([\"category\"],axis=1))\n",
    "    predictions_test_over_LR_AIS = grid_searchLogisticRegression_AIS.best_estimator_.predict(data_test.drop([\"category\"],axis=1))\n",
    "    predictions_test_over_KN_AIS = grid_searchKNeighbors_AIS.best_estimator_.predict(data_test.drop([\"category\"],axis=1))\n",
    "\n",
    "    predictions_GB = gradientBoosting_Base.predict(data_test.drop([\"category\"],axis=1))\n",
    "    predictions_RF = randomForest_Base.predict(data_test.drop([\"category\"],axis=1))\n",
    "    predictions_LR = logisticRegression_Base.predict(data_test.drop([\"category\"],axis=1))\n",
    "    predictions_KN = kNeighbors_Base.predict(data_test.drop([\"category\"],axis=1))\n",
    "\n",
    "    f1_score_GB = f1_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_GB)\n",
    "    f1_score_RF = f1_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_RF)\n",
    "    f1_score_LR = f1_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_LR)\n",
    "    f1_score_KN = f1_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_KN)\n",
    "\n",
    "    f1_score_GB_AIS = f1_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_GB_AIS) \n",
    "    f1_score_RF_AIS = f1_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_RF_AIS)\n",
    "    f1_score_LR_AIS = f1_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_LR_AIS)\n",
    "    f1_score_KN_AIS = f1_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_KN_AIS)\n",
    "\n",
    "    f1_score_GB_Base = f1_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_GB)\n",
    "    f1_score_RF_Base = f1_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_RF)\n",
    "    f1_score_LR_Base = f1_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_LR)\n",
    "    f1_score_KN_Base = f1_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_KN)\n",
    "\n",
    "    geometric_mean_score_GB = geometric_mean_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_GB, labels=None, pos_label=1, average='binary',)\n",
    "    geometric_mean_score_RF = geometric_mean_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_RF, labels=None, pos_label=1, average='binary',)\n",
    "    geometric_mean_score_LR = geometric_mean_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_LR, labels=None, pos_label=1, average='binary',)\n",
    "    geometric_mean_score_KN = geometric_mean_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_KN, labels=None, pos_label=1, average='binary',)\n",
    "\n",
    "    geometric_mean_score_GB_AIS = geometric_mean_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_GB_AIS, labels=None, pos_label=1, average='binary',)\n",
    "    geometric_mean_score_RF_AIS = geometric_mean_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_RF_AIS, labels=None, pos_label=1, average='binary',)\n",
    "    geometric_mean_score_LR_AIS = geometric_mean_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_LR_AIS, labels=None, pos_label=1, average='binary',)\n",
    "    geometric_mean_score_KN_AIS = geometric_mean_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_KN_AIS, labels=None, pos_label=1, average='binary',)\n",
    "\n",
    "    geometric_mean_score_GB_Base = geometric_mean_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_GB, labels=None, pos_label=1, average='binary',)\n",
    "    geometric_mean_score_RF_Base = geometric_mean_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_RF, labels=None, pos_label=1, average='binary',)\n",
    "    geometric_mean_score_LR_Base = geometric_mean_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_LR, labels=None, pos_label=1, average='binary',)\n",
    "    geometric_mean_score_KN_Base = geometric_mean_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_KN, labels=None, pos_label=1, average='binary',)\n",
    "\n",
    "    \n",
    "    roc_auc_GB_AIS = roc_auc_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_GB_AIS)\n",
    "    roc_auc_RF_AIS = roc_auc_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_RF_AIS)\n",
    "    roc_auc_LR_AIS = roc_auc_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_LR_AIS)\n",
    "    roc_auc_KN_AIS = roc_auc_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_KN_AIS)\n",
    " \n",
    "    roc_auc_GB_Base = roc_auc_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_GB)\n",
    "    roc_auc_RF_Base = roc_auc_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_RF)\n",
    "    roc_auc_LR_Base = roc_auc_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_LR)\n",
    "    roc_auc_KN_Base = roc_auc_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_KN)\n",
    "\n",
    "    roc_auc_GB = roc_auc_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_GB)\n",
    "    roc_auc_RF = roc_auc_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_RF)\n",
    "    roc_auc_LR = roc_auc_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_LR)\n",
    "    roc_auc_KN = roc_auc_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_KN)\n",
    "\n",
    "    \n",
    "\n",
    "    balanced_acc_GB_AIS = balanced_accuracy_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_GB_AIS)\n",
    "    balanced_acc_RF_AIS = balanced_accuracy_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_RF_AIS)\n",
    "    balanced_acc_LR_AIS = balanced_accuracy_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_LR_AIS)\n",
    "    balanced_acc_KN_AIS = balanced_accuracy_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_KN_AIS)\n",
    " \n",
    "    balanced_acc_GB = balanced_accuracy_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_GB)\n",
    "    balanced_acc_RF = balanced_accuracy_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_RF)\n",
    "    balanced_acc_LR = balanced_accuracy_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_LR)\n",
    "    balanced_acc_KN = balanced_accuracy_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_KN)\n",
    "\n",
    "    \n",
    "    balanced_acc_GB_Base = balanced_accuracy_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_GB)\n",
    "    balanced_acc_RF_Base = balanced_accuracy_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_RF)\n",
    "    balanced_acc_LR_Base = balanced_accuracy_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_LR)\n",
    "    balanced_acc_KN_Base = balanced_accuracy_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_KN)\n",
    "\n",
    "    \n",
    "    dataAIS.append( [fold,dataset,\"AIS\", elapsed_time_AIS,\" max_rounds = 100, stopping_cond = 20, model = logisticRegression,K_folds = 5,scorer = 'f1',min_change = 0.001, use_lof = False\", roc_auc_GB_AIS, roc_auc_RF_AIS, roc_auc_LR_AIS, roc_auc_KN_AIS, balanced_acc_GB_AIS, balanced_acc_RF_AIS,  balanced_acc_LR_AIS,  balanced_acc_KN_AIS, geometric_mean_score_GB_AIS, geometric_mean_score_RF_AIS, geometric_mean_score_LR_AIS, geometric_mean_score_KN_AIS,f1_score_GB_AIS,f1_score_RF_AIS,f1_score_LR_AIS,f1_score_KN_AIS ])\n",
    "    dataSMOTE.append([fold,dataset,\"SMOTE\", elapsed_time_SMOTE,\"NA\", roc_auc_GB,  roc_auc_RF, roc_auc_LR,roc_auc_KN, balanced_acc_GB, balanced_acc_RF,  balanced_acc_LR,  balanced_acc_KN, geometric_mean_score_GB, geometric_mean_score_RF, geometric_mean_score_LR, geometric_mean_score_KN,f1_score_GB,f1_score_RF,f1_score_LR,f1_score_KN])\n",
    "    dataBase.append([fold,dataset,\"BASE\", \"NA\",\"NA\", roc_auc_GB_Base, roc_auc_RF_Base, roc_auc_LR_Base, roc_auc_KN_Base, balanced_acc_GB_Base, balanced_acc_RF_Base,balanced_acc_LR_Base,  balanced_acc_KN_Base, geometric_mean_score_GB_Base, geometric_mean_score_RF_Base, geometric_mean_score_LR_Base, geometric_mean_score_KN_Base,f1_score_GB_Base,f1_score_RF_Base,f1_score_LR_Base,f1_score_KN_Base])\n",
    "    data.append(dataAIS[fold-1])\n",
    "    data.append(dataSMOTE[fold-1])\n",
    "    data.append(dataBase[fold-1])\n",
    "    data.append([\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"])\n",
    "\n",
    "average_AIS_Runtime = 0\n",
    "\n",
    "average_roc_auc_GB_AIS = 0\n",
    "average_roc_auc_RF_AIS = 0\n",
    "average_roc_auc_LR_AIS = 0\n",
    "average_roc_auc_KN_AIS = 0\n",
    "\n",
    "average_balanced_acc_GB_AIS = 0\n",
    "average_balanced_acc_RF_AIS = 0\n",
    "average_balanced_acc_LR_AIS = 0\n",
    "average_balanced_acc_KN_AIS = 0\n",
    "\n",
    "average_geometric_mean_score_GB_AIS = 0\n",
    "average_geometric_mean_score_RF_AIS = 0\n",
    "average_geometric_mean_score_LR_AIS = 0\n",
    "average_geometric_mean_score_KN_AIS = 0\n",
    "    \n",
    "average_f1_score_GB_AIS = 0\n",
    "average_f1_score_RF_AIS = 0\n",
    "average_f1_score_LR_AIS = 0\n",
    "average_f1_score_KN_AIS = 0\n",
    "\n",
    "\n",
    "average_SMOTE_Runtime = 0\n",
    "\n",
    "average_roc_auc_GB = 0\n",
    "average_roc_auc_RF = 0\n",
    "average_roc_auc_LR = 0\n",
    "average_roc_auc_KN = 0\n",
    "\n",
    "average_balanced_acc_GB = 0\n",
    "average_balanced_acc_RF = 0\n",
    "average_balanced_acc_LR = 0\n",
    "average_balanced_acc_KN = 0\n",
    "\n",
    "average_geometric_mean_score_GB = 0\n",
    "average_geometric_mean_score_RF = 0\n",
    "average_geometric_mean_score_LR = 0\n",
    "average_geometric_mean_score_KN = 0\n",
    "    \n",
    "average_f1_score_GB = 0\n",
    "average_f1_score_RF = 0\n",
    "average_f1_score_LR = 0\n",
    "average_f1_score_KN = 0\n",
    "\n",
    "average_roc_auc_GB_Base = 0\n",
    "average_roc_auc_RF_Base = 0\n",
    "average_roc_auc_LR_Base = 0\n",
    "average_roc_auc_KN_Base = 0\n",
    "\n",
    "average_balanced_acc_GB_Base = 0\n",
    "average_balanced_acc_RF_Base = 0\n",
    "average_balanced_acc_LR_Base = 0\n",
    "average_balanced_acc_KN_Base = 0\n",
    "\n",
    "average_geometric_mean_score_GB_Base = 0\n",
    "average_geometric_mean_score_RF_Base = 0\n",
    "average_geometric_mean_score_LR_Base = 0\n",
    "average_geometric_mean_score_KN_Base = 0\n",
    "    \n",
    "average_f1_score_GB_Base = 0\n",
    "average_f1_score_RF_Base = 0\n",
    "average_f1_score_LR_Base = 0\n",
    "average_f1_score_KN_Base = 0\n",
    "\n",
    "for array in dataAIS:\n",
    "\n",
    "    average_AIS_Runtime = average_AIS_Runtime + array[3]\n",
    "\n",
    "    average_roc_auc_GB_AIS = average_roc_auc_GB_AIS + array[5]\n",
    "    average_roc_auc_RF_AIS = average_roc_auc_RF_AIS + array[6]\n",
    "    average_roc_auc_LR_AIS = average_roc_auc_LR_AIS + array[7]\n",
    "    average_roc_auc_KN_AIS = average_roc_auc_KN_AIS + array[8]\n",
    "\n",
    "    average_balanced_acc_GB_AIS = average_balanced_acc_GB_AIS + array[9]\n",
    "    average_balanced_acc_RF_AIS = average_balanced_acc_RF_AIS + array[10]\n",
    "    average_balanced_acc_LR_AIS = average_balanced_acc_LR_AIS + array[11]\n",
    "    average_balanced_acc_KN_AIS = average_balanced_acc_KN_AIS + array[12]\n",
    "\n",
    "    average_geometric_mean_score_GB_AIS = average_geometric_mean_score_GB_AIS + array[13]\n",
    "    average_geometric_mean_score_RF_AIS = average_geometric_mean_score_RF_AIS + array[14]\n",
    "    average_geometric_mean_score_LR_AIS = average_geometric_mean_score_LR_AIS + array[15]\n",
    "    average_geometric_mean_score_KN_AIS = average_geometric_mean_score_KN_AIS + array[16]\n",
    "    \n",
    "    average_f1_score_GB_AIS = average_f1_score_GB_AIS + array[17]\n",
    "    average_f1_score_RF_AIS = average_f1_score_RF_AIS + array[18]\n",
    "    average_f1_score_LR_AIS = average_f1_score_LR_AIS + array[19]\n",
    "    average_f1_score_KN_AIS = average_f1_score_KN_AIS + array[20]\n",
    "\n",
    "for array in dataSMOTE:\n",
    "\n",
    "    average_SMOTE_Runtime = average_SMOTE_Runtime + array[3]\n",
    "\n",
    "    average_roc_auc_GB = average_roc_auc_GB + array[5]\n",
    "    average_roc_auc_RF = average_roc_auc_RF + array[6]\n",
    "    average_roc_auc_LR = average_roc_auc_LR + array[7]\n",
    "    average_roc_auc_KN = average_roc_auc_KN + array[8]\n",
    "\n",
    "    average_balanced_acc_GB = average_balanced_acc_GB + array[9]\n",
    "    average_balanced_acc_RF = average_balanced_acc_RF + array[10]\n",
    "    average_balanced_acc_LR = average_balanced_acc_LR + array[11]\n",
    "    average_balanced_acc_KN = average_balanced_acc_KN + array[12]\n",
    "\n",
    "    average_geometric_mean_score_GB = average_geometric_mean_score_GB + array[13]\n",
    "    average_geometric_mean_score_RF = average_geometric_mean_score_RF + array[14]\n",
    "    average_geometric_mean_score_LR = average_geometric_mean_score_LR + array[15]\n",
    "    average_geometric_mean_score_KN = average_geometric_mean_score_KN + array[16]\n",
    "    \n",
    "    average_f1_score_GB = average_f1_score_GB + array[17]\n",
    "    average_f1_score_RF = average_f1_score_RF + array[18]\n",
    "    average_f1_score_LR = average_f1_score_LR + array[19]\n",
    "    average_f1_score_KN = average_f1_score_KN + array[20]\n",
    "\n",
    "for array in dataBase:\n",
    "\n",
    "    average_roc_auc_GB_Base = average_roc_auc_GB_Base + array[5]\n",
    "    average_roc_auc_RF_Base = average_roc_auc_RF_Base + array[6]\n",
    "    average_roc_auc_LR_Base = average_roc_auc_LR_Base + array[7]\n",
    "    average_roc_auc_KN_Base = average_roc_auc_KN_Base + array[8]\n",
    "\n",
    "    average_balanced_acc_GB_Base = average_balanced_acc_GB_Base + array[9]\n",
    "    average_balanced_acc_RF_Base = average_balanced_acc_RF_Base + array[10]\n",
    "    average_balanced_acc_LR_Base = average_balanced_acc_LR_Base + array[11]\n",
    "    average_balanced_acc_KN_Base = average_balanced_acc_KN_Base + array[12]\n",
    "\n",
    "    average_geometric_mean_score_GB_Base = average_geometric_mean_score_GB_Base + array[13]\n",
    "    average_geometric_mean_score_RF_Base = average_geometric_mean_score_RF_Base + array[14]\n",
    "    average_geometric_mean_score_LR_Base = average_geometric_mean_score_LR_Base + array[15]\n",
    "    average_geometric_mean_score_KN_Base = average_geometric_mean_score_KN_Base + array[16]\n",
    "    \n",
    "    average_f1_score_GB_Base = average_f1_score_GB_Base + array[17]\n",
    "    average_f1_score_RF_Base = average_f1_score_RF_Base + array[18]\n",
    "    average_f1_score_LR_Base = average_f1_score_LR_Base + array[19]\n",
    "    average_f1_score_KN_Base = average_f1_score_KN_Base + array[20]\n",
    "\n",
    "average_f1_score_GB = average_f1_score_GB / fold\n",
    "average_f1_score_RF = average_f1_score_RF / fold\n",
    "average_f1_score_LR = average_f1_score_LR / fold\n",
    "average_f1_score_KN= average_f1_score_KN / fold\n",
    "\n",
    "average_f1_score_GB_AIS = average_f1_score_GB_AIS / fold\n",
    "average_f1_score_RF_AIS = average_f1_score_RF_AIS / fold\n",
    "average_f1_score_LR_AIS = average_f1_score_LR_AIS / fold\n",
    "average_f1_score_KN_AIS = average_f1_score_KN_AIS / fold\n",
    "\n",
    "average_f1_score_GB_Base = average_f1_score_GB_Base / fold\n",
    "average_f1_score_RF_Base = average_f1_score_RF_Base / fold\n",
    "average_f1_score_LR_Base = average_f1_score_LR_Base / fold\n",
    "average_f1_score_KN_Base= average_f1_score_KN_Base / fold\n",
    "\n",
    "average_geometric_mean_score_GB = average_geometric_mean_score_GB / fold\n",
    "average_geometric_mean_score_RF= average_geometric_mean_score_RF / fold\n",
    "average_geometric_mean_score_LR= average_geometric_mean_score_LR / fold\n",
    "average_geometric_mean_score_KN = average_geometric_mean_score_KN / fold\n",
    "\n",
    "average_geometric_mean_score_GB_AIS= average_geometric_mean_score_GB_AIS / fold\n",
    "average_geometric_mean_score_RF_AIS= average_geometric_mean_score_RF_AIS / fold\n",
    "average_geometric_mean_score_LR_AIS = average_geometric_mean_score_LR_AIS / fold\n",
    "average_geometric_mean_score_KN_AIS = average_geometric_mean_score_KN_AIS / fold\n",
    "\n",
    "average_geometric_mean_score_GB_Base = average_geometric_mean_score_GB_Base / fold\n",
    "average_geometric_mean_score_RF_Base= average_geometric_mean_score_RF_Base / fold\n",
    "average_geometric_mean_score_LR_Base= average_geometric_mean_score_LR_Base / fold\n",
    "average_geometric_mean_score_KN_Base= average_geometric_mean_score_KN_Base / fold\n",
    "\n",
    "    \n",
    "average_roc_auc_GB_AIS= average_roc_auc_GB_AIS / fold\n",
    "average_roc_auc_RF_AIS= average_roc_auc_RF_AIS / fold\n",
    "average_roc_auc_LR_AIS= average_roc_auc_LR_AIS / fold\n",
    "average_roc_auc_KN_AIS= average_roc_auc_KN_AIS / fold\n",
    " \n",
    "average_roc_auc_GB_Base = average_roc_auc_GB_Base / fold\n",
    "average_roc_auc_RF_Base= average_roc_auc_RF_Base / fold\n",
    "average_roc_auc_LR_Base= average_roc_auc_LR_Base / fold\n",
    "average_roc_auc_KN_Base= average_roc_auc_KN_Base / fold\n",
    "\n",
    "average_roc_auc_GB= average_roc_auc_GB / fold\n",
    "average_roc_auc_RF= average_roc_auc_RF / fold\n",
    "average_roc_auc_LR= average_roc_auc_LR / fold\n",
    "average_roc_auc_KN= average_roc_auc_KN / fold\n",
    "\n",
    "    \n",
    "\n",
    "average_balanced_acc_GB_AIS= average_balanced_acc_GB_AIS / fold\n",
    "average_balanced_acc_RF_AIS= average_balanced_acc_RF_AIS / fold\n",
    "average_balanced_acc_LR_AIS= average_balanced_acc_LR_AIS / fold\n",
    "average_balanced_acc_KN_AIS= average_balanced_acc_KN_AIS / fold\n",
    " \n",
    "average_balanced_acc_GB= average_balanced_acc_GB / fold\n",
    "average_balanced_acc_RF= average_balanced_acc_RF / fold\n",
    "average_balanced_acc_LR= average_balanced_acc_LR / fold\n",
    "average_balanced_acc_KN= average_balanced_acc_KN / fold\n",
    "\n",
    "    \n",
    "average_balanced_acc_GB_Base= average_balanced_acc_GB_Base / fold\n",
    "average_balanced_acc_RF_Base= average_balanced_acc_RF_Base / fold\n",
    "average_balanced_acc_LR_Base= average_balanced_acc_LR_Base / fold\n",
    "average_balanced_acc_KN_Base= average_balanced_acc_KN_Base / fold\n",
    "\n",
    "\n",
    "\n",
    "data.append( [\"\",\"\",\"AIS\", \"\",\"AVERAGE:\", average_roc_auc_GB_AIS, average_roc_auc_RF_AIS, average_roc_auc_LR_AIS, average_roc_auc_KN_AIS, average_balanced_acc_GB_AIS, average_balanced_acc_RF_AIS,  average_balanced_acc_LR_AIS,  average_balanced_acc_KN_AIS, average_geometric_mean_score_GB_AIS, average_geometric_mean_score_RF_AIS, average_geometric_mean_score_LR_AIS, average_geometric_mean_score_KN_AIS,average_f1_score_GB_AIS,average_f1_score_RF_AIS,average_f1_score_LR_AIS,average_f1_score_KN_AIS ])\n",
    "data.append([\"\",\"\",\"SMOTE\", \"\",\"AVERAGE:\", average_roc_auc_GB,  average_roc_auc_RF, average_roc_auc_LR,average_roc_auc_KN, average_balanced_acc_GB, average_balanced_acc_RF,  average_balanced_acc_LR,  average_balanced_acc_KN, average_geometric_mean_score_GB, average_geometric_mean_score_RF, average_geometric_mean_score_LR, average_geometric_mean_score_KN,average_f1_score_GB,average_f1_score_RF,average_f1_score_LR,average_f1_score_KN])\n",
    "data.append([\"\",\"\",\"BASE\", \"\",\"AVERAGE:\", average_roc_auc_GB_Base, average_roc_auc_RF_Base, average_roc_auc_LR_Base, average_roc_auc_KN_Base, average_balanced_acc_GB_Base, average_balanced_acc_RF_Base,balanced_acc_LR_Base,  average_balanced_acc_KN_Base, average_geometric_mean_score_GB_Base, average_geometric_mean_score_RF_Base, average_geometric_mean_score_LR_Base, average_geometric_mean_score_KN_Base,average_f1_score_GB_Base,average_f1_score_RF_Base,average_f1_score_LR_Base,average_f1_score_KN_Base])\n",
    "data.append([\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = [\"Fold\", \"Dataset\",\"Oversample\",\"Oversample Run Time\", \"Oversample Paramaters\", \"ROC AUC for Gradient Boosting\",  \"ROC AUC for Random Forests\", \"ROC AUC for Logistic Regression\",  \"ROC AUC for K Nearest Neighbours\", \"Balanced Accuracy for Gradient Boosting\", \"Balanced Accuracy for Random Forests\" ,\"Balanced Accuracy for Logistic Regression\",\"Balanced Accuracy for K Nearest Neighbours\", \"Geometric Mean Score for Gradient Boosting\", \"Geometric Mean Score for Random Forest\", \"Geometric Mean Score for Logestic Regression\", \"Geometric Mean Score for K Neighbors\", \"F1 Score for Gradient Boosting\", \"F1 Score for Random Forest\", \"F1 Score for Logestic Regression\", \"F1 Score for K Neighbors\"]\n",
    "dfoutput=pd.DataFrame(data,columns=col_names)\n",
    "title = \"ExperimentalResults/ExperimentalComparisons-TestReal.csv\"\n",
    "dfoutput.to_csv(title, mode='a',index=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('csi4106')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "51ea9996f2a91c7d112e626959c304b606e4bf2254e73fec145d965796b2ca69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
