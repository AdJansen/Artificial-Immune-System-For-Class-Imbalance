{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, cross_val_score, GridSearchCV, cross_validate\n",
    "\n",
    "# importing two different imputation methods that take into consideration all the features when predicting the missing values\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#multiclass imports\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.dummy import DummyClassifier #Will identify the maority calss base line, model needs to do better then the baseline\n",
    "\n",
    "from statistics import mean\n",
    "# to reduce randomness then you put the seed\n",
    "np.random.seed(42)\n",
    "\n",
    "from ArtificialImmuneSystem import *\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from tabulate import tabulate\n",
    "import time\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'Data\\hcv_data_split.csv'\n",
    "df = pd.read_csv(dataset)\n",
    "\n",
    "#df = df.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: \n",
      "(615, 14)\n",
      "\n",
      "Data size: \n",
      "8610\n",
      "\n",
      "Data ndim: \n",
      "2\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Old Class Distribution: Counter({0: 540, 1: 75})\n"
     ]
    }
   ],
   "source": [
    "print(f\"Data shape: \\n{df.shape}\\n\")\n",
    "print(f\"Data size: \\n{df.size}\\n\")\n",
    "print(f\"Data ndim: \\n{df.ndim}\\n\")\n",
    "print(\"_____________________________________________\\n\")\n",
    "print(f\"Old Class Distribution: {Counter(df['category'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "features =df.copy()\n",
    "features = features.drop(['category'],axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score1: 0.8450883057584125\n",
      "score2: 0.7762504526185973\n",
      "score1: 0.8450883057584125\n",
      "score2: 0.7946717774829228\n",
      "score1: 0.8450883057584125\n",
      "score2: 0.7658099978573666\n",
      "score1: 0.8450883057584125\n",
      "score2: 0.8452912268109068\n",
      "score1: 0.8450883057584125\n",
      "score2: 0.592952079786855\n",
      "score1: 0.8450883057584125\n",
      "score2: 0.8255155492590038\n",
      "score1: 0.8450883057584125\n",
      "score2: 0.729335473032718\n",
      "score1: 0.8450883057584125\n",
      "score2: 0.8384696664036515\n",
      "score1: 0.8450883057584125\n",
      "score2: 0.7604690648189101\n",
      "score1: 0.8450883057584125\n",
      "score2: 0.7228768341485104\n",
      "score1: 0.8450883057584125\n",
      "score2: 0.8646590842335122\n",
      "score1: 0.8646590842335122\n",
      "score2: 0.7733389625822701\n",
      "score1: 0.8646590842335122\n",
      "score2: 0.6548001344622885\n",
      "score1: 0.8646590842335122\n",
      "score2: 0.5831006289652763\n",
      "score1: 0.8646590842335122\n",
      "score2: 0.7688856670767701\n",
      "score1: 0.8646590842335122\n",
      "score2: 0.5879400555838985\n",
      "score1: 0.8646590842335122\n",
      "score2: 0.6508386788173556\n",
      "score1: 0.8646590842335122\n",
      "score2: 0.7122796570956618\n",
      "score1: 0.8646590842335122\n",
      "score2: 0.6614326420263519\n",
      "score1: 0.8646590842335122\n",
      "score2: 0.726716404408432\n",
      "score1: 0.8646590842335122\n",
      "score2: 0.8200763034752301\n",
      "score1: 0.8646590842335122\n",
      "score2: 0.7320143386965914\n",
      "score1: 0.8646590842335122\n",
      "score2: 0.7529942760700488\n",
      "score1: 0.8646590842335122\n",
      "score2: 0.7589285456041339\n",
      "score1: 0.8646590842335122\n",
      "score2: 0.7150827312933281\n",
      "score1: 0.8646590842335122\n",
      "score2: 0.6509505621322488\n",
      "score1: 0.8646590842335122\n",
      "score2: 0.7654189399349264\n",
      "score1: 0.8646590842335122\n",
      "score2: 0.5950884145315849\n",
      "score1: 0.8646590842335122\n",
      "score2: 0.6938088234835503\n",
      "score1: 0.8646590842335122\n",
      "score2: 0.7090467750941352\n",
      "score1: 0.8646590842335122\n",
      "score2: 0.750554751829891\n",
      "Best score GradientBoosting: \n",
      "0.9838175331294599\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score GradientBoosting AIS: \n",
      "0.9444444444444444\n",
      "\n",
      "Best score KNeighbors: \n",
      "0.9942235813795446\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score KNeighbors AIS: \n",
      "0.9352064220183487\n",
      "\n",
      "Best score Logistic Regression: \n",
      "0.9445506286102616\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score Logistic Regression AIS: \n",
      "0.9375212368331634\n",
      "\n",
      "Best score RandomForest: \n",
      "0.987289755351682\n",
      "\n",
      "Best score RandomForest AIS: \n",
      "0.9583333333333333\n",
      "\n",
      "score1: 0.9259504442925495\n",
      "score2: 0.8939065589299515\n",
      "score1: 0.9259504442925495\n",
      "score2: 0.8789174977828121\n",
      "score1: 0.9259504442925495\n",
      "score2: 0.9119674533033486\n",
      "score1: 0.9259504442925495\n",
      "score2: 0.8175069782467725\n",
      "score1: 0.9259504442925495\n",
      "score2: 0.7827790397293968\n",
      "score1: 0.9259504442925495\n",
      "score2: 0.8639024262893209\n",
      "score1: 0.9259504442925495\n",
      "score2: 0.7786675808408481\n",
      "score1: 0.9259504442925495\n",
      "score2: 0.7887570649561599\n",
      "score1: 0.9259504442925495\n",
      "score2: 0.9177094547740658\n",
      "score1: 0.9259504442925495\n",
      "score2: 0.7727731169938516\n",
      "score1: 0.9259504442925495\n",
      "score2: 0.848669453980724\n",
      "score1: 0.9259504442925495\n",
      "score2: 0.7638981278663605\n",
      "score1: 0.9259504442925495\n",
      "score2: 0.8652913053736502\n",
      "score1: 0.9259504442925495\n",
      "score2: 0.8600608925103268\n",
      "score1: 0.9259504442925495\n",
      "score2: 0.8553984294476831\n",
      "score1: 0.9259504442925495\n",
      "score2: 0.8136825711174831\n",
      "score1: 0.9259504442925495\n",
      "score2: 0.811176640886972\n",
      "score1: 0.9259504442925495\n",
      "score2: 0.8713349112426035\n",
      "score1: 0.9259504442925495\n",
      "score2: 0.8635459387104124\n",
      "score1: 0.9259504442925495\n",
      "score2: 0.7736716653809622\n",
      "Best score GradientBoosting: \n",
      "0.9906321636395697\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score GradientBoosting AIS: \n",
      "0.9357366425674484\n",
      "\n",
      "Best score KNeighbors: \n",
      "0.9918114089225887\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score KNeighbors AIS: \n",
      "0.9287272967730559\n",
      "\n",
      "Best score Logistic Regression: \n",
      "0.9508574325515782\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score Logistic Regression AIS: \n",
      "0.9345794392523364\n",
      "\n",
      "Best score RandomForest: \n",
      "0.9894529183565509\n",
      "\n",
      "Best score RandomForest AIS: \n",
      "0.9439031916769529\n",
      "\n",
      "score1: 0.8542908005453904\n",
      "score2: 0.8668148629910984\n",
      "score1: 0.8668148629910984\n",
      "score2: 0.7478981108621877\n",
      "score1: 0.8668148629910984\n",
      "score2: 0.8495164523878614\n",
      "score1: 0.8668148629910984\n",
      "score2: 0.7999468507045611\n",
      "score1: 0.8668148629910984\n",
      "score2: 0.8273005565724569\n",
      "score1: 0.8668148629910984\n",
      "score2: 0.8626832814226993\n",
      "score1: 0.8668148629910984\n",
      "score2: 0.8731748797542623\n",
      "score1: 0.8731748797542623\n",
      "score2: 0.7334220770147593\n",
      "score1: 0.8731748797542623\n",
      "score2: 0.7407114231346548\n",
      "score1: 0.8731748797542623\n",
      "score2: 0.7133384356759296\n",
      "score1: 0.8731748797542623\n",
      "score2: 0.6453280270466945\n",
      "score1: 0.8731748797542623\n",
      "score2: 0.6576607085847411\n",
      "score1: 0.8731748797542623\n",
      "score2: 0.6599766456284797\n",
      "score1: 0.8731748797542623\n",
      "score2: 0.6421545701161857\n",
      "score1: 0.8731748797542623\n",
      "score2: 0.6875744336565085\n",
      "score1: 0.8731748797542623\n",
      "score2: 0.7359156251209752\n",
      "score1: 0.8731748797542623\n",
      "score2: 0.7279788122530338\n",
      "score1: 0.8731748797542623\n",
      "score2: 0.6673230217639302\n",
      "score1: 0.8731748797542623\n",
      "score2: 0.7049005161505162\n",
      "score1: 0.8731748797542623\n",
      "score2: 0.6891121174606479\n",
      "score1: 0.8731748797542623\n",
      "score2: 0.6706552795590786\n",
      "score1: 0.8731748797542623\n",
      "score2: 0.7092273554013216\n",
      "score1: 0.8731748797542623\n",
      "score2: 0.737556808125199\n",
      "score1: 0.8731748797542623\n",
      "score2: 0.5600898798707109\n",
      "score1: 0.8731748797542623\n",
      "score2: 0.6746280253023949\n",
      "score1: 0.8731748797542623\n",
      "score2: 0.7142819317937897\n",
      "score1: 0.8731748797542623\n",
      "score2: 0.5962043014489771\n",
      "Best score GradientBoosting: \n",
      "0.9884577811756711\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score GradientBoosting AIS: \n",
      "0.9479272850832483\n",
      "\n",
      "Best score KNeighbors: \n",
      "0.9930874108053007\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score KNeighbors AIS: \n",
      "0.9282725959904858\n",
      "\n",
      "Best score Logistic Regression: \n",
      "0.9400165647298675\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score Logistic Regression AIS: \n",
      "0.9341976724430854\n",
      "\n",
      "Best score RandomForest: \n",
      "0.9896045701664968\n",
      "\n",
      "Best score RandomForest AIS: \n",
      "0.9572290180088344\n",
      "\n",
      "score1: 0.9058817184634936\n",
      "score2: 0.8115003955757155\n",
      "score1: 0.9058817184634936\n",
      "score2: 0.9030735554149836\n",
      "score1: 0.9058817184634936\n",
      "score2: 0.8633925082533107\n",
      "score1: 0.9058817184634936\n",
      "score2: 0.9076773372096951\n",
      "score1: 0.9076773372096951\n",
      "score2: 0.823131038503315\n",
      "score1: 0.9076773372096951\n",
      "score2: 0.6890388636776963\n",
      "score1: 0.9076773372096951\n",
      "score2: 0.7469544892475504\n",
      "score1: 0.9076773372096951\n",
      "score2: 0.7516792445194633\n",
      "score1: 0.9076773372096951\n",
      "score2: 0.7759242688206103\n",
      "score1: 0.9076773372096951\n",
      "score2: 0.8672047412562233\n",
      "score1: 0.9076773372096951\n",
      "score2: 0.590835276913975\n",
      "score1: 0.9076773372096951\n",
      "score2: 0.7619992767924899\n",
      "score1: 0.9076773372096951\n",
      "score2: 0.6782678832093609\n",
      "score1: 0.9076773372096951\n",
      "score2: 0.6631809566224753\n",
      "score1: 0.9076773372096951\n",
      "score2: 0.7118490952859514\n",
      "score1: 0.9076773372096951\n",
      "score2: 0.7149283380608682\n",
      "score1: 0.9076773372096951\n",
      "score2: 0.8480747087334246\n",
      "score1: 0.9076773372096951\n",
      "score2: 0.7238973689632878\n",
      "score1: 0.9076773372096951\n",
      "score2: 0.8190747566733492\n",
      "score1: 0.9076773372096951\n",
      "score2: 0.7859888010125581\n",
      "score1: 0.9076773372096951\n",
      "score2: 0.8056380659072069\n",
      "score1: 0.9076773372096951\n",
      "score2: 0.7449258641319633\n",
      "score1: 0.9076773372096951\n",
      "score2: 0.7254604561486051\n",
      "score1: 0.9076773372096951\n",
      "score2: 0.6652959578594021\n",
      "Best score GradientBoosting: \n",
      "0.9919193849813115\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score GradientBoosting AIS: \n",
      "0.9525675331294597\n",
      "\n",
      "Best score KNeighbors: \n",
      "0.9953916072035338\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score KNeighbors AIS: \n",
      "0.9386786442405708\n",
      "\n",
      "Best score Logistic Regression: \n",
      "0.9723496432212029\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score Logistic Regression AIS: \n",
      "0.9387104994903159\n",
      "\n",
      "Best score RandomForest: \n",
      "0.9919300033978933\n",
      "\n",
      "Best score RandomForest AIS: \n",
      "0.9618374108053007\n",
      "\n",
      "score1: 0.8668824841208556\n",
      "score2: 0.8581751863767224\n",
      "score1: 0.8668824841208556\n",
      "score2: 0.7827931651293575\n",
      "score1: 0.8668824841208556\n",
      "score2: 0.8965815794238111\n",
      "score1: 0.8965815794238111\n",
      "score2: 0.7263915186899196\n",
      "score1: 0.8965815794238111\n",
      "score2: 0.5340041532555965\n",
      "score1: 0.8965815794238111\n",
      "score2: 0.7028737287217\n",
      "score1: 0.8965815794238111\n",
      "score2: 0.7711672839505697\n",
      "score1: 0.8965815794238111\n",
      "score2: 0.7950139341143518\n",
      "score1: 0.8965815794238111\n",
      "score2: 0.7662344436490685\n",
      "score1: 0.8965815794238111\n",
      "score2: 0.7311989404084767\n",
      "score1: 0.8965815794238111\n",
      "score2: 0.714013782945998\n",
      "score1: 0.8965815794238111\n",
      "score2: 0.7198491243230458\n",
      "score1: 0.8965815794238111\n",
      "score2: 0.7050618350106841\n",
      "score1: 0.8965815794238111\n",
      "score2: 0.7771780820443204\n",
      "score1: 0.8965815794238111\n",
      "score2: 0.7273953414707811\n",
      "score1: 0.8965815794238111\n",
      "score2: 0.8002886500637476\n",
      "score1: 0.8965815794238111\n",
      "score2: 0.7249897493587126\n",
      "score1: 0.8965815794238111\n",
      "score2: 0.7802414861327176\n",
      "score1: 0.8965815794238111\n",
      "score2: 0.793322422855975\n",
      "score1: 0.8965815794238111\n",
      "score2: 0.6298122189370724\n",
      "score1: 0.8965815794238111\n",
      "score2: 0.7263977281606501\n",
      "score1: 0.8965815794238111\n",
      "score2: 0.7444390730179448\n",
      "score1: 0.8965815794238111\n",
      "score2: 0.7211458021943955\n",
      "Best score GradientBoosting: \n",
      "0.9895833333333333\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score GradientBoosting AIS: \n",
      "0.9444444444444444\n",
      "\n",
      "Best score KNeighbors: \n",
      "0.9907407407407408\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score KNeighbors AIS: \n",
      "0.9270833333333334\n",
      "\n",
      "Best score Logistic Regression: \n",
      "0.9548611111111112\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score Logistic Regression AIS: \n",
      "0.9386574074074074\n",
      "\n",
      "Best score RandomForest: \n",
      "0.9907407407407407\n",
      "\n",
      "Best score RandomForest AIS: \n",
      "0.9502314814814814\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "dataAIS = []\n",
    "dataSMOTE = []\n",
    "dataBase = []\n",
    "data = []\n",
    "fold = 0\n",
    "\n",
    "for result in kf.split(df):\n",
    "    fold = fold+1\n",
    "\n",
    "    #Print the shape of the train and test set\n",
    "    data_train = df.iloc[result[0]]\n",
    "    data_test =  df.iloc[result[1]]\n",
    "\n",
    "    label_train = data_train.copy()\n",
    "    label_train = label_train.drop(['Age','Sex','ALB','ALP','ALT','AST','BIL','CHE','CHOL','CREA','GGT','PROT','split'],axis=1) #Drop all except category for the train df\n",
    " \n",
    "    label_test = data_test.copy()\n",
    "    label_test = label_test.drop(['Age','Sex','ALB','ALP','ALT','AST','BIL','CHE','CHOL','CREA','GGT','PROT','split'],axis=1) #Drop all except category for the train df\n",
    "   \n",
    "    train_df = data_train.copy()\n",
    "    train_df = train_df.drop(['category'],axis=1)\n",
    "    numerical_attribute_train = train_df.drop(['split','Sex'],axis=1)\n",
    "    \n",
    "    num_pipeline = Pipeline([\n",
    "        ('imputer', KNNImputer(n_neighbors=5)),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "    num_attribs = list(numerical_attribute_train)\n",
    "    cat_attribs = [\"Sex\"]\n",
    "\n",
    "    full_pipeline = ColumnTransformer([\n",
    "        (\"num\", num_pipeline, num_attribs),\n",
    "        (\"cat\", OneHotEncoder(), cat_attribs),\n",
    "    ])\n",
    "\n",
    "\n",
    "    data_prepared_train = pd.DataFrame(full_pipeline.fit_transform(train_df),columns=train_df.columns, index=train_df.index)\n",
    "    rejoin_train = pd.concat([data_prepared_train,label_train],axis=1)\n",
    "\n",
    "    test_df = data_test.drop(['category'],axis=1) #We chose KNN for the actual impuation\n",
    "    num_pipeline_test = Pipeline([\n",
    "        ('imputer', KNNImputer(n_neighbors=5)),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "    cat_attribs_test = ['split',\"Sex\"]\n",
    "    numerical_attr_test = test_df.drop(['Sex'],axis=1)\n",
    "    numerical_attr_test = list(numerical_attr_test)\n",
    "\n",
    "    full_pipeline_test = ColumnTransformer([\n",
    "        (\"num\", num_pipeline_test, numerical_attr_test),\n",
    "        (\"cat\", OneHotEncoder(), cat_attribs_test),\n",
    "    ])\n",
    "\n",
    "    data_prepared_test = pd.DataFrame(full_pipeline.fit_transform(test_df),columns=test_df.columns, index=test_df.index)\n",
    "    rejoin_test = pd.concat([data_prepared_test,label_test],axis=1)\n",
    "   \n",
    "    \n",
    "    data_train_AIS = rejoin_train.copy()\n",
    "    data_train_SMOTE = rejoin_train.copy()\n",
    "\n",
    "    data_train_AIS = data_train_AIS.drop(['split'],axis=1)\n",
    "    data_train_SMOTE = data_train_SMOTE.drop(['split'],axis=1)\n",
    "\n",
    "    data_train = rejoin_train.copy()\n",
    "    data_test = rejoin_test.copy()\n",
    "\n",
    "    data_train = data_train.drop(['split'],axis=1)\n",
    "    data_test = data_test.drop(['split'],axis=1)\n",
    "    #Create an oversampling object\n",
    "   \n",
    "    oversample = SMOTE()\n",
    "    \n",
    "\n",
    "\n",
    "    oversample_AIS = ArtificialImmuneSystem()\n",
    "    #Oversample and add to the dataframe to fix the class imbalance\n",
    "    logisticRegression = LogisticRegression()\n",
    "    st = time.time()\n",
    "    x_over, y_over = oversample.fit_resample(data_train_SMOTE.drop([\"category\"], axis=1), data_train_SMOTE.drop(data_train_SMOTE.columns[0:-1],axis=1))\n",
    "    elapsed_time_SMOTE = time.time() - st\n",
    "\n",
    "    st = time.time()\n",
    "    input_x_over_AIS, y_over_AIS = oversample_AIS.AIS_Resample(data_train_AIS.drop([\"category\"], axis=1), data_train_AIS.drop(data_train_AIS.columns[0:-1],axis=1), max_rounds = 100, stopping_cond = 20, model = logisticRegression,K_folds = 5,scorer = 'f1',min_change = 0.001, use_lof = False)\n",
    "    elapsed_time_AIS = time.time() - st\n",
    "\n",
    "    smote_df = pd.concat([x_over, y_over], axis=1)\n",
    "    ais_df = pd.concat([input_x_over_AIS, y_over_AIS], axis=1)\n",
    "\n",
    "    # print the dimensionality of the oversampled dataset\n",
    "    #print(f\"SMOTE Oversampled Data shape: \\n{smote_df.shape}\\n\")\n",
    "    #print(f\"SMOTE Oversampled Data size: \\n{smote_df.size}\\n\")\n",
    "    #print(f\"SMOTE Oversampled Data ndim: \\n{smote_df.ndim}\\n\")\n",
    "    #print(\"_____________________________________________\\n\")\n",
    "\n",
    "    # print the dimensionality of the oversampled dataset\n",
    "    #print(f\"AIS Oversampled Data shape: \\n{ais_df.shape}\\n\")\n",
    "    #print(f\"AIS Oversampled Data size: \\n{ais_df.size}\\n\")\n",
    "    #print(f\"AIS Oversampled Data ndim: \\n{ais_df.ndim}\\n\")\n",
    "    #print(\"_____________________________________________\\n\")\n",
    "\n",
    "\n",
    "    # print the new class distribution using a Counter\n",
    "    #print(f\"New SMOTE Class Distribution: {Counter(smote_df['5'])}\")\n",
    "    #print(f\"New AIS Class Distribution: {Counter(ais_df['5'])}\")\n",
    "    ## print the new class distribution using a Counter\n",
    "    #print(f\"Old Class Distribution: {Counter(data_train['5'])}\")\n",
    "\n",
    "    #print(\"_____________________________________________\\n\")\n",
    "\n",
    "    #labelTrainFlat = labels_train.values.ravel()\n",
    "\n",
    "    #Fit one vs rest Gradient Boosting classification\n",
    "    gradientBoosting = GradientBoostingClassifier()\n",
    "    gradientBoosting = gradientBoosting.fit(x_over, y_over.values.ravel())\n",
    "\n",
    "    gradientBoosting_AIS = GradientBoostingClassifier()\n",
    "    gradientBoosting_AIS = gradientBoosting.fit(input_x_over_AIS, y_over_AIS.values.ravel())\n",
    "\n",
    "    gradientBoosting_Base = gradientBoosting.fit(data_train.drop([\"category\"], axis=1), data_train.drop(data_train.columns[0:-1],axis=1).values.ravel())\n",
    "\n",
    "    #Fit RandomForestClassifier classification\n",
    "    randomForest = RandomForestClassifier()\n",
    "    randomForest = randomForest.fit(x_over,y_over.values.ravel())\n",
    "\n",
    "    randomForest = RandomForestClassifier()\n",
    "    randomForest_AIS  = randomForest.fit(input_x_over_AIS,y_over_AIS.values.ravel())\n",
    "\n",
    "    randomForest_Base = randomForest.fit(data_train.drop([\"category\"], axis=1), data_train.drop(data_train.columns[0:-1],axis=1).values.ravel())\n",
    "    #randomForest_Base  = randomForest.fit(data_train.drop([\"5\"], axis=1), data_train.drop(data_train_AIS.columns[0:-1]).values.ravel())\n",
    "\n",
    "    #Create a KNeighbors classification object\n",
    "    kNeighbors = KNeighborsClassifier()\n",
    "    kNeighbors = kNeighbors.fit(x_over,y_over.values.ravel())\n",
    "\n",
    "    kNeighbors = KNeighborsClassifier()\n",
    "    kNeighbors_AIS  = kNeighbors.fit(input_x_over_AIS,y_over_AIS.values.ravel())\n",
    "    kNeighbors_Base = kNeighbors.fit(data_train.drop([\"category\"], axis=1), data_train.drop(data_train.columns[0:-1],axis=1).values.ravel())\n",
    "    #kNeighbors_base  = kNeighbors.fit(data_train.drop([\"5\"], axis=1), data_train.drop(data_train_AIS.columns[0:-1]).values.ravel())\n",
    "\n",
    "    #Create an LogisticRegression object\n",
    "    logisticRegression = LogisticRegression(max_iter=5000)\n",
    "    logisticRegression = logisticRegression.fit(x_over,y_over.values.ravel())\n",
    "\n",
    "    logisticRegression = LogisticRegression(max_iter=5000)\n",
    "    logisticRegression_AIS  = logisticRegression.fit(input_x_over_AIS,y_over_AIS.values.ravel())\n",
    "    logisticRegression_Base = logisticRegression.fit(data_train.drop([\"category\"], axis=1), data_train.drop(data_train.columns[0:-1],axis=1).values.ravel())\n",
    "    #logisticRegression_Base  = logisticRegression.fit(data_train.drop([\"5\"], axis=1), data_train.drop(data_train_AIS.columns[0:-1]).values.ravel())\n",
    "\n",
    "    #Set the parameters of GradientBoosting for GridSearchCV\n",
    "    parametersGradientBoosting = [\n",
    "        {'learning_rate': [0.44,0.45,0.46],'min_samples_leaf': [5,6,7],'min_samples_split': [7,8,9,10], 'n_estimators': [57,58,59,60]}\n",
    "    ]\n",
    "\n",
    "    #Set the scoring parameters\n",
    "    scoringX = {\"roc_auc\": \"roc_auc\", \"bal_accuracy\": \"balanced_accuracy\"}\n",
    "\n",
    "    #Preform Gridsearch to find best parameters\n",
    "    grid_searchGradientBoosting = GridSearchCV(gradientBoosting, parametersGradientBoosting, cv=4, scoring = scoringX, return_train_score=True, n_jobs=-1, refit='bal_accuracy')\n",
    "    grid_searchGradientBoosting_AIS = GridSearchCV(gradientBoosting_AIS, parametersGradientBoosting, cv=4, scoring = scoringX, return_train_score=True, n_jobs=-1, refit='bal_accuracy')\n",
    "    #grid_searchGradientBoosting_Base = GridSearchCV(gradientBoosting_Base, parametersGradientBoosting, cv=4, scoring = scoringX, return_train_score=True, n_jobs=-1, refit='bal_accuracy')\n",
    "    #Fit the GradientBoosting \n",
    "    grid_searchGradientBoosting.fit(x_over, y_over.values.ravel())\n",
    "    grid_searchGradientBoosting_AIS.fit(input_x_over_AIS,y_over_AIS.values.ravel())\n",
    "  \n",
    "    \n",
    "\n",
    "    #Print GridSearchCV Results\n",
    "    \n",
    "    print(f\"Best score GradientBoosting: \\n{grid_searchGradientBoosting.best_score_}\\n\")\n",
    "    print(\"_____________________________________________\\n\")\n",
    "    \n",
    "    print(f\"Best score GradientBoosting AIS: \\n{grid_searchGradientBoosting_AIS.best_score_}\\n\")\n",
    "\n",
    "    #Set the parameters of KNeighbors for GridSearchCV\n",
    "    parametersKNeighbors = [\n",
    "        {'n_neighbors': [1,2,3],'weights':['uniform', 'distance'],'algorithm':['auto'], 'p': [1,2,3]}\n",
    "    ]\n",
    "\n",
    "    #Set the scoring parameters\n",
    "    scoringX = {\"roc_auc\": \"roc_auc\", \"bal_accuracy\": \"balanced_accuracy\"}\n",
    "\n",
    "    #Preform KNeighbors to find best parameters\n",
    "    grid_searchKNeighbors = GridSearchCV(kNeighbors, parametersKNeighbors, cv=4, scoring = scoringX, return_train_score=True, n_jobs=-1, refit='bal_accuracy')\n",
    "    grid_searchKNeighbors_AIS = GridSearchCV(kNeighbors_AIS, parametersKNeighbors, cv=4, scoring = scoringX, return_train_score=True, n_jobs=-1, refit='bal_accuracy')\n",
    "\n",
    "    #Fit the KNeighbors \n",
    "    grid_searchKNeighbors.fit(x_over, y_over.values.ravel())\n",
    "    grid_searchKNeighbors_AIS.fit(input_x_over_AIS,y_over_AIS.values.ravel())\n",
    "\n",
    "    #Print GridSearchCV Results\n",
    "   \n",
    "    print(f\"Best score KNeighbors: \\n{grid_searchKNeighbors.best_score_}\\n\")\n",
    "    print(\"_____________________________________________\\n\")\n",
    "   \n",
    "    print(f\"Best score KNeighbors AIS: \\n{grid_searchKNeighbors_AIS.best_score_}\\n\")\n",
    "    \n",
    "    #Set the parameters of LogisticRegression for GridSearchCV\n",
    "    parametersLogisticRegression = [\n",
    "        {'multi_class': ['ovr'],'penalty':['none','l2'], 'C': [1,2,3]}\n",
    "    ]\n",
    "    scoringX = {\"roc_auc\": \"roc_auc\", \"bal_accuracy\": \"balanced_accuracy\"}\n",
    "\n",
    "    #Preform LogisticRegression to find best parameters\n",
    "    grid_searchLogisticRegression = GridSearchCV(logisticRegression, parametersLogisticRegression, cv=4, scoring = scoringX, return_train_score=True, n_jobs=-1, refit='bal_accuracy')\n",
    "    grid_searchLogisticRegression_AIS = GridSearchCV(logisticRegression_AIS, parametersLogisticRegression, cv=4, scoring = scoringX, return_train_score=True, n_jobs=-1, refit='bal_accuracy')\n",
    "\n",
    "    #Fit the LogisticRegression \n",
    "    grid_searchLogisticRegression.fit(x_over, y_over.values.ravel())\n",
    "    grid_searchLogisticRegression_AIS.fit(input_x_over_AIS,y_over_AIS.values.ravel())\n",
    "\n",
    "    #Print LogisticRegression Results\n",
    "    \n",
    "    print(f\"Best score Logistic Regression: \\n{grid_searchLogisticRegression.best_score_}\\n\")\n",
    "    print(\"_____________________________________________\\n\")\n",
    "   \n",
    "    print(f\"Best score Logistic Regression AIS: \\n{grid_searchLogisticRegression_AIS.best_score_}\\n\")\n",
    "\n",
    "    #Set the parameters of RandomForest for GridSearchCV\n",
    "    parametersRandomForest = [\n",
    "        {'n_estimators': [145,150,155,190],'max_depth': [10,12], 'bootstrap': [True, False],\n",
    "        'min_samples_split': [0.05,2], 'max_features': ['auto']}\n",
    "    ]\n",
    "\n",
    "    #Preform Gridsearch to find best parameters\n",
    "    grid_searchRandomForest = GridSearchCV(randomForest, parametersRandomForest, cv=4, scoring = scoringX, return_train_score=True, n_jobs=-1, refit='bal_accuracy')\n",
    "    grid_searchRandomForest_AIS = GridSearchCV(randomForest_AIS, parametersRandomForest, cv=4, scoring = scoringX, return_train_score=True, n_jobs=-1, refit='bal_accuracy')\n",
    "\n",
    "    #Fit the RandomForest \n",
    "    grid_searchRandomForest.fit(x_over, y_over.values.ravel())\n",
    "    grid_searchRandomForest_AIS.fit(input_x_over_AIS,y_over_AIS.values.ravel())\n",
    "\n",
    "    #Print GridSearchCV Results\n",
    "\n",
    "    print(f\"Best score RandomForest: \\n{grid_searchRandomForest.best_score_}\\n\")\n",
    "\n",
    "    print(f\"Best score RandomForest AIS: \\n{grid_searchRandomForest_AIS.best_score_}\\n\")\n",
    "\n",
    "    #Get the results for all classifiers \n",
    "    cross_val_resultsGB = grid_searchGradientBoosting.cv_results_\n",
    "    cross_val_resultsRF = grid_searchRandomForest.cv_results_\n",
    "    cross_val_resultsLR = grid_searchLogisticRegression.cv_results_\n",
    "    cross_val_resultsKN = grid_searchKNeighbors.cv_results_\n",
    "\n",
    "    cross_val_resultsGB_AIS = grid_searchGradientBoosting_AIS.cv_results_\n",
    "    cross_val_resultsRF_AIS = grid_searchRandomForest_AIS.cv_results_\n",
    "    cross_val_resultsLR_AIS = grid_searchLogisticRegression_AIS.cv_results_\n",
    "    cross_val_resultsKN_AIS = grid_searchKNeighbors_AIS.cv_results_\n",
    "\n",
    "\n",
    "    #Print the results of all classiifiers\n",
    "    #GBC\n",
    "    mean_test_roc_aucGB = mean(cross_val_resultsGB['mean_test_roc_auc'])\n",
    "    mean_test_bal_accuracyGB = mean(cross_val_resultsGB['mean_test_bal_accuracy'])\n",
    "    \n",
    "    mean_test_roc_aucGB_AIS = mean(cross_val_resultsGB_AIS['mean_test_roc_auc'])\n",
    "    mean_test_bal_accuracyGB_AIS = mean(cross_val_resultsGB_AIS['mean_test_bal_accuracy'])\n",
    "   \n",
    "    #RFC\n",
    "    mean_test_roc_aucRF = mean(cross_val_resultsRF['mean_test_roc_auc'])\n",
    "    mean_test_bal_accuracyRF = mean(cross_val_resultsRF['mean_test_bal_accuracy'])\n",
    "    \n",
    "    mean_test_roc_aucRF_AIS = mean(cross_val_resultsRF_AIS['mean_test_roc_auc'])\n",
    "    mean_test_bal_accuracyRF_AIS = mean(cross_val_resultsRF_AIS['mean_test_bal_accuracy'])\n",
    "    #LRC\n",
    "    mean_test_roc_aucLR = mean(cross_val_resultsLR['mean_test_roc_auc'])\n",
    "    mean_test_bal_accuracyLR = mean(cross_val_resultsLR['mean_test_bal_accuracy'])\n",
    "    \n",
    "    mean_test_roc_aucLR_AIS = mean(cross_val_resultsLR_AIS['mean_test_roc_auc'])\n",
    "    mean_test_bal_accuracyLR_AIS = mean(cross_val_resultsLR_AIS['mean_test_bal_accuracy'])\n",
    "\n",
    "    #KNC\n",
    "    mean_test_roc_aucKN = mean(cross_val_resultsKN['mean_test_roc_auc'])\n",
    "    mean_test_bal_accuracyKN = mean(cross_val_resultsKN['mean_test_bal_accuracy'])\n",
    "    \n",
    "    mean_test_roc_aucKN_AIS = mean(cross_val_resultsKN_AIS['mean_test_roc_auc'])\n",
    "    mean_test_bal_accuracyKN_AIS = mean(cross_val_resultsKN_AIS['mean_test_bal_accuracy'])\n",
    "\n",
    "    predictions_test_over_GB = grid_searchGradientBoosting.best_estimator_.predict(data_test.drop([\"category\"],axis=1))\n",
    "    predictions_test_over_RF = grid_searchRandomForest.best_estimator_.predict(data_test.drop([\"category\"],axis=1))\n",
    "    predictions_test_over_LR = grid_searchLogisticRegression.best_estimator_.predict(data_test.drop([\"category\"],axis=1))\n",
    "    predictions_test_over_KN = grid_searchKNeighbors.best_estimator_.predict(data_test.drop([\"category\"],axis=1))\n",
    "\n",
    "    predictions_test_over_GB_AIS = grid_searchGradientBoosting_AIS.best_estimator_.predict(data_test.drop([\"category\"],axis=1))\n",
    "    predictions_test_over_RF_AIS = grid_searchRandomForest_AIS.best_estimator_.predict(data_test.drop([\"category\"],axis=1))\n",
    "    predictions_test_over_LR_AIS = grid_searchLogisticRegression_AIS.best_estimator_.predict(data_test.drop([\"category\"],axis=1))\n",
    "    predictions_test_over_KN_AIS = grid_searchKNeighbors_AIS.best_estimator_.predict(data_test.drop([\"category\"],axis=1))\n",
    "\n",
    "    predictions_GB = gradientBoosting_Base.predict(data_test.drop([\"category\"],axis=1))\n",
    "    predictions_RF = randomForest_Base.predict(data_test.drop([\"category\"],axis=1))\n",
    "    predictions_LR = logisticRegression_Base.predict(data_test.drop([\"category\"],axis=1))\n",
    "    predictions_KN = kNeighbors_Base.predict(data_test.drop([\"category\"],axis=1))\n",
    "\n",
    "    f1_score_GB = f1_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_GB)\n",
    "    f1_score_RF = f1_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_RF)\n",
    "    f1_score_LR = f1_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_LR)\n",
    "    f1_score_KN = f1_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_KN)\n",
    "\n",
    "    f1_score_GB_AIS = f1_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_GB_AIS) \n",
    "    f1_score_RF_AIS = f1_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_RF_AIS)\n",
    "    f1_score_LR_AIS = f1_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_LR_AIS)\n",
    "    f1_score_KN_AIS = f1_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_KN_AIS)\n",
    "\n",
    "    f1_score_GB_Base = f1_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_GB)\n",
    "    f1_score_RF_Base = f1_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_RF)\n",
    "    f1_score_LR_Base = f1_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_LR)\n",
    "    f1_score_KN_Base = f1_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_KN)\n",
    "\n",
    "    geometric_mean_score_GB = geometric_mean_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_GB, labels=None, pos_label=1, average='binary',)\n",
    "    geometric_mean_score_RF = geometric_mean_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_RF, labels=None, pos_label=1, average='binary',)\n",
    "    geometric_mean_score_LR = geometric_mean_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_LR, labels=None, pos_label=1, average='binary',)\n",
    "    geometric_mean_score_KN = geometric_mean_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_KN, labels=None, pos_label=1, average='binary',)\n",
    "\n",
    "    geometric_mean_score_GB_AIS = geometric_mean_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_GB_AIS, labels=None, pos_label=1, average='binary',)\n",
    "    geometric_mean_score_RF_AIS = geometric_mean_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_RF_AIS, labels=None, pos_label=1, average='binary',)\n",
    "    geometric_mean_score_LR_AIS = geometric_mean_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_LR_AIS, labels=None, pos_label=1, average='binary',)\n",
    "    geometric_mean_score_KN_AIS = geometric_mean_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_KN_AIS, labels=None, pos_label=1, average='binary',)\n",
    "\n",
    "    geometric_mean_score_GB_Base = geometric_mean_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_GB, labels=None, pos_label=1, average='binary',)\n",
    "    geometric_mean_score_RF_Base = geometric_mean_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_RF, labels=None, pos_label=1, average='binary',)\n",
    "    geometric_mean_score_LR_Base = geometric_mean_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_LR, labels=None, pos_label=1, average='binary',)\n",
    "    geometric_mean_score_KN_Base = geometric_mean_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_KN, labels=None, pos_label=1, average='binary',)\n",
    "\n",
    "    \n",
    "    roc_auc_GB_AIS = roc_auc_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_GB_AIS)\n",
    "    roc_auc_RF_AIS = roc_auc_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_RF_AIS)\n",
    "    roc_auc_LR_AIS = roc_auc_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_LR_AIS)\n",
    "    roc_auc_KN_AIS = roc_auc_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_KN_AIS)\n",
    " \n",
    "    roc_auc_GB_Base = roc_auc_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_GB)\n",
    "    roc_auc_RF_Base = roc_auc_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_RF)\n",
    "    roc_auc_LR_Base = roc_auc_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_LR)\n",
    "    roc_auc_KN_Base = roc_auc_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_KN)\n",
    "\n",
    "    roc_auc_GB = roc_auc_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_GB)\n",
    "    roc_auc_RF = roc_auc_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_RF)\n",
    "    roc_auc_LR = roc_auc_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_LR)\n",
    "    roc_auc_KN = roc_auc_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_KN)\n",
    "\n",
    "    \n",
    "\n",
    "    balanced_acc_GB_AIS = balanced_accuracy_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_GB_AIS)\n",
    "    balanced_acc_RF_AIS = balanced_accuracy_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_RF_AIS)\n",
    "    balanced_acc_LR_AIS = balanced_accuracy_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_LR_AIS)\n",
    "    balanced_acc_KN_AIS = balanced_accuracy_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_KN_AIS)\n",
    " \n",
    "    balanced_acc_GB = balanced_accuracy_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_GB)\n",
    "    balanced_acc_RF = balanced_accuracy_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_RF)\n",
    "    balanced_acc_LR = balanced_accuracy_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_LR)\n",
    "    balanced_acc_KN = balanced_accuracy_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_KN)\n",
    "\n",
    "    \n",
    "    balanced_acc_GB_Base = balanced_accuracy_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_GB)\n",
    "    balanced_acc_RF_Base = balanced_accuracy_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_RF)\n",
    "    balanced_acc_LR_Base = balanced_accuracy_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_LR)\n",
    "    balanced_acc_KN_Base = balanced_accuracy_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_KN)\n",
    "\n",
    "    \n",
    "    dataAIS.append( [fold,dataset,\"AIS\", elapsed_time_AIS,\" max_rounds = 100, stopping_cond = 20, model = logisticRegression,K_folds = 5,scorer = 'f1',min_change = 0.001, use_lof = False\", roc_auc_GB_AIS, roc_auc_RF_AIS, roc_auc_LR_AIS, roc_auc_KN_AIS, balanced_acc_GB_AIS, balanced_acc_RF_AIS,  balanced_acc_LR_AIS,  balanced_acc_KN_AIS, geometric_mean_score_GB_AIS, geometric_mean_score_RF_AIS, geometric_mean_score_LR_AIS, geometric_mean_score_KN_AIS,f1_score_GB_AIS,f1_score_RF_AIS,f1_score_LR_AIS,f1_score_KN_AIS ])\n",
    "    dataSMOTE.append([fold,dataset,\"SMOTE\", elapsed_time_SMOTE,\"NA\", roc_auc_GB,  roc_auc_RF, roc_auc_LR,roc_auc_KN, balanced_acc_GB, balanced_acc_RF,  balanced_acc_LR,  balanced_acc_KN, geometric_mean_score_GB, geometric_mean_score_RF, geometric_mean_score_LR, geometric_mean_score_KN,f1_score_GB,f1_score_RF,f1_score_LR,f1_score_KN])\n",
    "    dataBase.append([fold,dataset,\"BASE\", \"NA\",\"NA\", roc_auc_GB_Base, roc_auc_RF_Base, roc_auc_LR_Base, roc_auc_KN_Base, balanced_acc_GB_Base, balanced_acc_RF_Base,balanced_acc_LR_Base,  balanced_acc_KN_Base, geometric_mean_score_GB_Base, geometric_mean_score_RF_Base, geometric_mean_score_LR_Base, geometric_mean_score_KN_Base,f1_score_GB_Base,f1_score_RF_Base,f1_score_LR_Base,f1_score_KN_Base])\n",
    "    data.append(dataAIS[fold-1])\n",
    "    data.append(dataSMOTE[fold-1])\n",
    "    data.append(dataBase[fold-1])\n",
    "    data.append([\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"])\n",
    "\n",
    "average_AIS_Runtime = 0\n",
    "\n",
    "average_roc_auc_GB_AIS = 0\n",
    "average_roc_auc_RF_AIS = 0\n",
    "average_roc_auc_LR_AIS = 0\n",
    "average_roc_auc_KN_AIS = 0\n",
    "\n",
    "average_balanced_acc_GB_AIS = 0\n",
    "average_balanced_acc_RF_AIS = 0\n",
    "average_balanced_acc_LR_AIS = 0\n",
    "average_balanced_acc_KN_AIS = 0\n",
    "\n",
    "average_geometric_mean_score_GB_AIS = 0\n",
    "average_geometric_mean_score_RF_AIS = 0\n",
    "average_geometric_mean_score_LR_AIS = 0\n",
    "average_geometric_mean_score_KN_AIS = 0\n",
    "    \n",
    "average_f1_score_GB_AIS = 0\n",
    "average_f1_score_RF_AIS = 0\n",
    "average_f1_score_LR_AIS = 0\n",
    "average_f1_score_KN_AIS = 0\n",
    "\n",
    "\n",
    "average_SMOTE_Runtime = 0\n",
    "\n",
    "average_roc_auc_GB = 0\n",
    "average_roc_auc_RF = 0\n",
    "average_roc_auc_LR = 0\n",
    "average_roc_auc_KN = 0\n",
    "\n",
    "average_balanced_acc_GB = 0\n",
    "average_balanced_acc_RF = 0\n",
    "average_balanced_acc_LR = 0\n",
    "average_balanced_acc_KN = 0\n",
    "\n",
    "average_geometric_mean_score_GB = 0\n",
    "average_geometric_mean_score_RF = 0\n",
    "average_geometric_mean_score_LR = 0\n",
    "average_geometric_mean_score_KN = 0\n",
    "    \n",
    "average_f1_score_GB = 0\n",
    "average_f1_score_RF = 0\n",
    "average_f1_score_LR = 0\n",
    "average_f1_score_KN = 0\n",
    "\n",
    "average_roc_auc_GB_Base = 0\n",
    "average_roc_auc_RF_Base = 0\n",
    "average_roc_auc_LR_Base = 0\n",
    "average_roc_auc_KN_Base = 0\n",
    "\n",
    "average_balanced_acc_GB_Base = 0\n",
    "average_balanced_acc_RF_Base = 0\n",
    "average_balanced_acc_LR_Base = 0\n",
    "average_balanced_acc_KN_Base = 0\n",
    "\n",
    "average_geometric_mean_score_GB_Base = 0\n",
    "average_geometric_mean_score_RF_Base = 0\n",
    "average_geometric_mean_score_LR_Base = 0\n",
    "average_geometric_mean_score_KN_Base = 0\n",
    "    \n",
    "average_f1_score_GB_Base = 0\n",
    "average_f1_score_RF_Base = 0\n",
    "average_f1_score_LR_Base = 0\n",
    "average_f1_score_KN_Base = 0\n",
    "\n",
    "for array in dataAIS:\n",
    "\n",
    "    average_AIS_Runtime = average_AIS_Runtime + array[3]\n",
    "\n",
    "    average_roc_auc_GB_AIS = average_roc_auc_GB_AIS + array[5]\n",
    "    average_roc_auc_RF_AIS = average_roc_auc_RF_AIS + array[6]\n",
    "    average_roc_auc_LR_AIS = average_roc_auc_LR_AIS + array[7]\n",
    "    average_roc_auc_KN_AIS = average_roc_auc_KN_AIS + array[8]\n",
    "\n",
    "    average_balanced_acc_GB_AIS = average_balanced_acc_GB_AIS + array[9]\n",
    "    average_balanced_acc_RF_AIS = average_balanced_acc_RF_AIS + array[10]\n",
    "    average_balanced_acc_LR_AIS = average_balanced_acc_LR_AIS + array[11]\n",
    "    average_balanced_acc_KN_AIS = average_balanced_acc_KN_AIS + array[12]\n",
    "\n",
    "    average_geometric_mean_score_GB_AIS = average_geometric_mean_score_GB_AIS + array[13]\n",
    "    average_geometric_mean_score_RF_AIS = average_geometric_mean_score_RF_AIS + array[14]\n",
    "    average_geometric_mean_score_LR_AIS = average_geometric_mean_score_LR_AIS + array[15]\n",
    "    average_geometric_mean_score_KN_AIS = average_geometric_mean_score_KN_AIS + array[16]\n",
    "    \n",
    "    average_f1_score_GB_AIS = average_f1_score_GB_AIS + array[17]\n",
    "    average_f1_score_RF_AIS = average_f1_score_RF_AIS + array[18]\n",
    "    average_f1_score_LR_AIS = average_f1_score_LR_AIS + array[19]\n",
    "    average_f1_score_KN_AIS = average_f1_score_KN_AIS + array[20]\n",
    "\n",
    "for array in dataSMOTE:\n",
    "\n",
    "    average_SMOTE_Runtime = average_SMOTE_Runtime + array[3]\n",
    "\n",
    "    average_roc_auc_GB = average_roc_auc_GB + array[5]\n",
    "    average_roc_auc_RF = average_roc_auc_RF + array[6]\n",
    "    average_roc_auc_LR = average_roc_auc_LR + array[7]\n",
    "    average_roc_auc_KN = average_roc_auc_KN + array[8]\n",
    "\n",
    "    average_balanced_acc_GB = average_balanced_acc_GB + array[9]\n",
    "    average_balanced_acc_RF = average_balanced_acc_RF + array[10]\n",
    "    average_balanced_acc_LR = average_balanced_acc_LR + array[11]\n",
    "    average_balanced_acc_KN = average_balanced_acc_KN + array[12]\n",
    "\n",
    "    average_geometric_mean_score_GB = average_geometric_mean_score_GB + array[13]\n",
    "    average_geometric_mean_score_RF = average_geometric_mean_score_RF + array[14]\n",
    "    average_geometric_mean_score_LR = average_geometric_mean_score_LR + array[15]\n",
    "    average_geometric_mean_score_KN = average_geometric_mean_score_KN + array[16]\n",
    "    \n",
    "    average_f1_score_GB = average_f1_score_GB + array[17]\n",
    "    average_f1_score_RF = average_f1_score_RF + array[18]\n",
    "    average_f1_score_LR = average_f1_score_LR + array[19]\n",
    "    average_f1_score_KN = average_f1_score_KN + array[20]\n",
    "\n",
    "for array in dataBase:\n",
    "\n",
    "    average_roc_auc_GB_Base = average_roc_auc_GB_Base + array[5]\n",
    "    average_roc_auc_RF_Base = average_roc_auc_RF_Base + array[6]\n",
    "    average_roc_auc_LR_Base = average_roc_auc_LR_Base + array[7]\n",
    "    average_roc_auc_KN_Base = average_roc_auc_KN_Base + array[8]\n",
    "\n",
    "    average_balanced_acc_GB_Base = average_balanced_acc_GB_Base + array[9]\n",
    "    average_balanced_acc_RF_Base = average_balanced_acc_RF_Base + array[10]\n",
    "    average_balanced_acc_LR_Base = average_balanced_acc_LR_Base + array[11]\n",
    "    average_balanced_acc_KN_Base = average_balanced_acc_KN_Base + array[12]\n",
    "\n",
    "    average_geometric_mean_score_GB_Base = average_geometric_mean_score_GB_Base + array[13]\n",
    "    average_geometric_mean_score_RF_Base = average_geometric_mean_score_RF_Base + array[14]\n",
    "    average_geometric_mean_score_LR_Base = average_geometric_mean_score_LR_Base + array[15]\n",
    "    average_geometric_mean_score_KN_Base = average_geometric_mean_score_KN_Base + array[16]\n",
    "    \n",
    "    average_f1_score_GB_Base = average_f1_score_GB_Base + array[17]\n",
    "    average_f1_score_RF_Base = average_f1_score_RF_Base + array[18]\n",
    "    average_f1_score_LR_Base = average_f1_score_LR_Base + array[19]\n",
    "    average_f1_score_KN_Base = average_f1_score_KN_Base + array[20]\n",
    "\n",
    "average_f1_score_GB = average_f1_score_GB / fold\n",
    "average_f1_score_RF = average_f1_score_RF / fold\n",
    "average_f1_score_LR = average_f1_score_LR / fold\n",
    "average_f1_score_KN= average_f1_score_KN / fold\n",
    "\n",
    "average_f1_score_GB_AIS = average_f1_score_GB_AIS / fold\n",
    "average_f1_score_RF_AIS = average_f1_score_RF_AIS / fold\n",
    "average_f1_score_LR_AIS = average_f1_score_LR_AIS / fold\n",
    "average_f1_score_KN_AIS = average_f1_score_KN_AIS / fold\n",
    "\n",
    "average_f1_score_GB_Base = average_f1_score_GB_Base / fold\n",
    "average_f1_score_RF_Base = average_f1_score_RF_Base / fold\n",
    "average_f1_score_LR_Base = average_f1_score_LR_Base / fold\n",
    "average_f1_score_KN_Base= average_f1_score_KN_Base / fold\n",
    "\n",
    "average_geometric_mean_score_GB = average_geometric_mean_score_GB / fold\n",
    "average_geometric_mean_score_RF= average_geometric_mean_score_RF / fold\n",
    "average_geometric_mean_score_LR= average_geometric_mean_score_LR / fold\n",
    "average_geometric_mean_score_KN = average_geometric_mean_score_KN / fold\n",
    "\n",
    "average_geometric_mean_score_GB_AIS= average_geometric_mean_score_GB_AIS / fold\n",
    "average_geometric_mean_score_RF_AIS= average_geometric_mean_score_RF_AIS / fold\n",
    "average_geometric_mean_score_LR_AIS = average_geometric_mean_score_LR_AIS / fold\n",
    "average_geometric_mean_score_KN_AIS = average_geometric_mean_score_KN_AIS / fold\n",
    "\n",
    "average_geometric_mean_score_GB_Base = average_geometric_mean_score_GB_Base / fold\n",
    "average_geometric_mean_score_RF_Base= average_geometric_mean_score_RF_Base / fold\n",
    "average_geometric_mean_score_LR_Base= average_geometric_mean_score_LR_Base / fold\n",
    "average_geometric_mean_score_KN_Base= average_geometric_mean_score_KN_Base / fold\n",
    "\n",
    "    \n",
    "average_roc_auc_GB_AIS= average_roc_auc_GB_AIS / fold\n",
    "average_roc_auc_RF_AIS= average_roc_auc_RF_AIS / fold\n",
    "average_roc_auc_LR_AIS= average_roc_auc_LR_AIS / fold\n",
    "average_roc_auc_KN_AIS= average_roc_auc_KN_AIS / fold\n",
    " \n",
    "average_roc_auc_GB_Base = average_roc_auc_GB_Base / fold\n",
    "average_roc_auc_RF_Base= average_roc_auc_RF_Base / fold\n",
    "average_roc_auc_LR_Base= average_roc_auc_LR_Base / fold\n",
    "average_roc_auc_KN_Base= average_roc_auc_KN_Base / fold\n",
    "\n",
    "average_roc_auc_GB= average_roc_auc_GB / fold\n",
    "average_roc_auc_RF= average_roc_auc_RF / fold\n",
    "average_roc_auc_LR= average_roc_auc_LR / fold\n",
    "average_roc_auc_KN= average_roc_auc_KN / fold\n",
    "\n",
    "    \n",
    "\n",
    "average_balanced_acc_GB_AIS= average_balanced_acc_GB_AIS / fold\n",
    "average_balanced_acc_RF_AIS= average_balanced_acc_RF_AIS / fold\n",
    "average_balanced_acc_LR_AIS= average_balanced_acc_LR_AIS / fold\n",
    "average_balanced_acc_KN_AIS= average_balanced_acc_KN_AIS / fold\n",
    " \n",
    "average_balanced_acc_GB= average_balanced_acc_GB / fold\n",
    "average_balanced_acc_RF= average_balanced_acc_RF / fold\n",
    "average_balanced_acc_LR= average_balanced_acc_LR / fold\n",
    "average_balanced_acc_KN= average_balanced_acc_KN / fold\n",
    "\n",
    "    \n",
    "average_balanced_acc_GB_Base= average_balanced_acc_GB_Base / fold\n",
    "average_balanced_acc_RF_Base= average_balanced_acc_RF_Base / fold\n",
    "average_balanced_acc_LR_Base= average_balanced_acc_LR_Base / fold\n",
    "average_balanced_acc_KN_Base= average_balanced_acc_KN_Base / fold\n",
    "\n",
    "\n",
    "\n",
    "data.append( [\"\",\"\",\"AIS\", \"\",\"AVERAGE:\", average_roc_auc_GB_AIS, average_roc_auc_RF_AIS, average_roc_auc_LR_AIS, average_roc_auc_KN_AIS, average_balanced_acc_GB_AIS, average_balanced_acc_RF_AIS,  average_balanced_acc_LR_AIS,  average_balanced_acc_KN_AIS, average_geometric_mean_score_GB_AIS, average_geometric_mean_score_RF_AIS, average_geometric_mean_score_LR_AIS, average_geometric_mean_score_KN_AIS,average_f1_score_GB_AIS,average_f1_score_RF_AIS,average_f1_score_LR_AIS,average_f1_score_KN_AIS ])\n",
    "data.append([\"\",\"\",\"SMOTE\", \"\",\"AVERAGE:\", average_roc_auc_GB,  average_roc_auc_RF, average_roc_auc_LR,average_roc_auc_KN, average_balanced_acc_GB, average_balanced_acc_RF,  average_balanced_acc_LR,  average_balanced_acc_KN, average_geometric_mean_score_GB, average_geometric_mean_score_RF, average_geometric_mean_score_LR, average_geometric_mean_score_KN,average_f1_score_GB,average_f1_score_RF,average_f1_score_LR,average_f1_score_KN])\n",
    "data.append([\"\",\"\",\"BASE\", \"\",\"AVERAGE:\", average_roc_auc_GB_Base, average_roc_auc_RF_Base, average_roc_auc_LR_Base, average_roc_auc_KN_Base, average_balanced_acc_GB_Base, average_balanced_acc_RF_Base,balanced_acc_LR_Base,  average_balanced_acc_KN_Base, average_geometric_mean_score_GB_Base, average_geometric_mean_score_RF_Base, average_geometric_mean_score_LR_Base, average_geometric_mean_score_KN_Base,average_f1_score_GB_Base,average_f1_score_RF_Base,average_f1_score_LR_Base,average_f1_score_KN_Base])\n",
    "data.append([\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = [\"Fold\", \"Dataset\",\"Oversample\",\"Oversample Run Time\", \"Oversample Paramaters\", \"ROC AUC for Gradient Boosting\",  \"ROC AUC for Random Forests\", \"ROC AUC for Logistic Regression\",  \"ROC AUC for K Nearest Neighbours\", \"Balanced Accuracy for Gradient Boosting\", \"Balanced Accuracy for Random Forests\" ,\"Balanced Accuracy for Logistic Regression\",\"Balanced Accuracy for K Nearest Neighbours\", \"Geometric Mean Score for Gradient Boosting\", \"Geometric Mean Score for Random Forest\", \"Geometric Mean Score for Logestic Regression\", \"Geometric Mean Score for K Neighbors\", \"F1 Score for Gradient Boosting\", \"F1 Score for Random Forest\", \"F1 Score for Logestic Regression\", \"F1 Score for K Neighbors\"]\n",
    "dfoutput=pd.DataFrame(data,columns=col_names)\n",
    "title = \"ExperimentalResults/ExperimentalComparisons-TestReal.csv\"\n",
    "dfoutput.to_csv(title, mode='a',index=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('csi4106')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "51ea9996f2a91c7d112e626959c304b606e4bf2254e73fec145d965796b2ca69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
