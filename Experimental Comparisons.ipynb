{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, cross_val_score, GridSearchCV, cross_validate\n",
    "\n",
    "# importing two different imputation methods that take into consideration all the features when predicting the missing values\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#multiclass imports\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.dummy import DummyClassifier #Will identify the maority calss base line, model needs to do better then the baseline\n",
    "\n",
    "from statistics import mean\n",
    "# to reduce randomness then you put the seed\n",
    "np.random.seed(42)\n",
    "\n",
    "from ArtificialImmuneSystem import *\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from tabulate import tabulate\n",
    "import time\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data\\GeneratedSyntheticData-testing.csv')\n",
    "#df = df.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: \n",
      "(300, 6)\n",
      "\n",
      "Data size: \n",
      "1800\n",
      "\n",
      "Data ndim: \n",
      "2\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Old Class Distribution: Counter({0.0: 247, 1.0: 53})\n"
     ]
    }
   ],
   "source": [
    "print(f\"Data shape: \\n{df.shape}\\n\")\n",
    "print(f\"Data size: \\n{df.size}\\n\")\n",
    "print(f\"Data ndim: \\n{df.ndim}\\n\")\n",
    "print(\"_____________________________________________\\n\")\n",
    "print(f\"Old Class Distribution: {Counter(df['5'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 154, 1.0: 38})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (156, 5)\n",
      "origin_labels_train after:  Counter({0.0: 195, 1.0: 45})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 160, 1.0: 32})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (156, 5)\n",
      "origin_labels_train after:  Counter({0.0: 202, 1.0: 38})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 159, 1.0: 33})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (156, 5)\n",
      "origin_labels_train after:  Counter({0.0: 198, 1.0: 42})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 161, 1.0: 31})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (156, 5)\n",
      "origin_labels_train after:  Counter({0.0: 200, 1.0: 40})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 155, 1.0: 37})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (156, 5)\n",
      "origin_labels_train after:  Counter({0.0: 193, 1.0: 47})\n",
      "old_score: 0.6085970635056\n",
      "population_score: 0.7332917189784969\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 156, 1.0: 36})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (156, 5)\n",
      "origin_labels_train after:  Counter({0.0: 196, 1.0: 44})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 158, 1.0: 34})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (156, 5)\n",
      "origin_labels_train after:  Counter({0.0: 196, 1.0: 44})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 155, 1.0: 37})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (156, 5)\n",
      "origin_labels_train after:  Counter({0.0: 192, 1.0: 48})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 160, 1.0: 32})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (156, 5)\n",
      "origin_labels_train after:  Counter({0.0: 202, 1.0: 38})\n",
      "old_score: 0.7332917189784969\n",
      "population_score: 0.7449830316742082\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 159, 1.0: 33})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (156, 5)\n",
      "origin_labels_train after:  Counter({0.0: 197, 1.0: 43})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 159, 1.0: 33})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (156, 5)\n",
      "origin_labels_train after:  Counter({0.0: 196, 1.0: 44})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 158, 1.0: 34})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (156, 5)\n",
      "origin_labels_train after:  Counter({0.0: 200, 1.0: 40})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 157, 1.0: 35})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (156, 5)\n",
      "origin_labels_train after:  Counter({0.0: 198, 1.0: 42})\n",
      "old_score: 0.7449830316742082\n",
      "population_score: 0.670521978021978\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 161, 1.0: 31})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (156, 5)\n",
      "origin_labels_train after:  Counter({0.0: 205, 1.0: 35})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 158, 1.0: 34})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (156, 5)\n",
      "origin_labels_train after:  Counter({0.0: 197, 1.0: 43})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 160, 1.0: 32})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (156, 5)\n",
      "origin_labels_train after:  Counter({0.0: 198, 1.0: 42})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 158, 1.0: 34})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (156, 5)\n",
      "origin_labels_train after:  Counter({0.0: 198, 1.0: 42})\n",
      "old_score: 0.7449830316742082\n",
      "population_score: 0.7430197335344395\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 159, 1.0: 33})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (156, 5)\n",
      "origin_labels_train after:  Counter({0.0: 201, 1.0: 39})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 159, 1.0: 33})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (156, 5)\n",
      "origin_labels_train after:  Counter({0.0: 196, 1.0: 44})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 160, 1.0: 32})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (156, 5)\n",
      "origin_labels_train after:  Counter({0.0: 199, 1.0: 41})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 159, 1.0: 33})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (156, 5)\n",
      "origin_labels_train after:  Counter({0.0: 198, 1.0: 42})\n",
      "old_score: 0.7449830316742082\n",
      "population_score: 0.6437179487179486\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 154, 1.0: 38})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (156, 5)\n",
      "origin_labels_train after:  Counter({0.0: 191, 1.0: 49})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 160, 1.0: 32})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (156, 5)\n",
      "origin_labels_train after:  Counter({0.0: 198, 1.0: 42})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 159, 1.0: 33})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (156, 5)\n",
      "origin_labels_train after:  Counter({0.0: 199, 1.0: 41})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 160, 1.0: 32})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (156, 5)\n",
      "origin_labels_train after:  Counter({0.0: 200, 1.0: 40})\n",
      "old_score: 0.7449830316742082\n",
      "population_score: 0.7321361800373354\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 160, 1.0: 32})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (156, 5)\n",
      "origin_labels_train after:  Counter({0.0: 200, 1.0: 40})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 155, 1.0: 37})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (156, 5)\n",
      "origin_labels_train after:  Counter({0.0: 192, 1.0: 48})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 163, 1.0: 29})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (156, 5)\n",
      "origin_labels_train after:  Counter({0.0: 206, 1.0: 34})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 158, 1.0: 34})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (156, 5)\n",
      "origin_labels_train after:  Counter({0.0: 198, 1.0: 42})\n",
      "old_score: 0.7449830316742082\n",
      "population_score: 0.7330599472990776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:570: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jacob\\AppData\\Local\\Temp\\ipykernel_31660\\3083189773.py:75: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  randomForest_Base = randomForest.fit(data_train.drop([\"5\"], axis=1), data_train.drop(data_train_AIS.columns[0:-1],axis=1))\n",
      "c:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:207: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score GradientBoosting: \n",
      "0.7626020408163265\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score GradientBoosting AIS: \n",
      "0.8881122448979593\n",
      "\n",
      "Best score KNeighbors: \n",
      "0.782704081632653\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score KNeighbors AIS: \n",
      "0.8321428571428571\n",
      "\n",
      "Best score Logistic Regression: \n",
      "0.5578571428571428\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score Logistic Regression AIS: \n",
      "0.7661734693877551\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score RandomForest: \n",
      "0.7171428571428571\n",
      "\n",
      "Best score RandomForest AIS: \n",
      "0.9108163265306122\n",
      "\n",
      "  Oversample Oversample Run Time        Oversample Paramaters  \\\n",
      "0        AIS           49.966202  MinChange = 0.005, LOF=True   \n",
      "1      SMOTE            0.005995                           NA   \n",
      "2       BASE                  NA                           NA   \n",
      "\n",
      "   ROC Accuracy for Gradient Boosting  \\\n",
      "0                            0.787570   \n",
      "1                            0.670686   \n",
      "2                            0.671614   \n",
      "\n",
      "   Balanced Test Accuracy for Gradient Boosting  \\\n",
      "0                                      0.787570   \n",
      "1                                      0.670686   \n",
      "2                                      0.671614   \n",
      "\n",
      "   ROC Accuracy for Random Forests  Balanced Test Accuracy for Random Forests  \\\n",
      "0                         0.727273                                   0.727273   \n",
      "1                         0.726345                                   0.726345   \n",
      "2                         0.686456                                   0.686456   \n",
      "\n",
      "   ROC Accuracy for Logistic Regression  \\\n",
      "0                              0.605751   \n",
      "1                              0.508349   \n",
      "2                              0.590909   \n",
      "\n",
      "   Balanced Test Accuracy for Logistic Regression  \\\n",
      "0                                        0.605751   \n",
      "1                                        0.508349   \n",
      "2                                        0.590909   \n",
      "\n",
      "   ROC Accuracy for K Nearest Neighbours  \\\n",
      "0                               0.605751   \n",
      "1                               0.543599   \n",
      "2                               0.626160   \n",
      "\n",
      "   Balanced Test Accuracy for K Nearest Neighbours  \\\n",
      "0                                         0.605751   \n",
      "1                                         0.543599   \n",
      "2                                         0.626160   \n",
      "\n",
      "   Geometric Mean Score for Gradient Boosting  \\\n",
      "0                                    0.772918   \n",
      "1                                    0.658891   \n",
      "2                                    0.596838   \n",
      "\n",
      "   Geometric Mean Score for Random Forest  \\\n",
      "0                                0.674200   \n",
      "1                                0.720750   \n",
      "2                                0.646096   \n",
      "\n",
      "   Geometric Mean Score for Logestic Regression  \\\n",
      "0                                      0.505994   \n",
      "1                                      0.487316   \n",
      "2                                      0.426401   \n",
      "\n",
      "   Geometric Mean Score for K Neighbors  \n",
      "0                              0.505994  \n",
      "1                              0.536255  \n",
      "2                              0.516877  \n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 157, 1.0: 35})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (148, 5)\n",
      "origin_labels_train after:  Counter({0.0: 195, 1.0: 45})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 155, 1.0: 37})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (148, 5)\n",
      "origin_labels_train after:  Counter({0.0: 192, 1.0: 48})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 150, 1.0: 42})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (148, 5)\n",
      "origin_labels_train after:  Counter({0.0: 183, 1.0: 57})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 158, 1.0: 34})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (148, 5)\n",
      "origin_labels_train after:  Counter({0.0: 201, 1.0: 39})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 152, 1.0: 40})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (148, 5)\n",
      "origin_labels_train after:  Counter({0.0: 193, 1.0: 47})\n",
      "old_score: 0.7334590246354953\n",
      "population_score: 0.6402005057834019\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 156, 1.0: 36})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (148, 5)\n",
      "origin_labels_train after:  Counter({0.0: 194, 1.0: 46})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 151, 1.0: 41})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (148, 5)\n",
      "origin_labels_train after:  Counter({0.0: 190, 1.0: 50})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 157, 1.0: 35})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (148, 5)\n",
      "origin_labels_train after:  Counter({0.0: 198, 1.0: 42})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 151, 1.0: 41})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (148, 5)\n",
      "origin_labels_train after:  Counter({0.0: 189, 1.0: 51})\n",
      "old_score: 0.7334590246354953\n",
      "population_score: 0.7075731972070645\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 153, 1.0: 39})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (148, 5)\n",
      "origin_labels_train after:  Counter({0.0: 194, 1.0: 46})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 154, 1.0: 38})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (148, 5)\n",
      "origin_labels_train after:  Counter({0.0: 191, 1.0: 49})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 154, 1.0: 38})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (148, 5)\n",
      "origin_labels_train after:  Counter({0.0: 189, 1.0: 51})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 155, 1.0: 37})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (148, 5)\n",
      "origin_labels_train after:  Counter({0.0: 192, 1.0: 48})\n",
      "old_score: 0.7334590246354953\n",
      "population_score: 0.6499358974358975\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 158, 1.0: 34})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (148, 5)\n",
      "origin_labels_train after:  Counter({0.0: 196, 1.0: 44})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 156, 1.0: 36})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (148, 5)\n",
      "origin_labels_train after:  Counter({0.0: 194, 1.0: 46})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 153, 1.0: 39})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (148, 5)\n",
      "origin_labels_train after:  Counter({0.0: 196, 1.0: 44})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 154, 1.0: 38})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (148, 5)\n",
      "origin_labels_train after:  Counter({0.0: 192, 1.0: 48})\n",
      "old_score: 0.7334590246354953\n",
      "population_score: 0.8383940620782726\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 154, 1.0: 38})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (148, 5)\n",
      "origin_labels_train after:  Counter({0.0: 192, 1.0: 48})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 156, 1.0: 36})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (148, 5)\n",
      "origin_labels_train after:  Counter({0.0: 196, 1.0: 44})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 152, 1.0: 40})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (148, 5)\n",
      "origin_labels_train after:  Counter({0.0: 188, 1.0: 52})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 158, 1.0: 34})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (148, 5)\n",
      "origin_labels_train after:  Counter({0.0: 195, 1.0: 45})\n",
      "old_score: 0.8383940620782726\n",
      "population_score: 0.7878542510121458\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 153, 1.0: 39})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (148, 5)\n",
      "origin_labels_train after:  Counter({0.0: 190, 1.0: 50})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 155, 1.0: 37})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (148, 5)\n",
      "origin_labels_train after:  Counter({0.0: 192, 1.0: 48})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 156, 1.0: 36})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (148, 5)\n",
      "origin_labels_train after:  Counter({0.0: 194, 1.0: 46})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 156, 1.0: 36})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (148, 5)\n",
      "origin_labels_train after:  Counter({0.0: 192, 1.0: 48})\n",
      "old_score: 0.8383940620782726\n",
      "population_score: 0.7161619082671714\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 156, 1.0: 36})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (148, 5)\n",
      "origin_labels_train after:  Counter({0.0: 194, 1.0: 46})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 155, 1.0: 37})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (148, 5)\n",
      "origin_labels_train after:  Counter({0.0: 194, 1.0: 46})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 158, 1.0: 34})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (148, 5)\n",
      "origin_labels_train after:  Counter({0.0: 196, 1.0: 44})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 152, 1.0: 40})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (148, 5)\n",
      "origin_labels_train after:  Counter({0.0: 191, 1.0: 49})\n",
      "old_score: 0.8383940620782726\n",
      "population_score: 0.8056574346705926\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 159, 1.0: 33})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (148, 5)\n",
      "origin_labels_train after:  Counter({0.0: 201, 1.0: 39})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 153, 1.0: 39})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (148, 5)\n",
      "origin_labels_train after:  Counter({0.0: 190, 1.0: 50})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 155, 1.0: 37})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (148, 5)\n",
      "origin_labels_train after:  Counter({0.0: 191, 1.0: 49})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 155, 1.0: 37})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (148, 5)\n",
      "origin_labels_train after:  Counter({0.0: 195, 1.0: 45})\n",
      "old_score: 0.8383940620782726\n",
      "population_score: 0.7046711851603156\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 157, 1.0: 35})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (148, 5)\n",
      "origin_labels_train after:  Counter({0.0: 193, 1.0: 47})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 152, 1.0: 40})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (148, 5)\n",
      "origin_labels_train after:  Counter({0.0: 190, 1.0: 50})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 156, 1.0: 36})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (148, 5)\n",
      "origin_labels_train after:  Counter({0.0: 196, 1.0: 44})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 158, 1.0: 34})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (148, 5)\n",
      "origin_labels_train after:  Counter({0.0: 197, 1.0: 43})\n",
      "old_score: 0.8383940620782726\n",
      "population_score: 0.8002226720647773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:570: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jacob\\AppData\\Local\\Temp\\ipykernel_31660\\3083189773.py:75: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  randomForest_Base = randomForest.fit(data_train.drop([\"5\"], axis=1), data_train.drop(data_train_AIS.columns[0:-1],axis=1))\n",
      "c:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:207: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score GradientBoosting: \n",
      "0.8066007653061225\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score GradientBoosting AIS: \n",
      "0.8780293367346939\n",
      "\n",
      "Best score KNeighbors: \n",
      "0.7990539965986394\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score KNeighbors AIS: \n",
      "0.8106398809523809\n",
      "\n",
      "Best score Logistic Regression: \n",
      "0.4901147959183674\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score Logistic Regression AIS: \n",
      "0.7926232993197279\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score RandomForest: \n",
      "0.7627551020408163\n",
      "\n",
      "Best score RandomForest AIS: \n",
      "0.8882865646258504\n",
      "\n",
      "  Oversample Oversample Run Time        Oversample Paramaters  \\\n",
      "0        AIS           45.913421  MinChange = 0.005, LOF=True   \n",
      "1      SMOTE            0.004039                           NA   \n",
      "2       BASE                  NA                           NA   \n",
      "\n",
      "   ROC Accuracy for Gradient Boosting  \\\n",
      "0                            0.648248   \n",
      "1                            0.582210   \n",
      "2                            0.676550   \n",
      "\n",
      "   Balanced Test Accuracy for Gradient Boosting  \\\n",
      "0                                      0.648248   \n",
      "1                                      0.582210   \n",
      "2                                      0.676550   \n",
      "\n",
      "   ROC Accuracy for Random Forests  Balanced Test Accuracy for Random Forests  \\\n",
      "0                         0.614555                                   0.614555   \n",
      "1                         0.601078                                   0.601078   \n",
      "2                         0.667116                                   0.667116   \n",
      "\n",
      "   ROC Accuracy for Logistic Regression  \\\n",
      "0                              0.695418   \n",
      "1                              0.606469   \n",
      "2                              0.500000   \n",
      "\n",
      "   Balanced Test Accuracy for Logistic Regression  \\\n",
      "0                                        0.695418   \n",
      "1                                        0.606469   \n",
      "2                                        0.500000   \n",
      "\n",
      "   ROC Accuracy for K Nearest Neighbours  \\\n",
      "0                               0.595687   \n",
      "1                               0.553908   \n",
      "2                               0.533693   \n",
      "\n",
      "   Balanced Test Accuracy for K Nearest Neighbours  \\\n",
      "0                                         0.595687   \n",
      "1                                         0.553908   \n",
      "2                                         0.533693   \n",
      "\n",
      "   Geometric Mean Score for Gradient Boosting  \\\n",
      "0                                    0.609892   \n",
      "1                                    0.561573   \n",
      "2                                    0.629465   \n",
      "\n",
      "   Geometric Mean Score for Random Forest  \\\n",
      "0                                0.519174   \n",
      "1                                0.575792   \n",
      "2                                0.623009   \n",
      "\n",
      "   Geometric Mean Score for Logestic Regression  \\\n",
      "0                                      0.642183   \n",
      "1                                      0.605456   \n",
      "2                                      0.000000   \n",
      "\n",
      "   Geometric Mean Score for K Neighbors  \n",
      "0                              0.508685  \n",
      "1                              0.539542  \n",
      "2                              0.363422  \n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 157, 1.0: 35})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (160, 5)\n",
      "origin_labels_train after:  Counter({0.0: 196, 1.0: 44})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 163, 1.0: 29})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (160, 5)\n",
      "origin_labels_train after:  Counter({0.0: 200, 1.0: 40})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 163, 1.0: 29})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (160, 5)\n",
      "origin_labels_train after:  Counter({0.0: 205, 1.0: 35})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 163, 1.0: 29})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (160, 5)\n",
      "origin_labels_train after:  Counter({0.0: 204, 1.0: 36})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 158, 1.0: 34})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (160, 5)\n",
      "origin_labels_train after:  Counter({0.0: 201, 1.0: 39})\n",
      "old_score: 0.6548030018761727\n",
      "population_score: 0.7188742690058479\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 161, 1.0: 31})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (160, 5)\n",
      "origin_labels_train after:  Counter({0.0: 202, 1.0: 38})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 163, 1.0: 29})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (160, 5)\n",
      "origin_labels_train after:  Counter({0.0: 204, 1.0: 36})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 156, 1.0: 36})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (160, 5)\n",
      "origin_labels_train after:  Counter({0.0: 195, 1.0: 45})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 160, 1.0: 32})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (160, 5)\n",
      "origin_labels_train after:  Counter({0.0: 198, 1.0: 42})\n",
      "old_score: 0.7188742690058479\n",
      "population_score: 0.7424542124542125\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 157, 1.0: 35})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (160, 5)\n",
      "origin_labels_train after:  Counter({0.0: 197, 1.0: 43})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 161, 1.0: 31})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (160, 5)\n",
      "origin_labels_train after:  Counter({0.0: 201, 1.0: 39})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 161, 1.0: 31})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (160, 5)\n",
      "origin_labels_train after:  Counter({0.0: 201, 1.0: 39})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 159, 1.0: 33})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (160, 5)\n",
      "origin_labels_train after:  Counter({0.0: 201, 1.0: 39})\n",
      "old_score: 0.7424542124542125\n",
      "population_score: 0.7134052089121748\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 158, 1.0: 34})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (160, 5)\n",
      "origin_labels_train after:  Counter({0.0: 198, 1.0: 42})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 160, 1.0: 32})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (160, 5)\n",
      "origin_labels_train after:  Counter({0.0: 199, 1.0: 41})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 159, 1.0: 33})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (160, 5)\n",
      "origin_labels_train after:  Counter({0.0: 201, 1.0: 39})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 160, 1.0: 32})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (160, 5)\n",
      "origin_labels_train after:  Counter({0.0: 197, 1.0: 43})\n",
      "old_score: 0.7424542124542125\n",
      "population_score: 0.7424587912087912\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 161, 1.0: 31})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (160, 5)\n",
      "origin_labels_train after:  Counter({0.0: 200, 1.0: 40})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 160, 1.0: 32})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (160, 5)\n",
      "origin_labels_train after:  Counter({0.0: 203, 1.0: 37})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 163, 1.0: 29})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (160, 5)\n",
      "origin_labels_train after:  Counter({0.0: 202, 1.0: 38})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 161, 1.0: 31})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (160, 5)\n",
      "origin_labels_train after:  Counter({0.0: 199, 1.0: 41})\n",
      "old_score: 0.7424542124542125\n",
      "population_score: 0.7065061343486738\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 161, 1.0: 31})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (160, 5)\n",
      "origin_labels_train after:  Counter({0.0: 204, 1.0: 36})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 163, 1.0: 29})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (160, 5)\n",
      "origin_labels_train after:  Counter({0.0: 203, 1.0: 37})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 162, 1.0: 30})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (160, 5)\n",
      "origin_labels_train after:  Counter({0.0: 205, 1.0: 35})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 161, 1.0: 31})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (160, 5)\n",
      "origin_labels_train after:  Counter({0.0: 205, 1.0: 35})\n",
      "old_score: 0.7424542124542125\n",
      "population_score: 0.7745052711516126\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 160, 1.0: 32})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (160, 5)\n",
      "origin_labels_train after:  Counter({0.0: 199, 1.0: 41})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 162, 1.0: 30})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (160, 5)\n",
      "origin_labels_train after:  Counter({0.0: 201, 1.0: 39})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 164, 1.0: 28})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (160, 5)\n",
      "origin_labels_train after:  Counter({0.0: 209, 1.0: 31})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 165, 1.0: 27})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (160, 5)\n",
      "origin_labels_train after:  Counter({0.0: 206, 1.0: 34})\n",
      "old_score: 0.7745052711516126\n",
      "population_score: 0.7434740259740259\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 158, 1.0: 34})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (160, 5)\n",
      "origin_labels_train after:  Counter({0.0: 203, 1.0: 37})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 164, 1.0: 28})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (160, 5)\n",
      "origin_labels_train after:  Counter({0.0: 211, 1.0: 29})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 161, 1.0: 31})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (160, 5)\n",
      "origin_labels_train after:  Counter({0.0: 203, 1.0: 37})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 157, 1.0: 35})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (160, 5)\n",
      "origin_labels_train after:  Counter({0.0: 190, 1.0: 50})\n",
      "old_score: 0.7745052711516126\n",
      "population_score: 0.7715620516499283\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 161, 1.0: 31})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (160, 5)\n",
      "origin_labels_train after:  Counter({0.0: 203, 1.0: 37})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 156, 1.0: 36})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (160, 5)\n",
      "origin_labels_train after:  Counter({0.0: 194, 1.0: 46})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 161, 1.0: 31})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (160, 5)\n",
      "origin_labels_train after:  Counter({0.0: 198, 1.0: 42})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 160, 1.0: 32})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (160, 5)\n",
      "origin_labels_train after:  Counter({0.0: 201, 1.0: 39})\n",
      "old_score: 0.7745052711516126\n",
      "population_score: 0.7091892911010558\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 155, 1.0: 37})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (160, 5)\n",
      "origin_labels_train after:  Counter({0.0: 195, 1.0: 45})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 161, 1.0: 31})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (160, 5)\n",
      "origin_labels_train after:  Counter({0.0: 198, 1.0: 42})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 159, 1.0: 33})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (160, 5)\n",
      "origin_labels_train after:  Counter({0.0: 199, 1.0: 41})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 157, 1.0: 35})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (160, 5)\n",
      "origin_labels_train after:  Counter({0.0: 192, 1.0: 48})\n",
      "old_score: 0.7745052711516126\n",
      "population_score: 0.7792485434975808\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 159, 1.0: 33})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (160, 5)\n",
      "origin_labels_train after:  Counter({0.0: 203, 1.0: 37})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 162, 1.0: 30})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (160, 5)\n",
      "origin_labels_train after:  Counter({0.0: 203, 1.0: 37})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 159, 1.0: 33})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (160, 5)\n",
      "origin_labels_train after:  Counter({0.0: 198, 1.0: 42})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 161, 1.0: 31})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (160, 5)\n",
      "origin_labels_train after:  Counter({0.0: 202, 1.0: 38})\n",
      "old_score: 0.7745052711516126\n",
      "population_score: 0.6831131129750212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:570: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jacob\\AppData\\Local\\Temp\\ipykernel_31660\\3083189773.py:75: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  randomForest_Base = randomForest.fit(data_train.drop([\"5\"], axis=1), data_train.drop(data_train_AIS.columns[0:-1],axis=1))\n",
      "c:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:207: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score GradientBoosting: \n",
      "0.7849999999999999\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score GradientBoosting AIS: \n",
      "0.905\n",
      "\n",
      "Best score KNeighbors: \n",
      "0.8025\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score KNeighbors AIS: \n",
      "0.855\n",
      "\n",
      "Best score Logistic Regression: \n",
      "0.6275\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score Logistic Regression AIS: \n",
      "0.7300000000000001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score RandomForest: \n",
      "0.76\n",
      "\n",
      "Best score RandomForest AIS: \n",
      "0.92\n",
      "\n",
      "  Oversample Oversample Run Time        Oversample Paramaters  \\\n",
      "0        AIS           64.268367  MinChange = 0.005, LOF=True   \n",
      "1      SMOTE             0.00509                           NA   \n",
      "2       BASE                  NA                           NA   \n",
      "\n",
      "   ROC Accuracy for Gradient Boosting  \\\n",
      "0                            0.545008   \n",
      "1                            0.624386   \n",
      "2                            0.545008   \n",
      "\n",
      "   Balanced Test Accuracy for Gradient Boosting  \\\n",
      "0                                      0.545008   \n",
      "1                                      0.624386   \n",
      "2                                      0.545008   \n",
      "\n",
      "   ROC Accuracy for Random Forests  Balanced Test Accuracy for Random Forests  \\\n",
      "0                         0.566285                                   0.566285   \n",
      "1                         0.652209                                   0.652209   \n",
      "2                         0.594108                                   0.594108   \n",
      "\n",
      "   ROC Accuracy for Logistic Regression  \\\n",
      "0                              0.513093   \n",
      "1                              0.511457   \n",
      "2                              0.538462   \n",
      "\n",
      "   Balanced Test Accuracy for Logistic Regression  \\\n",
      "0                                        0.513093   \n",
      "1                                        0.511457   \n",
      "2                                        0.538462   \n",
      "\n",
      "   ROC Accuracy for K Nearest Neighbours  \\\n",
      "0                               0.527823   \n",
      "1                               0.641571   \n",
      "2                               0.566285   \n",
      "\n",
      "   Balanced Test Accuracy for K Nearest Neighbours  \\\n",
      "0                                         0.527823   \n",
      "1                                         0.641571   \n",
      "2                                         0.566285   \n",
      "\n",
      "   Geometric Mean Score for Gradient Boosting  \\\n",
      "0                                    0.379508   \n",
      "1                                    0.602776   \n",
      "2                                    0.379508   \n",
      "\n",
      "   Geometric Mean Score for Random Forest  \\\n",
      "0                                0.388037   \n",
      "1                                0.642214   \n",
      "2                                0.470052   \n",
      "\n",
      "   Geometric Mean Score for Logestic Regression  \\\n",
      "0                                      0.366342   \n",
      "1                                      0.495479   \n",
      "2                                      0.277350   \n",
      "\n",
      "   Geometric Mean Score for K Neighbors  \n",
      "0                              0.274384  \n",
      "1                              0.633231  \n",
      "2                              0.388037  \n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 164, 1.0: 28})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (168, 5)\n",
      "origin_labels_train after:  Counter({0.0: 209, 1.0: 31})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 163, 1.0: 29})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (168, 5)\n",
      "origin_labels_train after:  Counter({0.0: 201, 1.0: 39})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 165, 1.0: 27})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (168, 5)\n",
      "origin_labels_train after:  Counter({0.0: 209, 1.0: 31})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 161, 1.0: 31})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (168, 5)\n",
      "origin_labels_train after:  Counter({0.0: 205, 1.0: 35})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 163, 1.0: 29})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (168, 5)\n",
      "origin_labels_train after:  Counter({0.0: 207, 1.0: 33})\n",
      "old_score: 0.7179776422764228\n",
      "population_score: 0.7049703650008528\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 162, 1.0: 30})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (168, 5)\n",
      "origin_labels_train after:  Counter({0.0: 201, 1.0: 39})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 167, 1.0: 25})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (168, 5)\n",
      "origin_labels_train after:  Counter({0.0: 210, 1.0: 30})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 166, 1.0: 26})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (168, 5)\n",
      "origin_labels_train after:  Counter({0.0: 207, 1.0: 33})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 164, 1.0: 28})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (168, 5)\n",
      "origin_labels_train after:  Counter({0.0: 206, 1.0: 34})\n",
      "old_score: 0.7179776422764228\n",
      "population_score: 0.7542991220878594\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 164, 1.0: 28})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (168, 5)\n",
      "origin_labels_train after:  Counter({0.0: 202, 1.0: 38})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 162, 1.0: 30})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (168, 5)\n",
      "origin_labels_train after:  Counter({0.0: 200, 1.0: 40})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 164, 1.0: 28})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (168, 5)\n",
      "origin_labels_train after:  Counter({0.0: 209, 1.0: 31})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 164, 1.0: 28})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (168, 5)\n",
      "origin_labels_train after:  Counter({0.0: 205, 1.0: 35})\n",
      "old_score: 0.7542991220878594\n",
      "population_score: 0.699812382739212\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 161, 1.0: 31})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (168, 5)\n",
      "origin_labels_train after:  Counter({0.0: 204, 1.0: 36})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 165, 1.0: 27})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (168, 5)\n",
      "origin_labels_train after:  Counter({0.0: 209, 1.0: 31})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 163, 1.0: 29})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (168, 5)\n",
      "origin_labels_train after:  Counter({0.0: 203, 1.0: 37})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 168, 1.0: 24})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (168, 5)\n",
      "origin_labels_train after:  Counter({0.0: 205, 1.0: 35})\n",
      "old_score: 0.7542991220878594\n",
      "population_score: 0.6985485413677666\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 161, 1.0: 31})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (168, 5)\n",
      "origin_labels_train after:  Counter({0.0: 202, 1.0: 38})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 160, 1.0: 32})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (168, 5)\n",
      "origin_labels_train after:  Counter({0.0: 204, 1.0: 36})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 161, 1.0: 31})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (168, 5)\n",
      "origin_labels_train after:  Counter({0.0: 198, 1.0: 42})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 162, 1.0: 30})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (168, 5)\n",
      "origin_labels_train after:  Counter({0.0: 203, 1.0: 37})\n",
      "old_score: 0.7542991220878594\n",
      "population_score: 0.7305044955044955\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 163, 1.0: 29})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (168, 5)\n",
      "origin_labels_train after:  Counter({0.0: 206, 1.0: 34})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 161, 1.0: 31})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (168, 5)\n",
      "origin_labels_train after:  Counter({0.0: 204, 1.0: 36})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 162, 1.0: 30})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (168, 5)\n",
      "origin_labels_train after:  Counter({0.0: 199, 1.0: 41})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 161, 1.0: 31})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (168, 5)\n",
      "origin_labels_train after:  Counter({0.0: 199, 1.0: 41})\n",
      "old_score: 0.7542991220878594\n",
      "population_score: 0.6990705128205128\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 167, 1.0: 25})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (168, 5)\n",
      "origin_labels_train after:  Counter({0.0: 210, 1.0: 30})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 161, 1.0: 31})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (168, 5)\n",
      "origin_labels_train after:  Counter({0.0: 204, 1.0: 36})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 165, 1.0: 27})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (168, 5)\n",
      "origin_labels_train after:  Counter({0.0: 210, 1.0: 30})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 160, 1.0: 32})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (168, 5)\n",
      "origin_labels_train after:  Counter({0.0: 200, 1.0: 40})\n",
      "old_score: 0.7542991220878594\n",
      "population_score: 0.7295833333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:570: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jacob\\AppData\\Local\\Temp\\ipykernel_31660\\3083189773.py:75: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  randomForest_Base = randomForest.fit(data_train.drop([\"5\"], axis=1), data_train.drop(data_train_AIS.columns[0:-1],axis=1))\n",
      "c:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:207: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score GradientBoosting: \n",
      "0.75\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score GradientBoosting AIS: \n",
      "0.8725490196078431\n",
      "\n",
      "Best score KNeighbors: \n",
      "0.7401960784313726\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score KNeighbors AIS: \n",
      "0.8186274509803921\n",
      "\n",
      "Best score Logistic Regression: \n",
      "0.5759803921568627\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score Logistic Regression AIS: \n",
      "0.7647058823529411\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score RandomForest: \n",
      "0.75\n",
      "\n",
      "Best score RandomForest AIS: \n",
      "0.8995098039215685\n",
      "\n",
      "  Oversample Oversample Run Time        Oversample Paramaters  \\\n",
      "0        AIS           51.172886  MinChange = 0.005, LOF=True   \n",
      "1      SMOTE            0.004996                           NA   \n",
      "2       BASE                  NA                           NA   \n",
      "\n",
      "   ROC Accuracy for Gradient Boosting  \\\n",
      "0                            0.677155   \n",
      "1                            0.590287   \n",
      "2                            0.664843   \n",
      "\n",
      "   Balanced Test Accuracy for Gradient Boosting  \\\n",
      "0                                      0.677155   \n",
      "1                                      0.590287   \n",
      "2                                      0.664843   \n",
      "\n",
      "   ROC Accuracy for Random Forests  Balanced Test Accuracy for Random Forests  \\\n",
      "0                         0.712038                                   0.712038   \n",
      "1                         0.689466                                   0.689466   \n",
      "2                         0.712038                                   0.712038   \n",
      "\n",
      "   ROC Accuracy for Logistic Regression  \\\n",
      "0                              0.642271   \n",
      "1                              0.549248   \n",
      "2                              0.558824   \n",
      "\n",
      "   Balanced Test Accuracy for Logistic Regression  \\\n",
      "0                                        0.642271   \n",
      "1                                        0.549248   \n",
      "2                                        0.558824   \n",
      "\n",
      "   ROC Accuracy for K Nearest Neighbours  \\\n",
      "0                               0.653215   \n",
      "1                               0.560876   \n",
      "2                               0.617647   \n",
      "\n",
      "   Balanced Test Accuracy for K Nearest Neighbours  \\\n",
      "0                                         0.653215   \n",
      "1                                         0.560876   \n",
      "2                                         0.617647   \n",
      "\n",
      "   Geometric Mean Score for Gradient Boosting  \\\n",
      "0                                    0.644879   \n",
      "1                                    0.587140   \n",
      "2                                    0.587140   \n",
      "\n",
      "   Geometric Mean Score for Random Forest  \\\n",
      "0                                0.669851   \n",
      "1                                0.681994   \n",
      "2                                0.669851   \n",
      "\n",
      "   Geometric Mean Score for Logestic Regression  \\\n",
      "0                                      0.618900   \n",
      "1                                      0.543586   \n",
      "2                                      0.342997   \n",
      "\n",
      "   Geometric Mean Score for K Neighbors  \n",
      "0                              0.580108  \n",
      "1                              0.553561  \n",
      "2                              0.485071  \n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 156, 1.0: 36})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (144, 5)\n",
      "origin_labels_train after:  Counter({0.0: 199, 1.0: 41})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 157, 1.0: 35})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (144, 5)\n",
      "origin_labels_train after:  Counter({0.0: 197, 1.0: 43})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 152, 1.0: 40})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (144, 5)\n",
      "origin_labels_train after:  Counter({0.0: 192, 1.0: 48})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 156, 1.0: 36})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (144, 5)\n",
      "origin_labels_train after:  Counter({0.0: 195, 1.0: 45})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 153, 1.0: 39})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (144, 5)\n",
      "origin_labels_train after:  Counter({0.0: 191, 1.0: 49})\n",
      "old_score: 0.6951967408585056\n",
      "population_score: 0.761388822735572\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 161, 1.0: 31})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (144, 5)\n",
      "origin_labels_train after:  Counter({0.0: 195, 1.0: 45})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 156, 1.0: 36})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (144, 5)\n",
      "origin_labels_train after:  Counter({0.0: 198, 1.0: 42})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 151, 1.0: 41})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (144, 5)\n",
      "origin_labels_train after:  Counter({0.0: 191, 1.0: 49})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 152, 1.0: 40})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (144, 5)\n",
      "origin_labels_train after:  Counter({0.0: 191, 1.0: 49})\n",
      "old_score: 0.761388822735572\n",
      "population_score: 0.6435346689923349\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 151, 1.0: 41})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (144, 5)\n",
      "origin_labels_train after:  Counter({0.0: 191, 1.0: 49})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 152, 1.0: 40})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (144, 5)\n",
      "origin_labels_train after:  Counter({0.0: 188, 1.0: 52})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 154, 1.0: 38})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (144, 5)\n",
      "origin_labels_train after:  Counter({0.0: 190, 1.0: 50})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 155, 1.0: 37})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (144, 5)\n",
      "origin_labels_train after:  Counter({0.0: 190, 1.0: 50})\n",
      "old_score: 0.761388822735572\n",
      "population_score: 0.6850809716599191\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 153, 1.0: 39})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (144, 5)\n",
      "origin_labels_train after:  Counter({0.0: 189, 1.0: 51})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 154, 1.0: 38})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (144, 5)\n",
      "origin_labels_train after:  Counter({0.0: 197, 1.0: 43})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 152, 1.0: 40})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (144, 5)\n",
      "origin_labels_train after:  Counter({0.0: 190, 1.0: 50})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 156, 1.0: 36})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (144, 5)\n",
      "origin_labels_train after:  Counter({0.0: 195, 1.0: 45})\n",
      "old_score: 0.761388822735572\n",
      "population_score: 0.7488573999100315\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 156, 1.0: 36})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (144, 5)\n",
      "origin_labels_train after:  Counter({0.0: 195, 1.0: 45})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 151, 1.0: 41})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (144, 5)\n",
      "origin_labels_train after:  Counter({0.0: 188, 1.0: 52})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 153, 1.0: 39})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (144, 5)\n",
      "origin_labels_train after:  Counter({0.0: 193, 1.0: 47})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 150, 1.0: 42})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (144, 5)\n",
      "origin_labels_train after:  Counter({0.0: 189, 1.0: 51})\n",
      "old_score: 0.761388822735572\n",
      "population_score: 0.7633169462116831\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 153, 1.0: 39})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (144, 5)\n",
      "origin_labels_train after:  Counter({0.0: 190, 1.0: 50})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 152, 1.0: 40})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (144, 5)\n",
      "origin_labels_train after:  Counter({0.0: 189, 1.0: 51})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 154, 1.0: 38})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (144, 5)\n",
      "origin_labels_train after:  Counter({0.0: 193, 1.0: 47})\n",
      "origin_feat_train before:  (192, 5)\n",
      "origin_labels_train before:  Counter({0.0: 150, 1.0: 42})\n",
      "origin_feat_train after:  (240, 5)\n",
      "population_features:  (144, 5)\n",
      "origin_labels_train after:  Counter({0.0: 186, 1.0: 54})\n",
      "old_score: 0.761388822735572\n",
      "population_score: 0.638169802333889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:570: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jacob\\AppData\\Local\\Temp\\ipykernel_31660\\3083189773.py:75: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  randomForest_Base = randomForest.fit(data_train.drop([\"5\"], axis=1), data_train.drop(data_train_AIS.columns[0:-1],axis=1))\n",
      "c:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:207: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score GradientBoosting: \n",
      "0.7057291666666666\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score GradientBoosting AIS: \n",
      "0.8567708333333334\n",
      "\n",
      "Best score KNeighbors: \n",
      "0.7109375\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score KNeighbors AIS: \n",
      "0.8203125\n",
      "\n",
      "Best score Logistic Regression: \n",
      "0.6171875\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score Logistic Regression AIS: \n",
      "0.8098958333333333\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "c:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score RandomForest: \n",
      "0.6901041666666667\n",
      "\n",
      "Best score RandomForest AIS: \n",
      "0.890625\n",
      "\n",
      "  Oversample Oversample Run Time        Oversample Paramaters  \\\n",
      "0        AIS           55.636309  MinChange = 0.005, LOF=True   \n",
      "1      SMOTE             0.00905                           NA   \n",
      "2       BASE                  NA                           NA   \n",
      "\n",
      "   ROC Accuracy for Gradient Boosting  \\\n",
      "0                            0.563636   \n",
      "1                            0.627273   \n",
      "2                            0.681818   \n",
      "\n",
      "   Balanced Test Accuracy for Gradient Boosting  \\\n",
      "0                                      0.563636   \n",
      "1                                      0.627273   \n",
      "2                                      0.681818   \n",
      "\n",
      "   ROC Accuracy for Random Forests  Balanced Test Accuracy for Random Forests  \\\n",
      "0                         0.681818                                   0.681818   \n",
      "1                         0.500000                                   0.500000   \n",
      "2                         0.554545                                   0.554545   \n",
      "\n",
      "   ROC Accuracy for Logistic Regression  \\\n",
      "0                              0.545455   \n",
      "1                              0.445455   \n",
      "2                              0.500000   \n",
      "\n",
      "   Balanced Test Accuracy for Logistic Regression  \\\n",
      "0                                        0.545455   \n",
      "1                                        0.445455   \n",
      "2                                        0.500000   \n",
      "\n",
      "   ROC Accuracy for K Nearest Neighbours  \\\n",
      "0                               0.500000   \n",
      "1                               0.590909   \n",
      "2                               0.500000   \n",
      "\n",
      "   Balanced Test Accuracy for K Nearest Neighbours  \\\n",
      "0                                         0.500000   \n",
      "1                                         0.590909   \n",
      "2                                         0.500000   \n",
      "\n",
      "   Geometric Mean Score for Gradient Boosting  \\\n",
      "0                                    0.430644   \n",
      "1                                    0.584652   \n",
      "2                                    0.620850   \n",
      "\n",
      "   Geometric Mean Score for Random Forest  \\\n",
      "0                                0.620850   \n",
      "1                                0.400000   \n",
      "2                                0.426401   \n",
      "\n",
      "   Geometric Mean Score for Logestic Regression  \\\n",
      "0                                      0.422116   \n",
      "1                                      0.371728   \n",
      "2                                      0.000000   \n",
      "\n",
      "   Geometric Mean Score for K Neighbors  \n",
      "0                               0.00000  \n",
      "1                               0.55922  \n",
      "2                               0.00000  \n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "\n",
    "for result in kf.split(df):\n",
    "    \n",
    "    #Print the shape of the train and test set\n",
    "    data_train = df.iloc[result[0]]\n",
    "    data_test =  df.iloc[result[1]]\n",
    "    #print(f\"Train Data shape: \\n{data_train}\\n\")\n",
    "    #print(f\"Test Data shape: \\n{data_test}\\n\")\n",
    "\n",
    "\n",
    "    data_train_AIS = data_train.copy()\n",
    "    data_train_SMOTE = data_train.copy()\n",
    "\n",
    "    #Create an oversampling object\n",
    "    \n",
    "    oversample = SMOTE()\n",
    "    \n",
    "\n",
    "\n",
    "    oversample_AIS = ArtificialImmuneSystem()\n",
    "    #Oversample and add to the dataframe to fix the class imbalance\n",
    "    randomForest = RandomForestClassifier()\n",
    "\n",
    "    st = time.time()\n",
    "    x_over, y_over = oversample.fit_resample(data_train_SMOTE.drop([\"5\"], axis=1), data_train_SMOTE.drop(data_train_SMOTE.columns[0:-1],axis=1))\n",
    "    elapsed_time_SMOTE = time.time() - st\n",
    "\n",
    "    st = time.time()\n",
    "    input_x_over_AIS, y_over_AIS = oversample_AIS.AIS_Resample(data_train_AIS.drop([\"5\"], axis=1), data_train_AIS.drop(data_train_AIS.columns[0:-1],axis=1), 20, 5, randomForest,5,'balanced_accuracy',min_change = 0.005, use_lof = True)\n",
    "    elapsed_time_AIS = time.time() - st\n",
    "\n",
    "    smote_df = pd.concat([x_over, y_over], axis=1)\n",
    "    ais_df = pd.concat([input_x_over_AIS, y_over_AIS], axis=1)\n",
    "\n",
    "    # print the dimensionality of the oversampled dataset\n",
    "    #print(f\"SMOTE Oversampled Data shape: \\n{smote_df.shape}\\n\")\n",
    "    #print(f\"SMOTE Oversampled Data size: \\n{smote_df.size}\\n\")\n",
    "    #print(f\"SMOTE Oversampled Data ndim: \\n{smote_df.ndim}\\n\")\n",
    "    #print(\"_____________________________________________\\n\")\n",
    "\n",
    "    # print the dimensionality of the oversampled dataset\n",
    "    #print(f\"AIS Oversampled Data shape: \\n{ais_df.shape}\\n\")\n",
    "    #print(f\"AIS Oversampled Data size: \\n{ais_df.size}\\n\")\n",
    "    #print(f\"AIS Oversampled Data ndim: \\n{ais_df.ndim}\\n\")\n",
    "    #print(\"_____________________________________________\\n\")\n",
    "\n",
    "\n",
    "    # print the new class distribution using a Counter\n",
    "    #print(f\"New SMOTE Class Distribution: {Counter(smote_df['5'])}\")\n",
    "    #print(f\"New AIS Class Distribution: {Counter(ais_df['5'])}\")\n",
    "    ## print the new class distribution using a Counter\n",
    "    #print(f\"Old Class Distribution: {Counter(data_train['5'])}\")\n",
    "\n",
    "    #print(\"_____________________________________________\\n\")\n",
    "\n",
    "    #labelTrainFlat = labels_train.values.ravel()\n",
    "\n",
    "    #Fit one vs rest Gradient Boosting classification\n",
    "    gradientBoosting = GradientBoostingClassifier()\n",
    "    gradientBoosting = gradientBoosting.fit(x_over, y_over.values.ravel())\n",
    "\n",
    "    gradientBoosting_AIS = GradientBoostingClassifier()\n",
    "    gradientBoosting_AIS = gradientBoosting.fit(input_x_over_AIS, y_over_AIS.values.ravel())\n",
    "\n",
    "    gradientBoosting_Base = gradientBoosting.fit(data_train.drop([\"5\"], axis=1), data_train.drop(data_train_AIS.columns[0:-1],axis=1))\n",
    "\n",
    "    #Fit RandomForestClassifier classification\n",
    "    randomForest = RandomForestClassifier()\n",
    "    randomForest = randomForest.fit(x_over,y_over.values.ravel())\n",
    "\n",
    "    randomForest = RandomForestClassifier()\n",
    "    randomForest_AIS  = randomForest.fit(input_x_over_AIS,y_over_AIS.values.ravel())\n",
    "\n",
    "    randomForest_Base = randomForest.fit(data_train.drop([\"5\"], axis=1), data_train.drop(data_train_AIS.columns[0:-1],axis=1))\n",
    "    #randomForest_Base  = randomForest.fit(data_train.drop([\"5\"], axis=1), data_train.drop(data_train_AIS.columns[0:-1]).values.ravel())\n",
    "\n",
    "    #Create a KNeighbors classification object\n",
    "    kNeighbors = KNeighborsClassifier()\n",
    "    kNeighbors = kNeighbors.fit(x_over,y_over.values.ravel())\n",
    "\n",
    "    kNeighbors = KNeighborsClassifier()\n",
    "    kNeighbors_AIS  = kNeighbors.fit(input_x_over_AIS,y_over_AIS.values.ravel())\n",
    "    kNeighbors_Base = kNeighbors.fit(data_train.drop([\"5\"], axis=1), data_train.drop(data_train_AIS.columns[0:-1],axis=1))\n",
    "    #kNeighbors_base  = kNeighbors.fit(data_train.drop([\"5\"], axis=1), data_train.drop(data_train_AIS.columns[0:-1]).values.ravel())\n",
    "\n",
    "    #Create an LogisticRegression object\n",
    "    logisticRegression = LogisticRegression(max_iter=5000)\n",
    "    logisticRegression = logisticRegression.fit(x_over,y_over.values.ravel())\n",
    "\n",
    "    logisticRegression = LogisticRegression(max_iter=5000)\n",
    "    logisticRegression_AIS  = logisticRegression.fit(input_x_over_AIS,y_over_AIS.values.ravel())\n",
    "    logisticRegression_Base = logisticRegression.fit(data_train.drop([\"5\"], axis=1), data_train.drop(data_train_AIS.columns[0:-1],axis=1))\n",
    "    #logisticRegression_Base  = logisticRegression.fit(data_train.drop([\"5\"], axis=1), data_train.drop(data_train_AIS.columns[0:-1]).values.ravel())\n",
    "\n",
    "    #Set the parameters of GradientBoosting for GridSearchCV\n",
    "    parametersGradientBoosting = [\n",
    "        {'learning_rate': [0.44,0.45,0.46],'min_samples_leaf': [5,6,7],'min_samples_split': [7,8,9,10], 'n_estimators': [57,58,59,60]}\n",
    "    ]\n",
    "\n",
    "    #Set the scoring parameters\n",
    "    scoringX = {\"roc_auc\": \"roc_auc\", \"bal_accuracy\": \"balanced_accuracy\"}\n",
    "\n",
    "    #Preform Gridsearch to find best parameters\n",
    "    grid_searchGradientBoosting = GridSearchCV(gradientBoosting, parametersGradientBoosting, cv=4, scoring = scoringX, return_train_score=True, n_jobs=-1, refit='bal_accuracy')\n",
    "    grid_searchGradientBoosting_AIS = GridSearchCV(gradientBoosting_AIS, parametersGradientBoosting, cv=4, scoring = scoringX, return_train_score=True, n_jobs=-1, refit='bal_accuracy')\n",
    "    #grid_searchGradientBoosting_Base = GridSearchCV(gradientBoosting_Base, parametersGradientBoosting, cv=4, scoring = scoringX, return_train_score=True, n_jobs=-1, refit='bal_accuracy')\n",
    "    #Fit the GradientBoosting \n",
    "    grid_searchGradientBoosting.fit(x_over, y_over.values.ravel())\n",
    "    grid_searchGradientBoosting_AIS.fit(input_x_over_AIS,y_over_AIS.values.ravel())\n",
    "  \n",
    "    \n",
    "\n",
    "    #Print GridSearchCV Results\n",
    "    \n",
    "    print(f\"Best score GradientBoosting: \\n{grid_searchGradientBoosting.best_score_}\\n\")\n",
    "    print(\"_____________________________________________\\n\")\n",
    "    \n",
    "    print(f\"Best score GradientBoosting AIS: \\n{grid_searchGradientBoosting_AIS.best_score_}\\n\")\n",
    "\n",
    "    #Set the parameters of KNeighbors for GridSearchCV\n",
    "    parametersKNeighbors = [\n",
    "        {'n_neighbors': [1,2,3],'weights':['uniform', 'distance'],'algorithm':['auto'], 'p': [1,2,3]}\n",
    "    ]\n",
    "\n",
    "    #Set the scoring parameters\n",
    "    scoringX = {\"roc_auc\": \"roc_auc\", \"bal_accuracy\": \"balanced_accuracy\"}\n",
    "\n",
    "    #Preform KNeighbors to find best parameters\n",
    "    grid_searchKNeighbors = GridSearchCV(kNeighbors, parametersKNeighbors, cv=4, scoring = scoringX, return_train_score=True, n_jobs=-1, refit='bal_accuracy')\n",
    "    grid_searchKNeighbors_AIS = GridSearchCV(kNeighbors_AIS, parametersKNeighbors, cv=4, scoring = scoringX, return_train_score=True, n_jobs=-1, refit='bal_accuracy')\n",
    "\n",
    "    #Fit the KNeighbors \n",
    "    grid_searchKNeighbors.fit(x_over, y_over.values.ravel())\n",
    "    grid_searchKNeighbors_AIS.fit(input_x_over_AIS,y_over_AIS.values.ravel())\n",
    "\n",
    "    #Print GridSearchCV Results\n",
    "   \n",
    "    print(f\"Best score KNeighbors: \\n{grid_searchKNeighbors.best_score_}\\n\")\n",
    "    print(\"_____________________________________________\\n\")\n",
    "   \n",
    "    print(f\"Best score KNeighbors AIS: \\n{grid_searchKNeighbors_AIS.best_score_}\\n\")\n",
    "    \n",
    "    #Set the parameters of LogisticRegression for GridSearchCV\n",
    "    parametersLogisticRegression = [\n",
    "        {'multi_class': ['ovr'],'penalty':['none','l2'], 'C': [1,2,3]}\n",
    "    ]\n",
    "    scoringX = {\"roc_auc\": \"roc_auc\", \"bal_accuracy\": \"balanced_accuracy\"}\n",
    "\n",
    "    #Preform LogisticRegression to find best parameters\n",
    "    grid_searchLogisticRegression = GridSearchCV(logisticRegression, parametersLogisticRegression, cv=4, scoring = scoringX, return_train_score=True, n_jobs=-1, refit='bal_accuracy')\n",
    "    grid_searchLogisticRegression_AIS = GridSearchCV(logisticRegression_AIS, parametersLogisticRegression, cv=4, scoring = scoringX, return_train_score=True, n_jobs=-1, refit='bal_accuracy')\n",
    "\n",
    "    #Fit the LogisticRegression \n",
    "    grid_searchLogisticRegression.fit(x_over, y_over.values.ravel())\n",
    "    grid_searchLogisticRegression_AIS.fit(input_x_over_AIS,y_over_AIS.values.ravel())\n",
    "\n",
    "    #Print LogisticRegression Results\n",
    "    \n",
    "    print(f\"Best score Logistic Regression: \\n{grid_searchLogisticRegression.best_score_}\\n\")\n",
    "    print(\"_____________________________________________\\n\")\n",
    "   \n",
    "    print(f\"Best score Logistic Regression AIS: \\n{grid_searchLogisticRegression_AIS.best_score_}\\n\")\n",
    "\n",
    "    #Set the parameters of RandomForest for GridSearchCV\n",
    "    parametersRandomForest = [\n",
    "        {'n_estimators': [145,150,155,190],'max_depth': [10,12], 'bootstrap': [True, False],\n",
    "        'min_samples_split': [0.05,2], 'max_features': ['auto']}\n",
    "    ]\n",
    "\n",
    "    #Preform Gridsearch to find best parameters\n",
    "    grid_searchRandomForest = GridSearchCV(randomForest, parametersRandomForest, cv=4, scoring = scoringX, return_train_score=True, n_jobs=-1, refit='bal_accuracy')\n",
    "    grid_searchRandomForest_AIS = GridSearchCV(randomForest_AIS, parametersRandomForest, cv=4, scoring = scoringX, return_train_score=True, n_jobs=-1, refit='bal_accuracy')\n",
    "\n",
    "    #Fit the RandomForest \n",
    "    grid_searchRandomForest.fit(x_over, y_over.values.ravel())\n",
    "    grid_searchRandomForest_AIS.fit(input_x_over_AIS,y_over_AIS.values.ravel())\n",
    "\n",
    "    #Print GridSearchCV Results\n",
    "\n",
    "    print(f\"Best score RandomForest: \\n{grid_searchRandomForest.best_score_}\\n\")\n",
    "\n",
    "    print(f\"Best score RandomForest AIS: \\n{grid_searchRandomForest_AIS.best_score_}\\n\")\n",
    "\n",
    "    #Get the results for all classifiers \n",
    "    cross_val_resultsGB = grid_searchGradientBoosting.cv_results_\n",
    "    cross_val_resultsRF = grid_searchRandomForest.cv_results_\n",
    "    cross_val_resultsLR = grid_searchLogisticRegression.cv_results_\n",
    "    cross_val_resultsKN = grid_searchKNeighbors.cv_results_\n",
    "\n",
    "    cross_val_resultsGB_AIS = grid_searchGradientBoosting_AIS.cv_results_\n",
    "    cross_val_resultsRF_AIS = grid_searchRandomForest_AIS.cv_results_\n",
    "    cross_val_resultsLR_AIS = grid_searchLogisticRegression_AIS.cv_results_\n",
    "    cross_val_resultsKN_AIS = grid_searchKNeighbors_AIS.cv_results_\n",
    "\n",
    "\n",
    "    #Print the results of all classiifiers\n",
    "    #GBC\n",
    "    mean_test_roc_aucGB = mean(cross_val_resultsGB['mean_test_roc_auc'])\n",
    "    mean_test_bal_accuracyGB = mean(cross_val_resultsGB['mean_test_bal_accuracy'])\n",
    "    \n",
    "    mean_test_roc_aucGB_AIS = mean(cross_val_resultsGB_AIS['mean_test_roc_auc'])\n",
    "    mean_test_bal_accuracyGB_AIS = mean(cross_val_resultsGB_AIS['mean_test_bal_accuracy'])\n",
    "   \n",
    "    #RFC\n",
    "    mean_test_roc_aucRF = mean(cross_val_resultsRF['mean_test_roc_auc'])\n",
    "    mean_test_bal_accuracyRF = mean(cross_val_resultsRF['mean_test_bal_accuracy'])\n",
    "    \n",
    "    mean_test_roc_aucRF_AIS = mean(cross_val_resultsRF_AIS['mean_test_roc_auc'])\n",
    "    mean_test_bal_accuracyRF_AIS = mean(cross_val_resultsRF_AIS['mean_test_bal_accuracy'])\n",
    "    #LRC\n",
    "    mean_test_roc_aucLR = mean(cross_val_resultsLR['mean_test_roc_auc'])\n",
    "    mean_test_bal_accuracyLR = mean(cross_val_resultsLR['mean_test_bal_accuracy'])\n",
    "    \n",
    "    mean_test_roc_aucLR_AIS = mean(cross_val_resultsLR_AIS['mean_test_roc_auc'])\n",
    "    mean_test_bal_accuracyLR_AIS = mean(cross_val_resultsLR_AIS['mean_test_bal_accuracy'])\n",
    "\n",
    "    #KNC\n",
    "    mean_test_roc_aucKN = mean(cross_val_resultsKN['mean_test_roc_auc'])\n",
    "    mean_test_bal_accuracyKN = mean(cross_val_resultsKN['mean_test_bal_accuracy'])\n",
    "    \n",
    "    mean_test_roc_aucKN_AIS = mean(cross_val_resultsKN_AIS['mean_test_roc_auc'])\n",
    "    mean_test_bal_accuracyKN_AIS = mean(cross_val_resultsKN_AIS['mean_test_bal_accuracy'])\n",
    "\n",
    "    predictions_test_over_GB = grid_searchGradientBoosting.best_estimator_.predict(data_test.drop([\"5\"],axis=1))\n",
    "    predictions_test_over_RF = grid_searchRandomForest.best_estimator_.predict(data_test.drop([\"5\"],axis=1))\n",
    "    predictions_test_over_LR = grid_searchLogisticRegression.best_estimator_.predict(data_test.drop([\"5\"],axis=1))\n",
    "    predictions_test_over_KN = grid_searchKNeighbors.best_estimator_.predict(data_test.drop([\"5\"],axis=1))\n",
    "\n",
    "    predictions_test_over_GB_AIS = grid_searchGradientBoosting_AIS.best_estimator_.predict(data_test.drop([\"5\"],axis=1))\n",
    "    predictions_test_over_RF_AIS = grid_searchRandomForest_AIS.best_estimator_.predict(data_test.drop([\"5\"],axis=1))\n",
    "    predictions_test_over_LR_AIS = grid_searchLogisticRegression_AIS.best_estimator_.predict(data_test.drop([\"5\"],axis=1))\n",
    "    predictions_test_over_KN_AIS = grid_searchKNeighbors_AIS.best_estimator_.predict(data_test.drop([\"5\"],axis=1))\n",
    "\n",
    "    predictions_GB = gradientBoosting_Base.predict(data_test.drop([\"5\"],axis=1))\n",
    "    predictions_RF = randomForest_Base.predict(data_test.drop([\"5\"],axis=1))\n",
    "    predictions_LR = logisticRegression_Base.predict(data_test.drop([\"5\"],axis=1))\n",
    "    predictions_KN = kNeighbors_Base.predict(data_test.drop([\"5\"],axis=1))\n",
    "\n",
    "    geometric_mean_score_GB = geometric_mean_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_GB, labels=None, pos_label=1, average='binary',)\n",
    "    geometric_mean_score_RF = geometric_mean_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_RF, labels=None, pos_label=1, average='binary',)\n",
    "    geometric_mean_score_LR = geometric_mean_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_LR, labels=None, pos_label=1, average='binary',)\n",
    "    geometric_mean_score_KN = geometric_mean_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_KN, labels=None, pos_label=1, average='binary',)\n",
    "\n",
    "    geometric_mean_score_GB_AIS = geometric_mean_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_GB_AIS, labels=None, pos_label=1, average='binary',)\n",
    "    geometric_mean_score_RF_AIS = geometric_mean_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_RF_AIS, labels=None, pos_label=1, average='binary',)\n",
    "    geometric_mean_score_LR_AIS = geometric_mean_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_LR_AIS, labels=None, pos_label=1, average='binary',)\n",
    "    geometric_mean_score_KN_AIS = geometric_mean_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_KN_AIS, labels=None, pos_label=1, average='binary',)\n",
    "\n",
    "    geometric_mean_score_GB_Base = geometric_mean_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_GB, labels=None, pos_label=1, average='binary',)\n",
    "    geometric_mean_score_RF_Base = geometric_mean_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_RF, labels=None, pos_label=1, average='binary',)\n",
    "    geometric_mean_score_LR_Base = geometric_mean_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_LR, labels=None, pos_label=1, average='binary',)\n",
    "    geometric_mean_score_KN_Base = geometric_mean_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_KN, labels=None, pos_label=1, average='binary',)\n",
    "\n",
    "    \n",
    "    roc_auc_GB_AIS = roc_auc_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_GB_AIS)\n",
    "    roc_auc_RF_AIS = roc_auc_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_RF_AIS)\n",
    "    roc_auc_LR_AIS = roc_auc_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_LR_AIS)\n",
    "    roc_auc_KN_AIS = roc_auc_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_KN_AIS)\n",
    " \n",
    "    balanced_acc_GB_AIS = balanced_accuracy_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_GB_AIS)\n",
    "    balanced_acc_RF_AIS = balanced_accuracy_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_RF_AIS)\n",
    "    balanced_acc_LR_AIS = balanced_accuracy_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_LR_AIS)\n",
    "    balanced_acc_KN_AIS = balanced_accuracy_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_KN_AIS)\n",
    "\n",
    "    roc_auc_GB = roc_auc_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_GB)\n",
    "    roc_auc_RF = roc_auc_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_RF)\n",
    "    roc_auc_LR = roc_auc_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_LR)\n",
    "    roc_auc_KN = roc_auc_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_KN)\n",
    " \n",
    "    balanced_acc_GB = balanced_accuracy_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_GB)\n",
    "    balanced_acc_RF = balanced_accuracy_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_RF)\n",
    "    balanced_acc_LR = balanced_accuracy_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_LR)\n",
    "    balanced_acc_KN = balanced_accuracy_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_KN)\n",
    "\n",
    "    roc_auc_GB_Base = roc_auc_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_GB)\n",
    "    roc_auc_RF_Base = roc_auc_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_RF)\n",
    "    roc_auc_LR_Base = roc_auc_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_LR)\n",
    "    roc_auc_KN_Base = roc_auc_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_KN)\n",
    " \n",
    "    balanced_acc_GB_Base = balanced_accuracy_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_GB)\n",
    "    balanced_acc_RF_Base = balanced_accuracy_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_RF)\n",
    "    balanced_acc_LR_Base = balanced_accuracy_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_LR)\n",
    "    balanced_acc_KN_Base = balanced_accuracy_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_KN)\n",
    "\n",
    "    col_names = [\"Oversample\",\"Oversample Run Time\", \"Oversample Paramaters\", \"ROC Accuracy for Gradient Boosting\", \"Balanced Test Accuracy for Gradient Boosting\", \"ROC Accuracy for Random Forests\", \"Balanced Test Accuracy for Random Forests\" , \"ROC Accuracy for Logistic Regression\", \"Balanced Test Accuracy for Logistic Regression\", \"ROC Accuracy for K Nearest Neighbours\", \"Balanced Test Accuracy for K Nearest Neighbours\", \"Geometric Mean Score for Gradient Boosting\", \"Geometric Mean Score for Random Forest\", \"Geometric Mean Score for Logestic Regression\", \"Geometric Mean Score for K Neighbors\"]\n",
    "    dataAIS = [\"AIS\", elapsed_time_AIS,\"MinChange = 0.005, LOF=True\", roc_auc_GB_AIS, balanced_acc_GB_AIS, roc_auc_RF_AIS, balanced_acc_RF_AIS, roc_auc_LR_AIS, balanced_acc_LR_AIS, roc_auc_KN_AIS, balanced_acc_KN_AIS, geometric_mean_score_GB_AIS, geometric_mean_score_RF_AIS, geometric_mean_score_LR_AIS, geometric_mean_score_KN_AIS]\n",
    "    dataSMOTE = [\"SMOTE\", elapsed_time_SMOTE,\"NA\", roc_auc_GB, balanced_acc_GB, roc_auc_RF, balanced_acc_RF, roc_auc_LR, balanced_acc_LR, roc_auc_KN, balanced_acc_KN, geometric_mean_score_GB, geometric_mean_score_RF, geometric_mean_score_LR, geometric_mean_score_KN]\n",
    "    dataBase = [\"BASE\", \"NA\",\"NA\", roc_auc_GB_Base, balanced_acc_GB_Base, roc_auc_RF_Base, balanced_acc_RF_Base, roc_auc_LR_Base, balanced_acc_LR_Base, roc_auc_KN_Base, balanced_acc_KN_Base, geometric_mean_score_GB_Base, geometric_mean_score_RF_Base, geometric_mean_score_LR_Base, geometric_mean_score_KN_Base]\n",
    "    data = [dataAIS,dataSMOTE,dataBase]\n",
    "\n",
    "    dfoutput=pd.DataFrame(data,columns=col_names)\n",
    "    print(dfoutput)\n",
    "    title = \"ExperimentalResults/ExperimentalComparisons-Dec05DEMO1.csv\"\n",
    "    dfoutput.to_csv(title, mode='a') \n",
    "\n",
    "col_names = [\"\",\"\", \"\", \"\", \"\", \"\", \"\" , \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"]\n",
    "dfoutput=pd.DataFrame(col_names)\n",
    "dfoutput.to_csv(title, mode='a',header=False,index=False) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aisOversample = ArtificialImmuneSystem()\n",
    "#minority_class = df[df['5'] == 1]\n",
    "#majority_class = df[df['5'] == 0]\n",
    "\n",
    "#requiredPopulation = len(majority_class)-len(minority_class)\n",
    "#population = aisOversample.AIS(minority_class, max_rounds=100, totalPopulation=requiredPopulation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting Labels\n",
    "#Get a list of all columns\n",
    "#columns = data_train.columns.to_list()\n",
    "#Remove the label and save it\n",
    "#columns_drop = columns.pop(-1)\n",
    "\n",
    "#Remove all labels except for the label in the train and test dataframe\n",
    "#labels_train = data_train.drop(columns, axis=1)\n",
    "#labels_test = data_test.drop(columns, axis=1)\n",
    "\n",
    "#Print the labesl of the test and train\n",
    "#print(f\"labels_train: \\n{labels_train}\\n\")\n",
    "#print(f\"labels_test: \\n{labels_test}\\n\")\n",
    "\n",
    "#Remove the label from the train and test dataframe\n",
    "#features_train = data_train.drop(['5'], axis=1)\n",
    "#features_test = data_test.drop(['5'], axis=1)\n",
    "\n",
    "#Print the features of the train and test dataset\n",
    "#print(f\"features_train: \\n{features_train }\\n\")\n",
    "#print(f\"lfeatures_test: \\n{features_test }\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('csi4106')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "51ea9996f2a91c7d112e626959c304b606e4bf2254e73fec145d965796b2ca69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
