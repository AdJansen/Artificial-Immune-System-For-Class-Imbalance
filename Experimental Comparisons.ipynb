{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from collections import Counter\n",
    "\n",
    "from ArtificialImmuneSystem import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Data\\GeneratedSyntheticData-NoiselessInformativeEasy.csv')\n",
    "df = df.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: \n",
      "(300, 6)\n",
      "\n",
      "Data size: \n",
      "1800\n",
      "\n",
      "Data ndim: \n",
      "2\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Old Class Distribution: Counter({0.0: 210, 1.0: 90})\n"
     ]
    }
   ],
   "source": [
    "print(f\"Data shape: \\n{df.shape}\\n\")\n",
    "print(f\"Data size: \\n{df.size}\\n\")\n",
    "print(f\"Data ndim: \\n{df.ndim}\\n\")\n",
    "print(\"_____________________________________________\\n\")\n",
    "print(f\"Old Class Distribution: {Counter(df['5'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oversampled Data shape: \n",
      "(300, 6)\n",
      "\n",
      "Oversampled Data size: \n",
      "1800\n",
      "\n",
      "Oversampled Data ndim: \n",
      "2\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "New Class Distribution: Counter({0.0: 210, 1.0: 210})\n",
      "_____________________________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Create an oversampling object\n",
    "oversample = SMOTE()\n",
    "#Oversample and add to the dataframe to fix the class imbalance\n",
    "x_over, y_over = oversample.fit_resample(df.drop([\"5\"], axis=1), df.drop(df.columns[0:-1],axis=1))\n",
    "smote_df = pd.concat([x_over, y_over], axis=1)\n",
    "\n",
    "# print the dimensionality of the oversampled dataset\n",
    "print(f\"Oversampled Data shape: \\n{df.shape}\\n\")\n",
    "print(f\"Oversampled Data size: \\n{df.size}\\n\")\n",
    "print(f\"Oversampled Data ndim: \\n{df.ndim}\\n\")\n",
    "print(\"_____________________________________________\\n\")\n",
    "\n",
    "\n",
    "# print the new class distribution using a Counter\n",
    "print(f\"New Class Distribution: {Counter(smote_df['5'])}\")\n",
    "\n",
    "print(\"_____________________________________________\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 182, in fit\n    y = self._validate_targets(y)\n  File \"c:\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 739, in _validate_targets\n    raise ValueError(\nValueError: The number of classes has to be greater than one; got 1 class\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [5], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m majority_class \u001b[39m=\u001b[39m df[df[\u001b[39m'\u001b[39m\u001b[39m5\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m]\n\u001b[0;32m      5\u001b[0m requiredPopulation \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(majority_class)\u001b[39m-\u001b[39m\u001b[39mlen\u001b[39m(minority_class)\n\u001b[1;32m----> 6\u001b[0m population \u001b[39m=\u001b[39m aisOversample\u001b[39m.\u001b[39mAIS(minority_class, max_rounds\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m, totalPopulation\u001b[39m=\u001b[39mrequiredPopulation)\n",
      "File \u001b[1;32mc:\\Users\\adamj\\Documents\\GitHub\\Artificial-Immune-System-For-Class-Imbalance\\ArtificialImmuneSystem.py:199\u001b[0m, in \u001b[0;36mArtificialImmuneSystem.AIS\u001b[1;34m(self, df, max_rounds, totalPopulation)\u001b[0m\n\u001b[0;32m    196\u001b[0m count\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m    198\u001b[0m \u001b[39m#change hardcoded\u001b[39;00m\n\u001b[1;32m--> 199\u001b[0m \u001b[39mif\u001b[39;00m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcomparePopulations(current_gen,next_gen,current_labels,next_labels,svm\u001b[39m.\u001b[39;49mSVC(random_state\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m), \u001b[39m5\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mf1_macro\u001b[39;49m\u001b[39m'\u001b[39;49m)):\n\u001b[0;32m    201\u001b[0m     no_change \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m    203\u001b[0m     current_gen \u001b[39m=\u001b[39m next_gen\u001b[39m.\u001b[39mcopy()\n",
      "File \u001b[1;32mc:\\Users\\adamj\\Documents\\GitHub\\Artificial-Immune-System-For-Class-Imbalance\\ArtificialImmuneSystem.py:158\u001b[0m, in \u001b[0;36mArtificialImmuneSystem.comparePopulations\u001b[1;34m(self, population1, population2, labels1, labels2, estimator, iterations, scorer)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcomparePopulations\u001b[39m(\u001b[39mself\u001b[39m,population1, population2, labels1, labels2, estimator, iterations, scorer):\n\u001b[1;32m--> 158\u001b[0m     score1 \u001b[39m=\u001b[39m fmean(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfitness(estimator, population1, labels1\u001b[39m.\u001b[39;49mvalues\u001b[39m.\u001b[39;49mravel(), iterations, scorer))\n\u001b[0;32m    159\u001b[0m     score2 \u001b[39m=\u001b[39m fmean(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfitness(estimator, population2, labels2\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mravel(), iterations, scorer))\n\u001b[0;32m    161\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mabs\u001b[39m(score1 \u001b[39m-\u001b[39m score2) \u001b[39m<\u001b[39m \u001b[39m0.005\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\adamj\\Documents\\GitHub\\Artificial-Immune-System-For-Class-Imbalance\\ArtificialImmuneSystem.py:101\u001b[0m, in \u001b[0;36mArtificialImmuneSystem.fitness\u001b[1;34m(self, model, feat, label, iterations, scorer)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfitness\u001b[39m(\u001b[39mself\u001b[39m, model, feat, label, iterations, scorer):\n\u001b[0;32m     99\u001b[0m     \u001b[39m#scorer is the name of the function wee aree using to evaluate our dataset\u001b[39;00m\n\u001b[0;32m    100\u001b[0m     \u001b[39m#it should be a function with signature scorer(model, feature, label) which should return only a single value.\u001b[39;00m\n\u001b[1;32m--> 101\u001b[0m     \u001b[39mreturn\u001b[39;00m cross_val_score(model, feat, label, cv \u001b[39m=\u001b[39;49m iterations, scoring \u001b[39m=\u001b[39;49m scorer)\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:515\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[39m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    513\u001b[0m scorer \u001b[39m=\u001b[39m check_scoring(estimator, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[1;32m--> 515\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(\n\u001b[0;32m    516\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m    517\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m    518\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    519\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[0;32m    520\u001b[0m     scoring\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mscore\u001b[39;49m\u001b[39m\"\u001b[39;49m: scorer},\n\u001b[0;32m    521\u001b[0m     cv\u001b[39m=\u001b[39;49mcv,\n\u001b[0;32m    522\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    523\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    524\u001b[0m     fit_params\u001b[39m=\u001b[39;49mfit_params,\n\u001b[0;32m    525\u001b[0m     pre_dispatch\u001b[39m=\u001b[39;49mpre_dispatch,\n\u001b[0;32m    526\u001b[0m     error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[0;32m    527\u001b[0m )\n\u001b[0;32m    528\u001b[0m \u001b[39mreturn\u001b[39;00m cv_results[\u001b[39m\"\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:285\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    265\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[0;32m    266\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    268\u001b[0m         clone(estimator),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    282\u001b[0m     \u001b[39mfor\u001b[39;00m train, test \u001b[39min\u001b[39;00m cv\u001b[39m.\u001b[39msplit(X, y, groups)\n\u001b[0;32m    283\u001b[0m )\n\u001b[1;32m--> 285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    287\u001b[0m \u001b[39m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    289\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n\u001b[0;32m    290\u001b[0m \u001b[39mif\u001b[39;00m callable(scoring):\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:367\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[39mif\u001b[39;00m num_failed_fits \u001b[39m==\u001b[39m num_fits:\n\u001b[0;32m    361\u001b[0m     all_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[0;32m    362\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mAll the \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIt is very likely that your model is misconfigured.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    364\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou can try to debug the error by setting error_score=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    365\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    366\u001b[0m     )\n\u001b[1;32m--> 367\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    369\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    370\u001b[0m     some_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[0;32m    371\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mnum_failed_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed out of a total of \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    372\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe score on these train-test partitions for these parameters\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    377\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Python310\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 686, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 182, in fit\n    y = self._validate_targets(y)\n  File \"c:\\Python310\\lib\\site-packages\\sklearn\\svm\\_base.py\", line 739, in _validate_targets\n    raise ValueError(\nValueError: The number of classes has to be greater than one; got 1 class\n"
     ]
    }
   ],
   "source": [
    "aisOversample = ArtificialImmuneSystem()\n",
    "minority_class = df[df['5'] == 1]\n",
    "majority_class = df[df['5'] == 0]\n",
    "\n",
    "requiredPopulation = len(majority_class)-len(minority_class)\n",
    "population = aisOversample.AIS(minority_class, max_rounds=100, totalPopulation=requiredPopulation)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
