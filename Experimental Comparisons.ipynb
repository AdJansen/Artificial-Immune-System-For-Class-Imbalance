{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, cross_val_score, GridSearchCV, cross_validate\n",
    "\n",
    "# importing two different imputation methods that take into consideration all the features when predicting the missing values\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#multiclass imports\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.dummy import DummyClassifier #Will identify the maority calss base line, model needs to do better then the baseline\n",
    "\n",
    "from statistics import mean\n",
    "# to reduce randomness then you put the seed\n",
    "np.random.seed(42)\n",
    "\n",
    "from ArtificialImmuneSystem import *\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from tabulate import tabulate\n",
    "import time\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'Data\\GeneratedSyntheticData-testing.csv'\n",
    "df = pd.read_csv(dataset)\n",
    "#df = df.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: \n",
      "(300, 6)\n",
      "\n",
      "Data size: \n",
      "1800\n",
      "\n",
      "Data ndim: \n",
      "2\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Old Class Distribution: Counter({0.0: 247, 1.0: 53})\n"
     ]
    }
   ],
   "source": [
    "print(f\"Data shape: \\n{df.shape}\\n\")\n",
    "print(f\"Data size: \\n{df.size}\\n\")\n",
    "print(f\"Data ndim: \\n{df.ndim}\\n\")\n",
    "print(\"_____________________________________________\\n\")\n",
    "print(f\"Old Class Distribution: {Counter(df['5'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score1: 0.4652004824141228\n",
      "score2: 0.5564440261378901\n",
      "score1: 0.5564440261378901\n",
      "score2: 0.646919181450358\n",
      "score1: 0.646919181450358\n",
      "score2: 0.3948726435011177\n",
      "score1: 0.646919181450358\n",
      "score2: 0.376295165945166\n",
      "score1: 0.646919181450358\n",
      "score2: 0.25221914440572973\n",
      "score1: 0.646919181450358\n",
      "score2: 0.3635094505494506\n",
      "score1: 0.646919181450358\n",
      "score2: 0.35364278481012656\n",
      "score1: 0.646919181450358\n",
      "score2: 0.4958809994049266\n",
      "score1: 0.646919181450358\n",
      "score2: 0.6387118571478135\n",
      "score1: 0.646919181450358\n",
      "score2: 0.256802477089619\n",
      "score1: 0.646919181450358\n",
      "score2: 0.5185963854784641\n",
      "score1: 0.646919181450358\n",
      "score2: 0.4940918613550192\n",
      "score1: 0.646919181450358\n",
      "score2: 0.5128001665336711\n",
      "score1: 0.646919181450358\n",
      "score2: 0.37199884326200117\n",
      "score1: 0.646919181450358\n",
      "score2: 0.2562891635830464\n",
      "score1: 0.646919181450358\n",
      "score2: 0.48089751562541727\n",
      "score1: 0.646919181450358\n",
      "score2: 0.5277934065934067\n",
      "score1: 0.646919181450358\n",
      "score2: 0.47223958967347357\n",
      "score1: 0.646919181450358\n",
      "score2: 0.5346841269841269\n",
      "score1: 0.646919181450358\n",
      "score2: 0.6588724525212387\n",
      "score1: 0.6588724525212387\n",
      "score2: 0.5804667966737886\n",
      "score1: 0.6588724525212387\n",
      "score2: 0.3711087312687313\n",
      "score1: 0.6588724525212387\n",
      "score2: 0.5998726875957898\n",
      "score1: 0.6588724525212387\n",
      "score2: 0.4062220232616518\n",
      "score1: 0.6588724525212387\n",
      "score2: 0.24538646065555678\n",
      "score1: 0.6588724525212387\n",
      "score2: 0.25797990570388973\n",
      "score1: 0.6588724525212387\n",
      "score2: 0.25305271943246627\n",
      "score1: 0.6588724525212387\n",
      "score2: 0.6716262053136737\n",
      "score1: 0.6716262053136737\n",
      "score2: 0.383245896674944\n",
      "score1: 0.6716262053136737\n",
      "score2: 0.25190564450352904\n",
      "score1: 0.6716262053136737\n",
      "score2: 0.24924199704802116\n",
      "score1: 0.6716262053136737\n",
      "score2: 0.3869408368779788\n",
      "score1: 0.6716262053136737\n",
      "score2: 0.37971543344108144\n",
      "score1: 0.6716262053136737\n",
      "score2: 0.43119509068167605\n",
      "score1: 0.6716262053136737\n",
      "score2: 0.42629285714285714\n",
      "score1: 0.6716262053136737\n",
      "score2: 0.4624829381145171\n",
      "score1: 0.6716262053136737\n",
      "score2: 0.44395927935168444\n",
      "score1: 0.6716262053136737\n",
      "score2: 0.45598579150579155\n",
      "score1: 0.6716262053136737\n",
      "score2: 0.37604040404040406\n",
      "score1: 0.6716262053136737\n",
      "score2: 0.2555807692307692\n",
      "score1: 0.6716262053136737\n",
      "score2: 0.34465461121157326\n",
      "score1: 0.6716262053136737\n",
      "score2: 0.4761884229729375\n",
      "score1: 0.6716262053136737\n",
      "score2: 0.5932548008644644\n",
      "score1: 0.6716262053136737\n",
      "score2: 0.4792033467202142\n",
      "score1: 0.6716262053136737\n",
      "score2: 0.3863818440435761\n",
      "score1: 0.6716262053136737\n",
      "score2: 0.5156213552173116\n",
      "score1: 0.6716262053136737\n",
      "score2: 0.3766863035081621\n",
      "score1: 0.6716262053136737\n",
      "score2: 0.5431448671880504\n",
      "score1: 0.6716262053136737\n",
      "score2: 0.6681391737891739\n",
      "score1: 0.6716262053136737\n",
      "score2: 0.25403734177215187\n",
      "score1: 0.6716262053136737\n",
      "score2: 0.459271567255621\n",
      "score1: 0.6716262053136737\n",
      "score2: 0.4232865414238832\n",
      "score1: 0.6716262053136737\n",
      "score2: 0.45906623049021456\n",
      "score1: 0.6716262053136737\n",
      "score2: 0.46931723817754173\n",
      "score1: 0.6716262053136737\n",
      "score2: 0.477321417538285\n",
      "score1: 0.6716262053136737\n",
      "score2: 0.4248780423280423\n",
      "score1: 0.6716262053136737\n",
      "score2: 0.25806\n",
      "score1: 0.6716262053136737\n",
      "score2: 0.43255347985347986\n",
      "score1: 0.6716262053136737\n",
      "score2: 0.5550928841903525\n",
      "score1: 0.6716262053136737\n",
      "score2: 0.2643220062732258\n",
      "score1: 0.6716262053136737\n",
      "score2: 0.3887856427420252\n",
      "score1: 0.6716262053136737\n",
      "score2: 0.44718603718598826\n",
      "score1: 0.6716262053136737\n",
      "score2: 0.5921868131868131\n",
      "score1: 0.6716262053136737\n",
      "score2: 0.5401705361260991\n",
      "score1: 0.6716262053136737\n",
      "score2: 0.41966987719426746\n",
      "score1: 0.6716262053136737\n",
      "score2: 0.5435153707052441\n",
      "score1: 0.6716262053136737\n",
      "score2: 0.5588783473976879\n",
      "score1: 0.6716262053136737\n",
      "score2: 0.5174681933906149\n",
      "score1: 0.6716262053136737\n",
      "score2: 0.6440816203217625\n",
      "score1: 0.6716262053136737\n",
      "score2: 0.5218827848101266\n",
      "score1: 0.6716262053136737\n",
      "score2: 0.4301355895884541\n",
      "score1: 0.6716262053136737\n",
      "score2: 0.25012026296869216\n",
      "score1: 0.6716262053136737\n",
      "score2: 0.5051590485463903\n",
      "score1: 0.6716262053136737\n",
      "score2: 0.3679553109280455\n",
      "score1: 0.6716262053136737\n",
      "score2: 0.4531145834389737\n",
      "score1: 0.6716262053136737\n",
      "score2: 0.44939930635896985\n",
      "score1: 0.6716262053136737\n",
      "score2: 0.26168610241256124\n",
      "score1: 0.6716262053136737\n",
      "score2: 0.36667517271757777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jacob\\AppData\\Local\\Temp/ipykernel_26068/3107727803.py:83: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  randomForest_Base = randomForest.fit(data_train.drop([\"5\"], axis=1), data_train.drop(data_train_AIS.columns[0:-1],axis=1))\n",
      "c:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score GradientBoosting: \n",
      "0.7652551020408164\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score GradientBoosting AIS: \n",
      "0.8880102040816327\n",
      "\n",
      "Best score KNeighbors: \n",
      "0.7731122448979593\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score KNeighbors AIS: \n",
      "0.8650510204081632\n",
      "\n",
      "Best score Logistic Regression: \n",
      "0.5203061224489796\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score Logistic Regression AIS: \n",
      "0.7343367346938776\n",
      "\n",
      "Best score RandomForest: \n",
      "0.7323979591836736\n",
      "\n",
      "Best score RandomForest AIS: \n",
      "0.9133163265306123\n",
      "\n",
      "score1: 0.5246711108966975\n",
      "score2: 0.5613224535603222\n",
      "score1: 0.5613224535603222\n",
      "score2: 0.5655034090047409\n",
      "score1: 0.5655034090047409\n",
      "score2: 0.47888720665680234\n",
      "score1: 0.5655034090047409\n",
      "score2: 0.5578248640104804\n",
      "score1: 0.5655034090047409\n",
      "score2: 0.4949099939722725\n",
      "score1: 0.5655034090047409\n",
      "score2: 0.5310241318355478\n",
      "score1: 0.5655034090047409\n",
      "score2: 0.40654916957623266\n",
      "score1: 0.5655034090047409\n",
      "score2: 0.48827793286911536\n",
      "score1: 0.5655034090047409\n",
      "score2: 0.6604841867326545\n",
      "score1: 0.6604841867326545\n",
      "score2: 0.5144273006459812\n",
      "score1: 0.6604841867326545\n",
      "score2: 0.3987063540345683\n",
      "score1: 0.6604841867326545\n",
      "score2: 0.4683543089430895\n",
      "score1: 0.6604841867326545\n",
      "score2: 0.6480306616552653\n",
      "score1: 0.6604841867326545\n",
      "score2: 0.3777180323781463\n",
      "score1: 0.6604841867326545\n",
      "score2: 0.550457142857143\n",
      "score1: 0.6604841867326545\n",
      "score2: 0.43766058786741713\n",
      "score1: 0.6604841867326545\n",
      "score2: 0.44318423969958226\n",
      "score1: 0.6604841867326545\n",
      "score2: 0.6305639288093652\n",
      "score1: 0.6604841867326545\n",
      "score2: 0.5873893291253589\n",
      "score1: 0.6604841867326545\n",
      "score2: 0.5841594661046716\n",
      "score1: 0.6604841867326545\n",
      "score2: 0.6761012724117987\n",
      "score1: 0.6761012724117987\n",
      "score2: 0.2596987096987097\n",
      "score1: 0.6761012724117987\n",
      "score2: 0.5089919562419563\n",
      "score1: 0.6761012724117987\n",
      "score2: 0.6039048793950231\n",
      "score1: 0.6761012724117987\n",
      "score2: 0.65233909930362\n",
      "score1: 0.6761012724117987\n",
      "score2: 0.6697290697766545\n",
      "score1: 0.6761012724117987\n",
      "score2: 0.2500871460774357\n",
      "score1: 0.6761012724117987\n",
      "score2: 0.5239148204547938\n",
      "score1: 0.6761012724117987\n",
      "score2: 0.3811004777936969\n",
      "score1: 0.6761012724117987\n",
      "score2: 0.6112352638352638\n",
      "score1: 0.6761012724117987\n",
      "score2: 0.6608253261927947\n",
      "score1: 0.6761012724117987\n",
      "score2: 0.3990937710128981\n",
      "score1: 0.6761012724117987\n",
      "score2: 0.6587381754345574\n",
      "score1: 0.6761012724117987\n",
      "score2: 0.4205389047962371\n",
      "score1: 0.6761012724117987\n",
      "score2: 0.4716451836451837\n",
      "score1: 0.6761012724117987\n",
      "score2: 0.3787751830001719\n",
      "score1: 0.6761012724117987\n",
      "score2: 0.45115516483516477\n",
      "score1: 0.6761012724117987\n",
      "score2: 0.6415524324324325\n",
      "score1: 0.6761012724117987\n",
      "score2: 0.33912388278388284\n",
      "score1: 0.6761012724117987\n",
      "score2: 0.4802432358200203\n",
      "score1: 0.6761012724117987\n",
      "score2: 0.35443303326810177\n",
      "score1: 0.6761012724117987\n",
      "score2: 0.5830726817042606\n",
      "score1: 0.6761012724117987\n",
      "score2: 0.5051774551418098\n",
      "score1: 0.6761012724117987\n",
      "score2: 0.5404582170036965\n",
      "score1: 0.6761012724117987\n",
      "score2: 0.6342462962962963\n",
      "score1: 0.6761012724117987\n",
      "score2: 0.43140836707152497\n",
      "score1: 0.6761012724117987\n",
      "score2: 0.4539986089859508\n",
      "score1: 0.6761012724117987\n",
      "score2: 0.3626323308270677\n",
      "score1: 0.6761012724117987\n",
      "score2: 0.6279753777654843\n",
      "score1: 0.6761012724117987\n",
      "score2: 0.26641590213594346\n",
      "score1: 0.6761012724117987\n",
      "score2: 0.2678171885409727\n",
      "score1: 0.6761012724117987\n",
      "score2: 0.49471126044687014\n",
      "score1: 0.6761012724117987\n",
      "score2: 0.4265197727260418\n",
      "score1: 0.6761012724117987\n",
      "score2: 0.4889322464905213\n",
      "score1: 0.6761012724117987\n",
      "score2: 0.5591127472527473\n",
      "score1: 0.6761012724117987\n",
      "score2: 0.34724280701754384\n",
      "score1: 0.6761012724117987\n",
      "score2: 0.5097115688859591\n",
      "score1: 0.6761012724117987\n",
      "score2: 0.5069399770413805\n",
      "score1: 0.6761012724117987\n",
      "score2: 0.6470659519115187\n",
      "score1: 0.6761012724117987\n",
      "score2: 0.4495390313390314\n",
      "score1: 0.6761012724117987\n",
      "score2: 0.4772542366054222\n",
      "score1: 0.6761012724117987\n",
      "score2: 0.5147969284871452\n",
      "score1: 0.6761012724117987\n",
      "score2: 0.4401301989150091\n",
      "score1: 0.6761012724117987\n",
      "score2: 0.6292055083537664\n",
      "score1: 0.6761012724117987\n",
      "score2: 0.4918475271337182\n",
      "score1: 0.6761012724117987\n",
      "score2: 0.38559544043192373\n",
      "score1: 0.6761012724117987\n",
      "score2: 0.3702313078517344\n",
      "score1: 0.6761012724117987\n",
      "score2: 0.5399313930183144\n",
      "score1: 0.6761012724117987\n",
      "score2: 0.259352387649856\n",
      "score1: 0.6761012724117987\n",
      "score2: 0.39919691237225485\n",
      "score1: 0.6761012724117987\n",
      "score2: 0.3705985654008439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jacob\\AppData\\Local\\Temp/ipykernel_26068/3107727803.py:83: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  randomForest_Base = randomForest.fit(data_train.drop([\"5\"], axis=1), data_train.drop(data_train_AIS.columns[0:-1],axis=1))\n",
      "c:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score GradientBoosting: \n",
      "0.7940051020408163\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score GradientBoosting AIS: \n",
      "0.8727678571428572\n",
      "\n",
      "Best score KNeighbors: \n",
      "0.7835884353741496\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score KNeighbors AIS: \n",
      "0.8492772108843538\n",
      "\n",
      "Best score Logistic Regression: \n",
      "0.4998937074829932\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score Logistic Regression AIS: \n",
      "0.7137542517006803\n",
      "\n",
      "Best score RandomForest: \n",
      "0.7475021258503401\n",
      "\n",
      "Best score RandomForest AIS: \n",
      "0.8986500850340136\n",
      "\n",
      "score1: 0.6411449494392353\n",
      "score2: 0.42168481278029885\n",
      "score1: 0.6411449494392353\n",
      "score2: 0.6752334297281666\n",
      "score1: 0.6752334297281666\n",
      "score2: 0.5505804322400203\n",
      "score1: 0.6752334297281666\n",
      "score2: 0.5430899000110868\n",
      "score1: 0.6752334297281666\n",
      "score2: 0.40663324979114457\n",
      "score1: 0.6752334297281666\n",
      "score2: 0.4846363483681436\n",
      "score1: 0.6752334297281666\n",
      "score2: 0.6015486299695457\n",
      "score1: 0.6752334297281666\n",
      "score2: 0.5638526757369615\n",
      "score1: 0.6752334297281666\n",
      "score2: 0.25761725892594306\n",
      "score1: 0.6752334297281666\n",
      "score2: 0.6265013709361535\n",
      "score1: 0.6752334297281666\n",
      "score2: 0.5528841197846558\n",
      "score1: 0.6752334297281666\n",
      "score2: 0.5318760163056185\n",
      "score1: 0.6752334297281666\n",
      "score2: 0.4386681682227547\n",
      "score1: 0.6752334297281666\n",
      "score2: 0.42718875884057195\n",
      "score1: 0.6752334297281666\n",
      "score2: 0.7040185943057362\n",
      "score1: 0.7040185943057362\n",
      "score2: 0.5795299325363948\n",
      "score1: 0.7040185943057362\n",
      "score2: 0.38033355252342593\n",
      "score1: 0.7040185943057362\n",
      "score2: 0.5528939543125306\n",
      "score1: 0.7040185943057362\n",
      "score2: 0.4420334085548544\n",
      "score1: 0.7040185943057362\n",
      "score2: 0.3639140120923253\n",
      "score1: 0.7040185943057362\n",
      "score2: 0.49877382230281847\n",
      "score1: 0.7040185943057362\n",
      "score2: 0.5003500468960034\n",
      "score1: 0.7040185943057362\n",
      "score2: 0.4445798627967303\n",
      "score1: 0.7040185943057362\n",
      "score2: 0.40128096855585643\n",
      "score1: 0.7040185943057362\n",
      "score2: 0.3814272331992773\n",
      "score1: 0.7040185943057362\n",
      "score2: 0.5240945098222347\n",
      "score1: 0.7040185943057362\n",
      "score2: 0.4050555903271693\n",
      "score1: 0.7040185943057362\n",
      "score2: 0.4118324636043057\n",
      "score1: 0.7040185943057362\n",
      "score2: 0.5065204281663543\n",
      "score1: 0.7040185943057362\n",
      "score2: 0.596404600698095\n",
      "score1: 0.7040185943057362\n",
      "score2: 0.49523996410093984\n",
      "score1: 0.7040185943057362\n",
      "score2: 0.39671444951444956\n",
      "score1: 0.7040185943057362\n",
      "score2: 0.39324285714285717\n",
      "score1: 0.7040185943057362\n",
      "score2: 0.6194936544616694\n",
      "score1: 0.7040185943057362\n",
      "score2: 0.5213312929760299\n",
      "score1: 0.7040185943057362\n",
      "score2: 0.4108608227934177\n",
      "score1: 0.7040185943057362\n",
      "score2: 0.5704024948024948\n",
      "score1: 0.7040185943057362\n",
      "score2: 0.3870393631962846\n",
      "score1: 0.7040185943057362\n",
      "score2: 0.695964353190669\n",
      "score1: 0.7040185943057362\n",
      "score2: 0.5350396392703423\n",
      "score1: 0.7040185943057362\n",
      "score2: 0.5840990720427963\n",
      "score1: 0.7040185943057362\n",
      "score2: 0.46998992745735857\n",
      "score1: 0.7040185943057362\n",
      "score2: 0.4567460148704051\n",
      "score1: 0.7040185943057362\n",
      "score2: 0.526523485356584\n",
      "score1: 0.7040185943057362\n",
      "score2: 0.5476548433048433\n",
      "score1: 0.7040185943057362\n",
      "score2: 0.6169975316463122\n",
      "score1: 0.7040185943057362\n",
      "score2: 0.3831525787073672\n",
      "score1: 0.7040185943057362\n",
      "score2: 0.5224104750546611\n",
      "score1: 0.7040185943057362\n",
      "score2: 0.6144055569702629\n",
      "score1: 0.7040185943057362\n",
      "score2: 0.5156471404541632\n",
      "score1: 0.7040185943057362\n",
      "score2: 0.40485819314821525\n",
      "score1: 0.7040185943057362\n",
      "score2: 0.36889117386678366\n",
      "score1: 0.7040185943057362\n",
      "score2: 0.4680192307692307\n",
      "score1: 0.7040185943057362\n",
      "score2: 0.44613563820261126\n",
      "score1: 0.7040185943057362\n",
      "score2: 0.3873344274548675\n",
      "score1: 0.7040185943057362\n",
      "score2: 0.46151189873417725\n",
      "score1: 0.7040185943057362\n",
      "score2: 0.4103761315303408\n",
      "score1: 0.7040185943057362\n",
      "score2: 0.5726943220867271\n",
      "score1: 0.7040185943057362\n",
      "score2: 0.5233468238442922\n",
      "score1: 0.7040185943057362\n",
      "score2: 0.5217407097036613\n",
      "score1: 0.7040185943057362\n",
      "score2: 0.6460594154727\n",
      "score1: 0.7040185943057362\n",
      "score2: 0.6278251657625077\n",
      "score1: 0.7040185943057362\n",
      "score2: 0.5802298106757593\n",
      "score1: 0.7040185943057362\n",
      "score2: 0.5801635213036881\n",
      "score1: 0.7040185943057362\n",
      "score2: 0.6019609022556391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jacob\\AppData\\Local\\Temp/ipykernel_26068/3107727803.py:83: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  randomForest_Base = randomForest.fit(data_train.drop([\"5\"], axis=1), data_train.drop(data_train_AIS.columns[0:-1],axis=1))\n",
      "c:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score GradientBoosting: \n",
      "0.7775\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score GradientBoosting AIS: \n",
      "0.905\n",
      "\n",
      "Best score KNeighbors: \n",
      "0.805\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score KNeighbors AIS: \n",
      "0.8724999999999999\n",
      "\n",
      "Best score Logistic Regression: \n",
      "0.5950000000000001\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score Logistic Regression AIS: \n",
      "0.7825\n",
      "\n",
      "Best score RandomForest: \n",
      "0.7825\n",
      "\n",
      "Best score RandomForest AIS: \n",
      "0.9225\n",
      "\n",
      "score1: 0.26158218526218524\n",
      "score2: 0.3654162892894969\n",
      "score1: 0.3654162892894969\n",
      "score2: 0.5281439228251374\n",
      "score1: 0.5281439228251374\n",
      "score2: 0.26090056980056986\n",
      "score1: 0.5281439228251374\n",
      "score2: 0.4275463620458989\n",
      "score1: 0.5281439228251374\n",
      "score2: 0.370170447947356\n",
      "score1: 0.5281439228251374\n",
      "score2: 0.26388649190394814\n",
      "score1: 0.5281439228251374\n",
      "score2: 0.44443180957988143\n",
      "score1: 0.5281439228251374\n",
      "score2: 0.5478350809219596\n",
      "score1: 0.5478350809219596\n",
      "score2: 0.5183798860279306\n",
      "score1: 0.5478350809219596\n",
      "score2: 0.4828591042348358\n",
      "score1: 0.5478350809219596\n",
      "score2: 0.4118905154662313\n",
      "score1: 0.5478350809219596\n",
      "score2: 0.2689448087709488\n",
      "score1: 0.5478350809219596\n",
      "score2: 0.5032348352310739\n",
      "score1: 0.5478350809219596\n",
      "score2: 0.5564206367955482\n",
      "score1: 0.5564206367955482\n",
      "score2: 0.2590614769938983\n",
      "score1: 0.5564206367955482\n",
      "score2: 0.43442624504988603\n",
      "score1: 0.5564206367955482\n",
      "score2: 0.26368859576235976\n",
      "score1: 0.5564206367955482\n",
      "score2: 0.25777770265898947\n",
      "score1: 0.5564206367955482\n",
      "score2: 0.3929469709730965\n",
      "score1: 0.5564206367955482\n",
      "score2: 0.5096515397881252\n",
      "score1: 0.5564206367955482\n",
      "score2: 0.4489642115259066\n",
      "score1: 0.5564206367955482\n",
      "score2: 0.26352583664208734\n",
      "score1: 0.5564206367955482\n",
      "score2: 0.41816432360524214\n",
      "score1: 0.5564206367955482\n",
      "score2: 0.44472989025768606\n",
      "score1: 0.5564206367955482\n",
      "score2: 0.5983757187480079\n",
      "score1: 0.5983757187480079\n",
      "score2: 0.2584806831789248\n",
      "score1: 0.5983757187480079\n",
      "score2: 0.4131028721933806\n",
      "score1: 0.5983757187480079\n",
      "score2: 0.5047674163944251\n",
      "score1: 0.5983757187480079\n",
      "score2: 0.2754657315712475\n",
      "score1: 0.5983757187480079\n",
      "score2: 0.27312764859366767\n",
      "score1: 0.5983757187480079\n",
      "score2: 0.3730856854978806\n",
      "score1: 0.5983757187480079\n",
      "score2: 0.3910692824231333\n",
      "score1: 0.5983757187480079\n",
      "score2: 0.5212977911646587\n",
      "score1: 0.5983757187480079\n",
      "score2: 0.42077332294618836\n",
      "score1: 0.5983757187480079\n",
      "score2: 0.26560157287847386\n",
      "score1: 0.5983757187480079\n",
      "score2: 0.5096791327913279\n",
      "score1: 0.5983757187480079\n",
      "score2: 0.3985063619307522\n",
      "score1: 0.5983757187480079\n",
      "score2: 0.2719619594920021\n",
      "score1: 0.5983757187480079\n",
      "score2: 0.37597671113890624\n",
      "score1: 0.5983757187480079\n",
      "score2: 0.4436964457414695\n",
      "score1: 0.5983757187480079\n",
      "score2: 0.3970203123489827\n",
      "score1: 0.5983757187480079\n",
      "score2: 0.4875832382807066\n",
      "score1: 0.5983757187480079\n",
      "score2: 0.2585440058723433\n",
      "score1: 0.5983757187480079\n",
      "score2: 0.5836248522918611\n",
      "score1: 0.5983757187480079\n",
      "score2: 0.38880926708498287\n",
      "score1: 0.5983757187480079\n",
      "score2: 0.3900183280189049\n",
      "score1: 0.5983757187480079\n",
      "score2: 0.27399177848893397\n",
      "score1: 0.5983757187480079\n",
      "score2: 0.40182780195975465\n",
      "score1: 0.5983757187480079\n",
      "score2: 0.420039382789959\n",
      "score1: 0.5983757187480079\n",
      "score2: 0.5226243100480741\n",
      "score1: 0.5983757187480079\n",
      "score2: 0.4503768726414634\n",
      "score1: 0.5983757187480079\n",
      "score2: 0.48325515224670895\n",
      "score1: 0.5983757187480079\n",
      "score2: 0.4214005357980041\n",
      "score1: 0.5983757187480079\n",
      "score2: 0.4515191823524646\n",
      "score1: 0.5983757187480079\n",
      "score2: 0.5109049479610365\n",
      "score1: 0.5983757187480079\n",
      "score2: 0.4199009149543812\n",
      "score1: 0.5983757187480079\n",
      "score2: 0.373334126984127\n",
      "score1: 0.5983757187480079\n",
      "score2: 0.4075082621082621\n",
      "score1: 0.5983757187480079\n",
      "score2: 0.4092421426366163\n",
      "score1: 0.5983757187480079\n",
      "score2: 0.26808998949384033\n",
      "score1: 0.5983757187480079\n",
      "score2: 0.262263667329918\n",
      "score1: 0.5983757187480079\n",
      "score2: 0.2736521398699594\n",
      "score1: 0.5983757187480079\n",
      "score2: 0.2736137622424856\n",
      "score1: 0.5983757187480079\n",
      "score2: 0.2710022218070852\n",
      "score1: 0.5983757187480079\n",
      "score2: 0.5525468576590529\n",
      "score1: 0.5983757187480079\n",
      "score2: 0.2716534314114972\n",
      "score1: 0.5983757187480079\n",
      "score2: 0.48935696794145234\n",
      "score1: 0.5983757187480079\n",
      "score2: 0.45603761899917783\n",
      "score1: 0.5983757187480079\n",
      "score2: 0.2667281384472301\n",
      "score1: 0.5983757187480079\n",
      "score2: 0.5967235672850131\n",
      "score1: 0.5983757187480079\n",
      "score2: 0.5954950683400051\n",
      "score1: 0.5983757187480079\n",
      "score2: 0.26298080472499075\n",
      "score1: 0.5983757187480079\n",
      "score2: 0.267506357771303\n",
      "score1: 0.5983757187480079\n",
      "score2: 0.5953684053286316\n",
      "score1: 0.5983757187480079\n",
      "score2: 0.44538800347725305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jacob\\AppData\\Local\\Temp/ipykernel_26068/3107727803.py:83: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  randomForest_Base = randomForest.fit(data_train.drop([\"5\"], axis=1), data_train.drop(data_train_AIS.columns[0:-1],axis=1))\n",
      "c:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score GradientBoosting: \n",
      "0.7769607843137255\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score GradientBoosting AIS: \n",
      "0.8995098039215685\n",
      "\n",
      "Best score KNeighbors: \n",
      "0.7647058823529411\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score KNeighbors AIS: \n",
      "0.8848039215686274\n",
      "\n",
      "Best score Logistic Regression: \n",
      "0.5637254901960784\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score Logistic Regression AIS: \n",
      "0.6813725490196079\n",
      "\n",
      "Best score RandomForest: \n",
      "0.7622549019607843\n",
      "\n",
      "Best score RandomForest AIS: \n",
      "0.9240196078431373\n",
      "\n",
      "score1: 0.4976348694316436\n",
      "score2: 0.48600119118522933\n",
      "score1: 0.4976348694316436\n",
      "score2: 0.43156085636626784\n",
      "score1: 0.4976348694316436\n",
      "score2: 0.5124978040425117\n",
      "score1: 0.5124978040425117\n",
      "score2: 0.5234273927019512\n",
      "score1: 0.5234273927019512\n",
      "score2: 0.5316897445170863\n",
      "score1: 0.5316897445170863\n",
      "score2: 0.5944642857142857\n",
      "score1: 0.5944642857142857\n",
      "score2: 0.5179859855334538\n",
      "score1: 0.5944642857142857\n",
      "score2: 0.46521662852784135\n",
      "score1: 0.5944642857142857\n",
      "score2: 0.5558042147821263\n",
      "score1: 0.5944642857142857\n",
      "score2: 0.6069313657827714\n",
      "score1: 0.6069313657827714\n",
      "score2: 0.5233394736842105\n",
      "score1: 0.6069313657827714\n",
      "score2: 0.5071142202403073\n",
      "score1: 0.6069313657827714\n",
      "score2: 0.5990270945615437\n",
      "score1: 0.6069313657827714\n",
      "score2: 0.5731024342067318\n",
      "score1: 0.6069313657827714\n",
      "score2: 0.6726129864253394\n",
      "score1: 0.6726129864253394\n",
      "score2: 0.4337502849002849\n",
      "score1: 0.6726129864253394\n",
      "score2: 0.40087011251758087\n",
      "score1: 0.6726129864253394\n",
      "score2: 0.34936561311186964\n",
      "score1: 0.6726129864253394\n",
      "score2: 0.616813278877846\n",
      "score1: 0.6726129864253394\n",
      "score2: 0.5730613578591929\n",
      "score1: 0.6726129864253394\n",
      "score2: 0.4379919769746806\n",
      "score1: 0.6726129864253394\n",
      "score2: 0.5553465136954405\n",
      "score1: 0.6726129864253394\n",
      "score2: 0.471046843881592\n",
      "score1: 0.6726129864253394\n",
      "score2: 0.2600853498231167\n",
      "score1: 0.6726129864253394\n",
      "score2: 0.37800667126754084\n",
      "score1: 0.6726129864253394\n",
      "score2: 0.4300262046327264\n",
      "score1: 0.6726129864253394\n",
      "score2: 0.3985938438059329\n",
      "score1: 0.6726129864253394\n",
      "score2: 0.4884638352638353\n",
      "score1: 0.6726129864253394\n",
      "score2: 0.6018217873405082\n",
      "score1: 0.6726129864253394\n",
      "score2: 0.3996575147085042\n",
      "score1: 0.6726129864253394\n",
      "score2: 0.5844808708917456\n",
      "score1: 0.6726129864253394\n",
      "score2: 0.46406921920185085\n",
      "score1: 0.6726129864253394\n",
      "score2: 0.418968092759784\n",
      "score1: 0.6726129864253394\n",
      "score2: 0.47896030307591947\n",
      "score1: 0.6726129864253394\n",
      "score2: 0.5650028571428571\n",
      "score1: 0.6726129864253394\n",
      "score2: 0.5721415632137388\n",
      "score1: 0.6726129864253394\n",
      "score2: 0.6188926364692219\n",
      "score1: 0.6726129864253394\n",
      "score2: 0.35785724730521534\n",
      "score1: 0.6726129864253394\n",
      "score2: 0.7666143127020149\n",
      "score1: 0.7666143127020149\n",
      "score2: 0.4842566931882722\n",
      "score1: 0.7666143127020149\n",
      "score2: 0.5415148656972759\n",
      "score1: 0.7666143127020149\n",
      "score2: 0.4022103066867773\n",
      "score1: 0.7666143127020149\n",
      "score2: 0.46591561700650275\n",
      "score1: 0.7666143127020149\n",
      "score2: 0.6630435015035082\n",
      "score1: 0.7666143127020149\n",
      "score2: 0.46796249072602014\n",
      "score1: 0.7666143127020149\n",
      "score2: 0.5071713859654602\n",
      "score1: 0.7666143127020149\n",
      "score2: 0.5777481204075834\n",
      "score1: 0.7666143127020149\n",
      "score2: 0.36517412982969283\n",
      "score1: 0.7666143127020149\n",
      "score2: 0.6068884077281812\n",
      "score1: 0.7666143127020149\n",
      "score2: 0.35822380952380956\n",
      "score1: 0.7666143127020149\n",
      "score2: 0.4375455671699574\n",
      "score1: 0.7666143127020149\n",
      "score2: 0.6115625352221181\n",
      "score1: 0.7666143127020149\n",
      "score2: 0.27185085935429354\n",
      "score1: 0.7666143127020149\n",
      "score2: 0.6254658931082983\n",
      "score1: 0.7666143127020149\n",
      "score2: 0.5071012285012284\n",
      "score1: 0.7666143127020149\n",
      "score2: 0.38161054070931505\n",
      "score1: 0.7666143127020149\n",
      "score2: 0.3876858435681965\n",
      "score1: 0.7666143127020149\n",
      "score2: 0.3657972161886466\n",
      "score1: 0.7666143127020149\n",
      "score2: 0.6646661387757392\n",
      "score1: 0.7666143127020149\n",
      "score2: 0.5482641177897817\n",
      "score1: 0.7666143127020149\n",
      "score2: 0.39453766292200865\n",
      "score1: 0.7666143127020149\n",
      "score2: 0.5181370149747664\n",
      "score1: 0.7666143127020149\n",
      "score2: 0.6414515683575136\n",
      "score1: 0.7666143127020149\n",
      "score2: 0.49148590974243156\n",
      "score1: 0.7666143127020149\n",
      "score2: 0.38820789886442064\n",
      "score1: 0.7666143127020149\n",
      "score2: 0.46145367441019614\n",
      "score1: 0.7666143127020149\n",
      "score2: 0.48097703337139974\n",
      "score1: 0.7666143127020149\n",
      "score2: 0.4793165948933794\n",
      "score1: 0.7666143127020149\n",
      "score2: 0.4414634586466165\n",
      "score1: 0.7666143127020149\n",
      "score2: 0.47967169765233814\n",
      "score1: 0.7666143127020149\n",
      "score2: 0.4740125258976261\n",
      "score1: 0.7666143127020149\n",
      "score2: 0.47316584271064344\n",
      "score1: 0.7666143127020149\n",
      "score2: 0.2606922222222222\n",
      "score1: 0.7666143127020149\n",
      "score2: 0.3633930341954445\n",
      "score1: 0.7666143127020149\n",
      "score2: 0.5416963501539436\n",
      "score1: 0.7666143127020149\n",
      "score2: 0.26902016743874535\n",
      "score1: 0.7666143127020149\n",
      "score2: 0.5120712502167505\n",
      "score1: 0.7666143127020149\n",
      "score2: 0.5337679737078375\n",
      "score1: 0.7666143127020149\n",
      "score2: 0.3511288394532297\n",
      "score1: 0.7666143127020149\n",
      "score2: 0.5587048863227675\n",
      "score1: 0.7666143127020149\n",
      "score2: 0.5578100675146047\n",
      "score1: 0.7666143127020149\n",
      "score2: 0.3747455176402545\n",
      "score1: 0.7666143127020149\n",
      "score2: 0.665148303870043\n",
      "score1: 0.7666143127020149\n",
      "score2: 0.5149609022556391\n",
      "score1: 0.7666143127020149\n",
      "score2: 0.45169727710995317\n",
      "score1: 0.7666143127020149\n",
      "score2: 0.4570744810744811\n",
      "score1: 0.7666143127020149\n",
      "score2: 0.4686863296089907\n",
      "score1: 0.7666143127020149\n",
      "score2: 0.5343033123348914\n",
      "score1: 0.7666143127020149\n",
      "score2: 0.5976372899798083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jacob\\AppData\\Local\\Temp/ipykernel_26068/3107727803.py:83: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  randomForest_Base = randomForest.fit(data_train.drop([\"5\"], axis=1), data_train.drop(data_train_AIS.columns[0:-1],axis=1))\n",
      "c:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score GradientBoosting: \n",
      "0.6927083333333333\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score GradientBoosting AIS: \n",
      "0.8385416666666667\n",
      "\n",
      "Best score KNeighbors: \n",
      "0.734375\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score KNeighbors AIS: \n",
      "0.8437500000000001\n",
      "\n",
      "Best score Logistic Regression: \n",
      "0.6328125000000001\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score Logistic Regression AIS: \n",
      "0.6536458333333333\n",
      "\n",
      "Best score RandomForest: \n",
      "0.6901041666666666\n",
      "\n",
      "Best score RandomForest AIS: \n",
      "0.8802083333333333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "dataAIS = []\n",
    "dataSMOTE = []\n",
    "dataBase = []\n",
    "data = []\n",
    "fold = 0\n",
    "\n",
    "for result in kf.split(df):\n",
    "    fold = fold+1\n",
    "    #Print the shape of the train and test set\n",
    "    data_train = df.iloc[result[0]]\n",
    "    data_test =  df.iloc[result[1]]\n",
    "    #print(f\"Train Data shape: \\n{data_train}\\n\")\n",
    "    #print(f\"Test Data shape: \\n{data_test}\\n\")\n",
    "\n",
    "\n",
    "    data_train_AIS = data_train.copy()\n",
    "    data_train_SMOTE = data_train.copy()\n",
    "\n",
    "    #Create an oversampling object\n",
    "    \n",
    "    oversample = SMOTE()\n",
    "    \n",
    "\n",
    "\n",
    "    oversample_AIS = ArtificialImmuneSystem()\n",
    "    #Oversample and add to the dataframe to fix the class imbalance\n",
    "    randomForest = RandomForestClassifier()\n",
    "    logisticRegression = LogisticRegression()\n",
    "    kNeighbors = KNeighborsClassifier()\n",
    "    gradientBoosting = GradientBoostingClassifier()\n",
    "\n",
    "    st = time.time()\n",
    "    x_over, y_over = oversample.fit_resample(data_train_SMOTE.drop([\"5\"], axis=1), data_train_SMOTE.drop(data_train_SMOTE.columns[0:-1],axis=1))\n",
    "    elapsed_time_SMOTE = time.time() - st\n",
    "\n",
    "    st = time.time()\n",
    "    input_x_over_AIS, y_over_AIS = oversample_AIS.AIS_Resample(data_train_AIS.drop([\"5\"], axis=1), data_train_AIS.drop(data_train_AIS.columns[0:-1],axis=1),max_rounds = 200, stopping_cond = 50, model = kNeighbors,K_folds = 5,scorer = 'f1',min_change = 0.001, use_lof = False)\n",
    "    elapsed_time_AIS = time.time() - st\n",
    "\n",
    "    smote_df = pd.concat([x_over, y_over], axis=1)\n",
    "    ais_df = pd.concat([input_x_over_AIS, y_over_AIS], axis=1)\n",
    "\n",
    "    # print the dimensionality of the oversampled dataset\n",
    "    #print(f\"SMOTE Oversampled Data shape: \\n{smote_df.shape}\\n\")\n",
    "    #print(f\"SMOTE Oversampled Data size: \\n{smote_df.size}\\n\")\n",
    "    #print(f\"SMOTE Oversampled Data ndim: \\n{smote_df.ndim}\\n\")\n",
    "    #print(\"_____________________________________________\\n\")\n",
    "\n",
    "    # print the dimensionality of the oversampled dataset\n",
    "    #print(f\"AIS Oversampled Data shape: \\n{ais_df.shape}\\n\")\n",
    "    #print(f\"AIS Oversampled Data size: \\n{ais_df.size}\\n\")\n",
    "    #print(f\"AIS Oversampled Data ndim: \\n{ais_df.ndim}\\n\")\n",
    "    #print(\"_____________________________________________\\n\")\n",
    "\n",
    "\n",
    "    # print the new class distribution using a Counter\n",
    "    #print(f\"New SMOTE Class Distribution: {Counter(smote_df['5'])}\")\n",
    "    #print(f\"New AIS Class Distribution: {Counter(ais_df['5'])}\")\n",
    "    ## print the new class distribution using a Counter\n",
    "    #print(f\"Old Class Distribution: {Counter(data_train['5'])}\")\n",
    "\n",
    "    #print(\"_____________________________________________\\n\")\n",
    "\n",
    "    #labelTrainFlat = labels_train.values.ravel()\n",
    "\n",
    "    #Fit one vs rest Gradient Boosting classification\n",
    "    gradientBoosting = GradientBoostingClassifier()\n",
    "    gradientBoosting = gradientBoosting.fit(x_over, y_over.values.ravel())\n",
    "\n",
    "    gradientBoosting_AIS = GradientBoostingClassifier()\n",
    "    gradientBoosting_AIS = gradientBoosting.fit(input_x_over_AIS, y_over_AIS.values.ravel())\n",
    "\n",
    "    gradientBoosting_Base = gradientBoosting.fit(data_train.drop([\"5\"], axis=1), data_train.drop(data_train_AIS.columns[0:-1],axis=1))\n",
    "\n",
    "    #Fit RandomForestClassifier classification\n",
    "    randomForest = RandomForestClassifier()\n",
    "    randomForest = randomForest.fit(x_over,y_over.values.ravel())\n",
    "\n",
    "    randomForest = RandomForestClassifier()\n",
    "    randomForest_AIS  = randomForest.fit(input_x_over_AIS,y_over_AIS.values.ravel())\n",
    "\n",
    "    randomForest_Base = randomForest.fit(data_train.drop([\"5\"], axis=1), data_train.drop(data_train_AIS.columns[0:-1],axis=1))\n",
    "    #randomForest_Base  = randomForest.fit(data_train.drop([\"5\"], axis=1), data_train.drop(data_train_AIS.columns[0:-1]).values.ravel())\n",
    "\n",
    "    #Create a KNeighbors classification object\n",
    "    kNeighbors = KNeighborsClassifier()\n",
    "    kNeighbors = kNeighbors.fit(x_over,y_over.values.ravel())\n",
    "\n",
    "    kNeighbors = KNeighborsClassifier()\n",
    "    kNeighbors_AIS  = kNeighbors.fit(input_x_over_AIS,y_over_AIS.values.ravel())\n",
    "    kNeighbors_Base = kNeighbors.fit(data_train.drop([\"5\"], axis=1), data_train.drop(data_train_AIS.columns[0:-1],axis=1))\n",
    "    #kNeighbors_base  = kNeighbors.fit(data_train.drop([\"5\"], axis=1), data_train.drop(data_train_AIS.columns[0:-1]).values.ravel())\n",
    "\n",
    "    #Create an LogisticRegression object\n",
    "    logisticRegression = LogisticRegression(max_iter=5000)\n",
    "    logisticRegression = logisticRegression.fit(x_over,y_over.values.ravel())\n",
    "\n",
    "    logisticRegression = LogisticRegression(max_iter=5000)\n",
    "    logisticRegression_AIS  = logisticRegression.fit(input_x_over_AIS,y_over_AIS.values.ravel())\n",
    "    logisticRegression_Base = logisticRegression.fit(data_train.drop([\"5\"], axis=1), data_train.drop(data_train_AIS.columns[0:-1],axis=1))\n",
    "    #logisticRegression_Base  = logisticRegression.fit(data_train.drop([\"5\"], axis=1), data_train.drop(data_train_AIS.columns[0:-1]).values.ravel())\n",
    "\n",
    "    #Set the parameters of GradientBoosting for GridSearchCV\n",
    "    parametersGradientBoosting = [\n",
    "        {'learning_rate': [0.44,0.45,0.46],'min_samples_leaf': [5,6,7],'min_samples_split': [7,8,9,10], 'n_estimators': [57,58,59,60]}\n",
    "    ]\n",
    "\n",
    "    #Set the scoring parameters\n",
    "    scoringX = {\"roc_auc\": \"roc_auc\", \"bal_accuracy\": \"balanced_accuracy\"}\n",
    "\n",
    "    #Preform Gridsearch to find best parameters\n",
    "    grid_searchGradientBoosting = GridSearchCV(gradientBoosting, parametersGradientBoosting, cv=4, scoring = scoringX, return_train_score=True, n_jobs=-1, refit='bal_accuracy')\n",
    "    grid_searchGradientBoosting_AIS = GridSearchCV(gradientBoosting_AIS, parametersGradientBoosting, cv=4, scoring = scoringX, return_train_score=True, n_jobs=-1, refit='bal_accuracy')\n",
    "    #grid_searchGradientBoosting_Base = GridSearchCV(gradientBoosting_Base, parametersGradientBoosting, cv=4, scoring = scoringX, return_train_score=True, n_jobs=-1, refit='bal_accuracy')\n",
    "    #Fit the GradientBoosting \n",
    "    grid_searchGradientBoosting.fit(x_over, y_over.values.ravel())\n",
    "    grid_searchGradientBoosting_AIS.fit(input_x_over_AIS,y_over_AIS.values.ravel())\n",
    "  \n",
    "    \n",
    "\n",
    "    #Print GridSearchCV Results\n",
    "    \n",
    "    print(f\"Best score GradientBoosting: \\n{grid_searchGradientBoosting.best_score_}\\n\")\n",
    "    print(\"_____________________________________________\\n\")\n",
    "    \n",
    "    print(f\"Best score GradientBoosting AIS: \\n{grid_searchGradientBoosting_AIS.best_score_}\\n\")\n",
    "\n",
    "    #Set the parameters of KNeighbors for GridSearchCV\n",
    "    parametersKNeighbors = [\n",
    "        {'n_neighbors': [1,2,3],'weights':['uniform', 'distance'],'algorithm':['auto'], 'p': [1,2,3]}\n",
    "    ]\n",
    "\n",
    "    #Set the scoring parameters\n",
    "    scoringX = {\"roc_auc\": \"roc_auc\", \"bal_accuracy\": \"balanced_accuracy\"}\n",
    "\n",
    "    #Preform KNeighbors to find best parameters\n",
    "    grid_searchKNeighbors = GridSearchCV(kNeighbors, parametersKNeighbors, cv=4, scoring = scoringX, return_train_score=True, n_jobs=-1, refit='bal_accuracy')\n",
    "    grid_searchKNeighbors_AIS = GridSearchCV(kNeighbors_AIS, parametersKNeighbors, cv=4, scoring = scoringX, return_train_score=True, n_jobs=-1, refit='bal_accuracy')\n",
    "\n",
    "    #Fit the KNeighbors \n",
    "    grid_searchKNeighbors.fit(x_over, y_over.values.ravel())\n",
    "    grid_searchKNeighbors_AIS.fit(input_x_over_AIS,y_over_AIS.values.ravel())\n",
    "\n",
    "    #Print GridSearchCV Results\n",
    "   \n",
    "    print(f\"Best score KNeighbors: \\n{grid_searchKNeighbors.best_score_}\\n\")\n",
    "    print(\"_____________________________________________\\n\")\n",
    "   \n",
    "    print(f\"Best score KNeighbors AIS: \\n{grid_searchKNeighbors_AIS.best_score_}\\n\")\n",
    "    \n",
    "    #Set the parameters of LogisticRegression for GridSearchCV\n",
    "    parametersLogisticRegression = [\n",
    "        {'multi_class': ['ovr'],'penalty':['none','l2'], 'C': [1,2,3]}\n",
    "    ]\n",
    "    scoringX = {\"roc_auc\": \"roc_auc\", \"bal_accuracy\": \"balanced_accuracy\"}\n",
    "\n",
    "    #Preform LogisticRegression to find best parameters\n",
    "    grid_searchLogisticRegression = GridSearchCV(logisticRegression, parametersLogisticRegression, cv=4, scoring = scoringX, return_train_score=True, n_jobs=-1, refit='bal_accuracy')\n",
    "    grid_searchLogisticRegression_AIS = GridSearchCV(logisticRegression_AIS, parametersLogisticRegression, cv=4, scoring = scoringX, return_train_score=True, n_jobs=-1, refit='bal_accuracy')\n",
    "\n",
    "    #Fit the LogisticRegression \n",
    "    grid_searchLogisticRegression.fit(x_over, y_over.values.ravel())\n",
    "    grid_searchLogisticRegression_AIS.fit(input_x_over_AIS,y_over_AIS.values.ravel())\n",
    "\n",
    "    #Print LogisticRegression Results\n",
    "    \n",
    "    print(f\"Best score Logistic Regression: \\n{grid_searchLogisticRegression.best_score_}\\n\")\n",
    "    print(\"_____________________________________________\\n\")\n",
    "   \n",
    "    print(f\"Best score Logistic Regression AIS: \\n{grid_searchLogisticRegression_AIS.best_score_}\\n\")\n",
    "\n",
    "    #Set the parameters of RandomForest for GridSearchCV\n",
    "    parametersRandomForest = [\n",
    "        {'n_estimators': [145,150,155,190],'max_depth': [10,12], 'bootstrap': [True, False],\n",
    "        'min_samples_split': [0.05,2], 'max_features': ['auto']}\n",
    "    ]\n",
    "\n",
    "    #Preform Gridsearch to find best parameters\n",
    "    grid_searchRandomForest = GridSearchCV(randomForest, parametersRandomForest, cv=4, scoring = scoringX, return_train_score=True, n_jobs=-1, refit='bal_accuracy')\n",
    "    grid_searchRandomForest_AIS = GridSearchCV(randomForest_AIS, parametersRandomForest, cv=4, scoring = scoringX, return_train_score=True, n_jobs=-1, refit='bal_accuracy')\n",
    "\n",
    "    #Fit the RandomForest \n",
    "    grid_searchRandomForest.fit(x_over, y_over.values.ravel())\n",
    "    grid_searchRandomForest_AIS.fit(input_x_over_AIS,y_over_AIS.values.ravel())\n",
    "\n",
    "    #Print GridSearchCV Results\n",
    "\n",
    "    print(f\"Best score RandomForest: \\n{grid_searchRandomForest.best_score_}\\n\")\n",
    "\n",
    "    print(f\"Best score RandomForest AIS: \\n{grid_searchRandomForest_AIS.best_score_}\\n\")\n",
    "\n",
    "    #Get the results for all classifiers \n",
    "    cross_val_resultsGB = grid_searchGradientBoosting.cv_results_\n",
    "    cross_val_resultsRF = grid_searchRandomForest.cv_results_\n",
    "    cross_val_resultsLR = grid_searchLogisticRegression.cv_results_\n",
    "    cross_val_resultsKN = grid_searchKNeighbors.cv_results_\n",
    "\n",
    "    cross_val_resultsGB_AIS = grid_searchGradientBoosting_AIS.cv_results_\n",
    "    cross_val_resultsRF_AIS = grid_searchRandomForest_AIS.cv_results_\n",
    "    cross_val_resultsLR_AIS = grid_searchLogisticRegression_AIS.cv_results_\n",
    "    cross_val_resultsKN_AIS = grid_searchKNeighbors_AIS.cv_results_\n",
    "\n",
    "\n",
    "    #Print the results of all classiifiers\n",
    "    #GBC\n",
    "    mean_test_roc_aucGB = mean(cross_val_resultsGB['mean_test_roc_auc'])\n",
    "    mean_test_bal_accuracyGB = mean(cross_val_resultsGB['mean_test_bal_accuracy'])\n",
    "    \n",
    "    mean_test_roc_aucGB_AIS = mean(cross_val_resultsGB_AIS['mean_test_roc_auc'])\n",
    "    mean_test_bal_accuracyGB_AIS = mean(cross_val_resultsGB_AIS['mean_test_bal_accuracy'])\n",
    "   \n",
    "    #RFC\n",
    "    mean_test_roc_aucRF = mean(cross_val_resultsRF['mean_test_roc_auc'])\n",
    "    mean_test_bal_accuracyRF = mean(cross_val_resultsRF['mean_test_bal_accuracy'])\n",
    "    \n",
    "    mean_test_roc_aucRF_AIS = mean(cross_val_resultsRF_AIS['mean_test_roc_auc'])\n",
    "    mean_test_bal_accuracyRF_AIS = mean(cross_val_resultsRF_AIS['mean_test_bal_accuracy'])\n",
    "    #LRC\n",
    "    mean_test_roc_aucLR = mean(cross_val_resultsLR['mean_test_roc_auc'])\n",
    "    mean_test_bal_accuracyLR = mean(cross_val_resultsLR['mean_test_bal_accuracy'])\n",
    "    \n",
    "    mean_test_roc_aucLR_AIS = mean(cross_val_resultsLR_AIS['mean_test_roc_auc'])\n",
    "    mean_test_bal_accuracyLR_AIS = mean(cross_val_resultsLR_AIS['mean_test_bal_accuracy'])\n",
    "\n",
    "    #KNC\n",
    "    mean_test_roc_aucKN = mean(cross_val_resultsKN['mean_test_roc_auc'])\n",
    "    mean_test_bal_accuracyKN = mean(cross_val_resultsKN['mean_test_bal_accuracy'])\n",
    "    \n",
    "    mean_test_roc_aucKN_AIS = mean(cross_val_resultsKN_AIS['mean_test_roc_auc'])\n",
    "    mean_test_bal_accuracyKN_AIS = mean(cross_val_resultsKN_AIS['mean_test_bal_accuracy'])\n",
    "\n",
    "    predictions_test_over_GB = grid_searchGradientBoosting.best_estimator_.predict(data_test.drop([\"5\"],axis=1))\n",
    "    predictions_test_over_RF = grid_searchRandomForest.best_estimator_.predict(data_test.drop([\"5\"],axis=1))\n",
    "    predictions_test_over_LR = grid_searchLogisticRegression.best_estimator_.predict(data_test.drop([\"5\"],axis=1))\n",
    "    predictions_test_over_KN = grid_searchKNeighbors.best_estimator_.predict(data_test.drop([\"5\"],axis=1))\n",
    "\n",
    "    predictions_test_over_GB_AIS = grid_searchGradientBoosting_AIS.best_estimator_.predict(data_test.drop([\"5\"],axis=1))\n",
    "    predictions_test_over_RF_AIS = grid_searchRandomForest_AIS.best_estimator_.predict(data_test.drop([\"5\"],axis=1))\n",
    "    predictions_test_over_LR_AIS = grid_searchLogisticRegression_AIS.best_estimator_.predict(data_test.drop([\"5\"],axis=1))\n",
    "    predictions_test_over_KN_AIS = grid_searchKNeighbors_AIS.best_estimator_.predict(data_test.drop([\"5\"],axis=1))\n",
    "\n",
    "    predictions_GB = gradientBoosting_Base.predict(data_test.drop([\"5\"],axis=1))\n",
    "    predictions_RF = randomForest_Base.predict(data_test.drop([\"5\"],axis=1))\n",
    "    predictions_LR = logisticRegression_Base.predict(data_test.drop([\"5\"],axis=1))\n",
    "    predictions_KN = kNeighbors_Base.predict(data_test.drop([\"5\"],axis=1))\n",
    "\n",
    "    f1_score_GB = f1_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_GB)\n",
    "    f1_score_RF = f1_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_RF)\n",
    "    f1_score_LR = f1_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_LR)\n",
    "    f1_score_KN = f1_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_KN)\n",
    "\n",
    "    f1_score_GB_AIS = f1_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_GB_AIS) \n",
    "    f1_score_RF_AIS = f1_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_RF_AIS)\n",
    "    f1_score_LR_AIS = f1_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_LR_AIS)\n",
    "    f1_score_KN_AIS = f1_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_KN_AIS)\n",
    "\n",
    "    f1_score_GB_Base = f1_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_GB)\n",
    "    f1_score_RF_Base = f1_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_RF)\n",
    "    f1_score_LR_Base = f1_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_LR)\n",
    "    f1_score_KN_Base = f1_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_KN)\n",
    "\n",
    "    geometric_mean_score_GB = geometric_mean_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_GB, labels=None, pos_label=1, average='binary',)\n",
    "    geometric_mean_score_RF = geometric_mean_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_RF, labels=None, pos_label=1, average='binary',)\n",
    "    geometric_mean_score_LR = geometric_mean_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_LR, labels=None, pos_label=1, average='binary',)\n",
    "    geometric_mean_score_KN = geometric_mean_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_KN, labels=None, pos_label=1, average='binary',)\n",
    "\n",
    "    geometric_mean_score_GB_AIS = geometric_mean_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_GB_AIS, labels=None, pos_label=1, average='binary',)\n",
    "    geometric_mean_score_RF_AIS = geometric_mean_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_RF_AIS, labels=None, pos_label=1, average='binary',)\n",
    "    geometric_mean_score_LR_AIS = geometric_mean_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_LR_AIS, labels=None, pos_label=1, average='binary',)\n",
    "    geometric_mean_score_KN_AIS = geometric_mean_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_KN_AIS, labels=None, pos_label=1, average='binary',)\n",
    "\n",
    "    geometric_mean_score_GB_Base = geometric_mean_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_GB, labels=None, pos_label=1, average='binary',)\n",
    "    geometric_mean_score_RF_Base = geometric_mean_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_RF, labels=None, pos_label=1, average='binary',)\n",
    "    geometric_mean_score_LR_Base = geometric_mean_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_LR, labels=None, pos_label=1, average='binary',)\n",
    "    geometric_mean_score_KN_Base = geometric_mean_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_KN, labels=None, pos_label=1, average='binary',)\n",
    "\n",
    "    \n",
    "    roc_auc_GB_AIS = roc_auc_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_GB_AIS)\n",
    "    roc_auc_RF_AIS = roc_auc_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_RF_AIS)\n",
    "    roc_auc_LR_AIS = roc_auc_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_LR_AIS)\n",
    "    roc_auc_KN_AIS = roc_auc_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_KN_AIS)\n",
    " \n",
    "    roc_auc_GB_Base = roc_auc_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_GB)\n",
    "    roc_auc_RF_Base = roc_auc_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_RF)\n",
    "    roc_auc_LR_Base = roc_auc_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_LR)\n",
    "    roc_auc_KN_Base = roc_auc_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_KN)\n",
    "\n",
    "    roc_auc_GB = roc_auc_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_GB)\n",
    "    roc_auc_RF = roc_auc_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_RF)\n",
    "    roc_auc_LR = roc_auc_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_LR)\n",
    "    roc_auc_KN = roc_auc_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_KN)\n",
    "\n",
    "    \n",
    "\n",
    "    balanced_acc_GB_AIS = balanced_accuracy_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_GB_AIS)\n",
    "    balanced_acc_RF_AIS = balanced_accuracy_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_RF_AIS)\n",
    "    balanced_acc_LR_AIS = balanced_accuracy_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_LR_AIS)\n",
    "    balanced_acc_KN_AIS = balanced_accuracy_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_KN_AIS)\n",
    " \n",
    "    balanced_acc_GB = balanced_accuracy_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_GB)\n",
    "    balanced_acc_RF = balanced_accuracy_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_RF)\n",
    "    balanced_acc_LR = balanced_accuracy_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_LR)\n",
    "    balanced_acc_KN = balanced_accuracy_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_KN)\n",
    "\n",
    "    \n",
    "    balanced_acc_GB_Base = balanced_accuracy_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_GB)\n",
    "    balanced_acc_RF_Base = balanced_accuracy_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_RF)\n",
    "    balanced_acc_LR_Base = balanced_accuracy_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_LR)\n",
    "    balanced_acc_KN_Base = balanced_accuracy_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_KN)\n",
    "\n",
    "    \n",
    "    dataAIS.append( [fold,dataset,\"AIS\", elapsed_time_AIS,\"max_rounds = 200, stopping_cond = 50, model = kNeighbors,K_folds = 5,scorer = 'f1',min_change = 0.001, use_lof = False, This is testing Niks changes in fitness\", roc_auc_GB_AIS, roc_auc_RF_AIS, roc_auc_LR_AIS, roc_auc_KN_AIS, balanced_acc_GB_AIS, balanced_acc_RF_AIS,  balanced_acc_LR_AIS,  balanced_acc_KN_AIS, geometric_mean_score_GB_AIS, geometric_mean_score_RF_AIS, geometric_mean_score_LR_AIS, geometric_mean_score_KN_AIS,f1_score_GB_AIS,f1_score_RF_AIS,f1_score_LR_AIS,f1_score_KN_AIS ])\n",
    "    dataSMOTE.append([fold,dataset,\"SMOTE\", elapsed_time_SMOTE,\"NA\", roc_auc_GB,  roc_auc_RF, roc_auc_LR,roc_auc_KN, balanced_acc_GB, balanced_acc_RF,  balanced_acc_LR,  balanced_acc_KN, geometric_mean_score_GB, geometric_mean_score_RF, geometric_mean_score_LR, geometric_mean_score_KN,f1_score_GB,f1_score_RF,f1_score_LR,f1_score_KN])\n",
    "    dataBase.append([fold,dataset,\"BASE\", \"NA\",\"NA\", roc_auc_GB_Base, roc_auc_RF_Base, roc_auc_LR_Base, roc_auc_KN_Base, balanced_acc_GB_Base, balanced_acc_RF_Base,balanced_acc_LR_Base,  balanced_acc_KN_Base, geometric_mean_score_GB_Base, geometric_mean_score_RF_Base, geometric_mean_score_LR_Base, geometric_mean_score_KN_Base,f1_score_GB_Base,f1_score_RF_Base,f1_score_LR_Base,f1_score_KN_Base])\n",
    "    data.append(dataAIS[fold-1])\n",
    "    data.append(dataSMOTE[fold-1])\n",
    "    data.append(dataBase[fold-1])\n",
    "    data.append([\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"])\n",
    "\n",
    "average_AIS_Runtime = 0\n",
    "\n",
    "average_roc_auc_GB_AIS = 0\n",
    "average_roc_auc_RF_AIS = 0\n",
    "average_roc_auc_LR_AIS = 0\n",
    "average_roc_auc_KN_AIS = 0\n",
    "\n",
    "average_balanced_acc_GB_AIS = 0\n",
    "average_balanced_acc_RF_AIS = 0\n",
    "average_balanced_acc_LR_AIS = 0\n",
    "average_balanced_acc_KN_AIS = 0\n",
    "\n",
    "average_geometric_mean_score_GB_AIS = 0\n",
    "average_geometric_mean_score_RF_AIS = 0\n",
    "average_geometric_mean_score_LR_AIS = 0\n",
    "average_geometric_mean_score_KN_AIS = 0\n",
    "    \n",
    "average_f1_score_GB_AIS = 0\n",
    "average_f1_score_RF_AIS = 0\n",
    "average_f1_score_LR_AIS = 0\n",
    "average_f1_score_KN_AIS = 0\n",
    "\n",
    "\n",
    "average_SMOTE_Runtime = 0\n",
    "\n",
    "average_roc_auc_GB = 0\n",
    "average_roc_auc_RF = 0\n",
    "average_roc_auc_LR = 0\n",
    "average_roc_auc_KN = 0\n",
    "\n",
    "average_balanced_acc_GB = 0\n",
    "average_balanced_acc_RF = 0\n",
    "average_balanced_acc_LR = 0\n",
    "average_balanced_acc_KN = 0\n",
    "\n",
    "average_geometric_mean_score_GB = 0\n",
    "average_geometric_mean_score_RF = 0\n",
    "average_geometric_mean_score_LR = 0\n",
    "average_geometric_mean_score_KN = 0\n",
    "    \n",
    "average_f1_score_GB = 0\n",
    "average_f1_score_RF = 0\n",
    "average_f1_score_LR = 0\n",
    "average_f1_score_KN = 0\n",
    "\n",
    "average_roc_auc_GB_Base = 0\n",
    "average_roc_auc_RF_Base = 0\n",
    "average_roc_auc_LR_Base = 0\n",
    "average_roc_auc_KN_Base = 0\n",
    "\n",
    "average_balanced_acc_GB_Base = 0\n",
    "average_balanced_acc_RF_Base = 0\n",
    "average_balanced_acc_LR_Base = 0\n",
    "average_balanced_acc_KN_Base = 0\n",
    "\n",
    "average_geometric_mean_score_GB_Base = 0\n",
    "average_geometric_mean_score_RF_Base = 0\n",
    "average_geometric_mean_score_LR_Base = 0\n",
    "average_geometric_mean_score_KN_Base = 0\n",
    "    \n",
    "average_f1_score_GB_Base = 0\n",
    "average_f1_score_RF_Base = 0\n",
    "average_f1_score_LR_Base = 0\n",
    "average_f1_score_KN_Base = 0\n",
    "\n",
    "for array in dataAIS:\n",
    "\n",
    "    average_AIS_Runtime = average_AIS_Runtime + array[3]\n",
    "\n",
    "    average_roc_auc_GB_AIS = average_roc_auc_GB_AIS + array[5]\n",
    "    average_roc_auc_RF_AIS = average_roc_auc_RF_AIS + array[6]\n",
    "    average_roc_auc_LR_AIS = average_roc_auc_LR_AIS + array[7]\n",
    "    average_roc_auc_KN_AIS = average_roc_auc_KN_AIS + array[8]\n",
    "\n",
    "    average_balanced_acc_GB_AIS = average_balanced_acc_GB_AIS + array[9]\n",
    "    average_balanced_acc_RF_AIS = average_balanced_acc_RF_AIS + array[10]\n",
    "    average_balanced_acc_LR_AIS = average_balanced_acc_LR_AIS + array[11]\n",
    "    average_balanced_acc_KN_AIS = average_balanced_acc_KN_AIS + array[12]\n",
    "\n",
    "    average_geometric_mean_score_GB_AIS = average_geometric_mean_score_GB_AIS + array[13]\n",
    "    average_geometric_mean_score_RF_AIS = average_geometric_mean_score_RF_AIS + array[14]\n",
    "    average_geometric_mean_score_LR_AIS = average_geometric_mean_score_LR_AIS + array[15]\n",
    "    average_geometric_mean_score_KN_AIS = average_geometric_mean_score_KN_AIS + array[16]\n",
    "    \n",
    "    average_f1_score_GB_AIS = average_f1_score_GB_AIS + array[17]\n",
    "    average_f1_score_RF_AIS = average_f1_score_RF_AIS + array[18]\n",
    "    average_f1_score_LR_AIS = average_f1_score_LR_AIS + array[19]\n",
    "    average_f1_score_KN_AIS = average_f1_score_KN_AIS + array[20]\n",
    "\n",
    "for array in dataSMOTE:\n",
    "\n",
    "    average_SMOTE_Runtime = average_SMOTE_Runtime + array[3]\n",
    "\n",
    "    average_roc_auc_GB = average_roc_auc_GB + array[5]\n",
    "    average_roc_auc_RF = average_roc_auc_RF + array[6]\n",
    "    average_roc_auc_LR = average_roc_auc_LR + array[7]\n",
    "    average_roc_auc_KN = average_roc_auc_KN + array[8]\n",
    "\n",
    "    average_balanced_acc_GB = average_balanced_acc_GB + array[9]\n",
    "    average_balanced_acc_RF = average_balanced_acc_RF + array[10]\n",
    "    average_balanced_acc_LR = average_balanced_acc_LR + array[11]\n",
    "    average_balanced_acc_KN = average_balanced_acc_KN + array[12]\n",
    "\n",
    "    average_geometric_mean_score_GB = average_geometric_mean_score_GB + array[13]\n",
    "    average_geometric_mean_score_RF = average_geometric_mean_score_RF + array[14]\n",
    "    average_geometric_mean_score_LR = average_geometric_mean_score_LR + array[15]\n",
    "    average_geometric_mean_score_KN = average_geometric_mean_score_KN + array[16]\n",
    "    \n",
    "    average_f1_score_GB = average_f1_score_GB + array[17]\n",
    "    average_f1_score_RF = average_f1_score_RF + array[18]\n",
    "    average_f1_score_LR = average_f1_score_LR + array[19]\n",
    "    average_f1_score_KN = average_f1_score_KN + array[20]\n",
    "\n",
    "for array in dataBase:\n",
    "\n",
    "    average_roc_auc_GB_Base = average_roc_auc_GB_Base + array[5]\n",
    "    average_roc_auc_RF_Base = average_roc_auc_RF_Base + array[6]\n",
    "    average_roc_auc_LR_Base = average_roc_auc_LR_Base + array[7]\n",
    "    average_roc_auc_KN_Base = average_roc_auc_KN_Base + array[8]\n",
    "\n",
    "    average_balanced_acc_GB_Base = average_balanced_acc_GB_Base + array[9]\n",
    "    average_balanced_acc_RF_Base = average_balanced_acc_RF_Base + array[10]\n",
    "    average_balanced_acc_LR_Base = average_balanced_acc_LR_Base + array[11]\n",
    "    average_balanced_acc_KN_Base = average_balanced_acc_KN_Base + array[12]\n",
    "\n",
    "    average_geometric_mean_score_GB_Base = average_geometric_mean_score_GB_Base + array[13]\n",
    "    average_geometric_mean_score_RF_Base = average_geometric_mean_score_RF_Base + array[14]\n",
    "    average_geometric_mean_score_LR_Base = average_geometric_mean_score_LR_Base + array[15]\n",
    "    average_geometric_mean_score_KN_Base = average_geometric_mean_score_KN_Base + array[16]\n",
    "    \n",
    "    average_f1_score_GB_Base = average_f1_score_GB_Base + array[17]\n",
    "    average_f1_score_RF_Base = average_f1_score_RF_Base + array[18]\n",
    "    average_f1_score_LR_Base = average_f1_score_LR_Base + array[19]\n",
    "    average_f1_score_KN_Base = average_f1_score_KN_Base + array[20]\n",
    "\n",
    "average_f1_score_GB = average_f1_score_GB / fold\n",
    "average_f1_score_RF = average_f1_score_RF / fold\n",
    "average_f1_score_LR = average_f1_score_LR / fold\n",
    "average_f1_score_KN= average_f1_score_KN / fold\n",
    "\n",
    "average_f1_score_GB_AIS = average_f1_score_GB_AIS / fold\n",
    "average_f1_score_RF_AIS = average_f1_score_RF_AIS / fold\n",
    "average_f1_score_LR_AIS = average_f1_score_LR_AIS / fold\n",
    "average_f1_score_KN_AIS = average_f1_score_KN_AIS / fold\n",
    "\n",
    "average_f1_score_GB_Base = average_f1_score_GB_Base / fold\n",
    "average_f1_score_RF_Base = average_f1_score_RF_Base / fold\n",
    "average_f1_score_LR_Base = average_f1_score_LR_Base / fold\n",
    "average_f1_score_KN_Base= average_f1_score_KN_Base / fold\n",
    "\n",
    "average_geometric_mean_score_GB = average_geometric_mean_score_GB / fold\n",
    "average_geometric_mean_score_RF= average_geometric_mean_score_RF / fold\n",
    "average_geometric_mean_score_LR= average_geometric_mean_score_LR / fold\n",
    "average_geometric_mean_score_KN = average_geometric_mean_score_KN / fold\n",
    "\n",
    "average_geometric_mean_score_GB_AIS= average_geometric_mean_score_GB_AIS / fold\n",
    "average_geometric_mean_score_RF_AIS= average_geometric_mean_score_RF_AIS / fold\n",
    "average_geometric_mean_score_LR_AIS = average_geometric_mean_score_LR_AIS / fold\n",
    "average_geometric_mean_score_KN_AIS = average_geometric_mean_score_KN_AIS / fold\n",
    "\n",
    "average_geometric_mean_score_GB_Base = average_geometric_mean_score_GB_Base / fold\n",
    "average_geometric_mean_score_RF_Base= average_geometric_mean_score_RF_Base / fold\n",
    "average_geometric_mean_score_LR_Base= average_geometric_mean_score_LR_Base / fold\n",
    "average_geometric_mean_score_KN_Base= average_geometric_mean_score_KN_Base / fold\n",
    "\n",
    "    \n",
    "average_roc_auc_GB_AIS= average_roc_auc_GB_AIS / fold\n",
    "average_roc_auc_RF_AIS= average_roc_auc_RF_AIS / fold\n",
    "average_roc_auc_LR_AIS= average_roc_auc_LR_AIS / fold\n",
    "average_roc_auc_KN_AIS= average_roc_auc_KN_AIS / fold\n",
    " \n",
    "average_roc_auc_GB_Base = average_roc_auc_GB_Base / fold\n",
    "average_roc_auc_RF_Base= average_roc_auc_RF_Base / fold\n",
    "average_roc_auc_LR_Base= average_roc_auc_LR_Base / fold\n",
    "average_roc_auc_KN_Base= average_roc_auc_KN_Base / fold\n",
    "\n",
    "average_roc_auc_GB= average_roc_auc_GB / fold\n",
    "average_roc_auc_RF= average_roc_auc_RF / fold\n",
    "average_roc_auc_LR= average_roc_auc_LR / fold\n",
    "average_roc_auc_KN= average_roc_auc_KN / fold\n",
    "\n",
    "    \n",
    "\n",
    "average_balanced_acc_GB_AIS= average_balanced_acc_GB_AIS / fold\n",
    "average_balanced_acc_RF_AIS= average_balanced_acc_RF_AIS / fold\n",
    "average_balanced_acc_LR_AIS= average_balanced_acc_LR_AIS / fold\n",
    "average_balanced_acc_KN_AIS= average_balanced_acc_KN_AIS / fold\n",
    " \n",
    "average_balanced_acc_GB= average_balanced_acc_GB / fold\n",
    "average_balanced_acc_RF= average_balanced_acc_RF / fold\n",
    "average_balanced_acc_LR= average_balanced_acc_LR / fold\n",
    "average_balanced_acc_KN= average_balanced_acc_KN / fold\n",
    "\n",
    "    \n",
    "average_balanced_acc_GB_Base= average_balanced_acc_GB_Base / fold\n",
    "average_balanced_acc_RF_Base= average_balanced_acc_RF_Base / fold\n",
    "average_balanced_acc_LR_Base= average_balanced_acc_LR_Base / fold\n",
    "average_balanced_acc_KN_Base= average_balanced_acc_KN_Base / fold\n",
    "\n",
    "\n",
    "\n",
    "data.append( [\"\",\"\",\"AIS\", \"\",\"AVERAGE:\", average_roc_auc_GB_AIS, average_roc_auc_RF_AIS, average_roc_auc_LR_AIS, average_roc_auc_KN_AIS, average_balanced_acc_GB_AIS, average_balanced_acc_RF_AIS,  average_balanced_acc_LR_AIS,  average_balanced_acc_KN_AIS, average_geometric_mean_score_GB_AIS, average_geometric_mean_score_RF_AIS, average_geometric_mean_score_LR_AIS, average_geometric_mean_score_KN_AIS,average_f1_score_GB_AIS,average_f1_score_RF_AIS,average_f1_score_LR_AIS,average_f1_score_KN_AIS ])\n",
    "data.append([\"\",\"\",\"SMOTE\", \"\",\"AVERAGE:\", average_roc_auc_GB,  average_roc_auc_RF, average_roc_auc_LR,average_roc_auc_KN, average_balanced_acc_GB, average_balanced_acc_RF,  average_balanced_acc_LR,  average_balanced_acc_KN, average_geometric_mean_score_GB, average_geometric_mean_score_RF, average_geometric_mean_score_LR, average_geometric_mean_score_KN,average_f1_score_GB,average_f1_score_RF,average_f1_score_LR,average_f1_score_KN])\n",
    "data.append([\"\",\"\",\"BASE\", \"\",\"AVERAGE:\", average_roc_auc_GB_Base, average_roc_auc_RF_Base, average_roc_auc_LR_Base, average_roc_auc_KN_Base, average_balanced_acc_GB_Base, average_balanced_acc_RF_Base,balanced_acc_LR_Base,  average_balanced_acc_KN_Base, average_geometric_mean_score_GB_Base, average_geometric_mean_score_RF_Base, average_geometric_mean_score_LR_Base, average_geometric_mean_score_KN_Base,average_f1_score_GB_Base,average_f1_score_RF_Base,average_f1_score_LR_Base,average_f1_score_KN_Base])\n",
    "data.append([\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "col_names = [\"Fold\", \"Dataset\",\"Oversample\",\"Oversample Run Time\", \"Oversample Paramaters\", \"ROC AUC for Gradient Boosting\",  \"ROC AUC for Random Forests\", \"ROC AUC for Logistic Regression\",  \"ROC AUC for K Nearest Neighbours\", \"Balanced Accuracy for Gradient Boosting\", \"Balanced Accuracy for Random Forests\" ,\"Balanced Accuracy for Logistic Regression\",\"Balanced Accuracy for K Nearest Neighbours\", \"Geometric Mean Score for Gradient Boosting\", \"Geometric Mean Score for Random Forest\", \"Geometric Mean Score for Logestic Regression\", \"Geometric Mean Score for K Neighbors\", \"F1 Score for Gradient Boosting\", \"F1 Score for Random Forest\", \"F1 Score for Logestic Regression\", \"F1 Score for K Neighbors\"]\n",
    "dfoutput=pd.DataFrame(data,columns=col_names)\n",
    "title = \"ExperimentalResults/ExperimentalComparisons-TestingOverlapingData.csv\"\n",
    "dfoutput.to_csv(title, mode='a',index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aisOversample = ArtificialImmuneSystem()\n",
    "#minority_class = df[df['5'] == 1]\n",
    "#majority_class = df[df['5'] == 0]\n",
    "\n",
    "#requiredPopulation = len(majority_class)-len(minority_class)\n",
    "#population = aisOversample.AIS(minority_class, max_rounds=100, totalPopulation=requiredPopulation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting Labels\n",
    "#Get a list of all columns\n",
    "#columns = data_train.columns.to_list()\n",
    "#Remove the label and save it\n",
    "#columns_drop = columns.pop(-1)\n",
    "\n",
    "#Remove all labels except for the label in the train and test dataframe\n",
    "#labels_train = data_train.drop(columns, axis=1)\n",
    "#labels_test = data_test.drop(columns, axis=1)\n",
    "\n",
    "#Print the labesl of the test and train\n",
    "#print(f\"labels_train: \\n{labels_train}\\n\")\n",
    "#print(f\"labels_test: \\n{labels_test}\\n\")\n",
    "\n",
    "#Remove the label from the train and test dataframe\n",
    "#features_train = data_train.drop(['5'], axis=1)\n",
    "#features_test = data_test.drop(['5'], axis=1)\n",
    "\n",
    "#Print the features of the train and test dataset\n",
    "#print(f\"features_train: \\n{features_train }\\n\")\n",
    "#print(f\"lfeatures_test: \\n{features_test }\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('csi4106')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "51ea9996f2a91c7d112e626959c304b606e4bf2254e73fec145d965796b2ca69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
