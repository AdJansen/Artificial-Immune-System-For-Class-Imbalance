{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, cross_val_score, GridSearchCV, cross_validate\n",
    "\n",
    "# importing two different imputation methods that take into consideration all the features when predicting the missing values\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "#multiclass imports\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.dummy import DummyClassifier #Will identify the maority calss base line, model needs to do better then the baseline\n",
    "\n",
    "from statistics import mean\n",
    "# to reduce randomness then you put the seed\n",
    "np.random.seed(42)\n",
    "\n",
    "from ArtificialImmuneSystem import *\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from tabulate import tabulate\n",
    "import time\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'Data\\GeneratedSyntheticData-testing.csv'\n",
    "df = pd.read_csv(dataset)\n",
    "#df = df.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: \n",
      "(300, 6)\n",
      "\n",
      "Data size: \n",
      "1800\n",
      "\n",
      "Data ndim: \n",
      "2\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Old Class Distribution: Counter({0.0: 247, 1.0: 53})\n"
     ]
    }
   ],
   "source": [
    "print(f\"Data shape: \\n{df.shape}\\n\")\n",
    "print(f\"Data size: \\n{df.size}\\n\")\n",
    "print(f\"Data ndim: \\n{df.ndim}\\n\")\n",
    "print(\"_____________________________________________\\n\")\n",
    "print(f\"Old Class Distribution: {Counter(df['5'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score1: 0.403037998663371\n",
      "score2: 0.635946922221432\n",
      "score1: 0.635946922221432\n",
      "score2: 0.6214282804074671\n",
      "score1: 0.635946922221432\n",
      "score2: 0.3144914862914864\n",
      "score1: 0.635946922221432\n",
      "score2: 0.3029385336075115\n",
      "score1: 0.635946922221432\n",
      "score2: 0.1579929793882397\n",
      "score1: 0.635946922221432\n",
      "score2: 0.2867873695846299\n",
      "score1: 0.635946922221432\n",
      "score2: 0.2750371393086878\n",
      "score1: 0.635946922221432\n",
      "score2: 0.4463285940829801\n",
      "score1: 0.635946922221432\n",
      "score2: 0.6123401643401644\n",
      "score1: 0.635946922221432\n",
      "score2: 0.15566584127987637\n",
      "score1: 0.635946922221432\n",
      "score2: 0.47269606005808545\n",
      "score1: 0.635946922221432\n",
      "score2: 0.4547721992293422\n",
      "score1: 0.635946922221432\n",
      "score2: 0.46911937623360983\n",
      "score1: 0.635946922221432\n",
      "score2: 0.2995466472062217\n",
      "score1: 0.635946922221432\n",
      "score2: 0.16238382908767884\n",
      "score1: 0.635946922221432\n",
      "score2: 0.421933680354733\n",
      "score1: 0.635946922221432\n",
      "score2: 0.4765757144704514\n",
      "score1: 0.635946922221432\n",
      "score2: 0.4199767516434183\n",
      "score1: 0.635946922221432\n",
      "score2: 0.5019769610653331\n",
      "score1: 0.635946922221432\n",
      "score2: 0.635559965281057\n",
      "score1: 0.635946922221432\n",
      "score2: 0.5537310386090875\n",
      "score1: 0.635946922221432\n",
      "score2: 0.3042100857313672\n",
      "score1: 0.635946922221432\n",
      "score2: 0.5715246628570381\n",
      "score1: 0.635946922221432\n",
      "score2: 0.49097616769195723\n",
      "score1: 0.635946922221432\n",
      "score2: 0.15622861528715187\n",
      "score1: 0.635946922221432\n",
      "score2: 0.16402477622628\n",
      "score1: 0.635946922221432\n",
      "score2: 0.1609908777446561\n",
      "score1: 0.635946922221432\n",
      "score2: 0.6545683969575613\n",
      "score1: 0.6545683969575613\n",
      "score2: 0.3084316998241049\n",
      "score1: 0.6545683969575613\n",
      "score2: 0.15997781992518836\n",
      "score1: 0.6545683969575613\n",
      "score2: 0.15309065083034892\n",
      "score1: 0.6545683969575613\n",
      "score2: 0.3127326417309096\n",
      "score1: 0.6545683969575613\n",
      "score2: 0.4408124907710567\n",
      "score1: 0.6545683969575613\n",
      "score2: 0.4552611765744296\n",
      "score1: 0.6545683969575613\n",
      "score2: 0.3550396250351532\n",
      "score1: 0.6545683969575613\n",
      "score2: 0.40715124875124875\n",
      "score1: 0.6545683969575613\n",
      "score2: 0.37703772825724047\n",
      "score1: 0.6545683969575613\n",
      "score2: 0.3871122517851643\n",
      "score1: 0.6545683969575613\n",
      "score2: 0.30012995620364047\n",
      "score1: 0.6545683969575613\n",
      "score2: 0.15438335294537828\n",
      "score1: 0.6545683969575613\n",
      "score2: 0.2661980247600501\n",
      "score1: 0.6545683969575613\n",
      "score2: 0.42207339310695746\n",
      "score1: 0.6545683969575613\n",
      "score2: 0.5588047301971353\n",
      "score1: 0.6545683969575613\n",
      "score2: 0.42135796075901044\n",
      "score1: 0.6545683969575613\n",
      "score2: 0.3152975020269692\n",
      "score1: 0.6545683969575613\n",
      "score2: 0.46200261631494516\n",
      "score1: 0.6545683969575613\n",
      "score2: 0.29940605253063624\n",
      "score1: 0.6545683969575613\n",
      "score2: 0.508487085838253\n",
      "score1: 0.6545683969575613\n",
      "score2: 0.6481717880784705\n",
      "score1: 0.6545683969575613\n",
      "score2: 0.15629394595612467\n",
      "score1: 0.6545683969575613\n",
      "score2: 0.3966175393110706\n",
      "score1: 0.6545683969575613\n",
      "score2: 0.3529327212871517\n",
      "score1: 0.6545683969575613\n",
      "score2: 0.3983276752897006\n",
      "score1: 0.6545683969575613\n",
      "score2: 0.4212054566732328\n",
      "score1: 0.6545683969575613\n",
      "score2: 0.41707688327635656\n",
      "score1: 0.6545683969575613\n",
      "score2: 0.3582374360655507\n",
      "score1: 0.6545683969575613\n",
      "score2: 0.15763636323199867\n",
      "score1: 0.6545683969575613\n",
      "score2: 0.3692595510519562\n",
      "score1: 0.6545683969575613\n",
      "score2: 0.51603454276401\n",
      "score1: 0.6545683969575613\n",
      "score2: 0.1604032639738882\n",
      "score1: 0.6545683969575613\n",
      "score2: 0.31680009622607475\n",
      "score1: 0.6545683969575613\n",
      "score2: 0.3725996810207337\n",
      "score1: 0.6545683969575613\n",
      "score2: 0.5509001476124764\n",
      "score1: 0.6545683969575613\n",
      "score2: 0.4986923096456904\n",
      "score1: 0.6545683969575613\n",
      "score2: 0.3532239932239932\n",
      "score1: 0.6545683969575613\n",
      "score2: 0.4939007659007659\n",
      "score1: 0.6545683969575613\n",
      "score2: 0.5230869943065065\n",
      "score1: 0.6545683969575613\n",
      "score2: 0.4767695035450144\n",
      "score1: 0.6545683969575613\n",
      "score2: 0.6171433111413326\n",
      "score1: 0.6545683969575613\n",
      "score2: 0.4741715704448749\n",
      "score1: 0.6545683969575613\n",
      "score2: 0.3598888888888889\n",
      "score1: 0.6545683969575613\n",
      "score2: 0.1548360298336202\n",
      "score1: 0.6545683969575613\n",
      "score2: 0.4542716932190617\n",
      "score1: 0.6545683969575613\n",
      "score2: 0.29582739012013975\n",
      "score1: 0.6545683969575613\n",
      "score2: 0.40508826704208484\n",
      "score1: 0.6545683969575613\n",
      "score2: 0.35611236158601484\n",
      "score1: 0.6545683969575613\n",
      "score2: 0.16125120529077022\n",
      "score1: 0.6545683969575613\n",
      "score2: 0.2850476167858076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jacob\\AppData\\Local\\Temp/ipykernel_17184/519229823.py:83: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  randomForest_Base = randomForest.fit(data_train.drop([\"5\"], axis=1), data_train.drop(data_train_AIS.columns[0:-1],axis=1))\n",
      "c:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score GradientBoosting: \n",
      "0.7653061224489797\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score GradientBoosting AIS: \n",
      "0.8880612244897959\n",
      "\n",
      "Best score KNeighbors: \n",
      "0.7731122448979593\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score KNeighbors AIS: \n",
      "0.85\n",
      "\n",
      "Best score Logistic Regression: \n",
      "0.5203061224489796\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score Logistic Regression AIS: \n",
      "0.7719897959183675\n",
      "\n",
      "Best score RandomForest: \n",
      "0.7451020408163265\n",
      "\n",
      "Best score RandomForest AIS: \n",
      "0.9108163265306122\n",
      "\n",
      "score1: 0.49524883159452876\n",
      "score2: 0.3381980296946689\n",
      "score1: 0.49524883159452876\n",
      "score2: 0.1549009344278252\n",
      "score1: 0.49524883159452876\n",
      "score2: 0.5740677472011286\n",
      "score1: 0.5740677472011286\n",
      "score2: 0.3743753664774942\n",
      "score1: 0.5740677472011286\n",
      "score2: 0.5247527367147621\n",
      "score1: 0.5740677472011286\n",
      "score2: 0.4502531031135151\n",
      "score1: 0.5740677472011286\n",
      "score2: 0.42140794399717807\n",
      "score1: 0.5740677472011286\n",
      "score2: 0.5796987654320989\n",
      "score1: 0.5796987654320989\n",
      "score2: 0.4217971758664955\n",
      "score1: 0.5796987654320989\n",
      "score2: 0.5951899532501563\n",
      "score1: 0.5951899532501563\n",
      "score2: 0.629407426488234\n",
      "score1: 0.629407426488234\n",
      "score2: 0.36411910774779976\n",
      "score1: 0.629407426488234\n",
      "score2: 0.29562070648078353\n",
      "score1: 0.629407426488234\n",
      "score2: 0.3803636363636364\n",
      "score1: 0.629407426488234\n",
      "score2: 0.38559318275821497\n",
      "score1: 0.629407426488234\n",
      "score2: 0.29706048745774777\n",
      "score1: 0.629407426488234\n",
      "score2: 0.4949953344900713\n",
      "score1: 0.629407426488234\n",
      "score2: 0.5265264127046206\n",
      "score1: 0.629407426488234\n",
      "score2: 0.4725462304409673\n",
      "score1: 0.629407426488234\n",
      "score2: 0.36407889502626345\n",
      "score1: 0.629407426488234\n",
      "score2: 0.5577882117882118\n",
      "score1: 0.629407426488234\n",
      "score2: 0.2827589822917475\n",
      "score1: 0.629407426488234\n",
      "score2: 0.5187219156839411\n",
      "score1: 0.629407426488234\n",
      "score2: 0.5566208194056296\n",
      "score1: 0.629407426488234\n",
      "score2: 0.6424303016996701\n",
      "score1: 0.6424303016996701\n",
      "score2: 0.6569888472619985\n",
      "score1: 0.6569888472619985\n",
      "score2: 0.15216084633806154\n",
      "score1: 0.6569888472619985\n",
      "score2: 0.48497214924862353\n",
      "score1: 0.6569888472619985\n",
      "score2: 0.297716833890747\n",
      "score1: 0.6569888472619985\n",
      "score2: 0.5810903960237294\n",
      "score1: 0.6569888472619985\n",
      "score2: 0.6424729154922361\n",
      "score1: 0.6569888472619985\n",
      "score2: 0.3206910957788151\n",
      "score1: 0.6569888472619985\n",
      "score2: 0.6315680644739469\n",
      "score1: 0.6569888472619985\n",
      "score2: 0.36452670030391554\n",
      "score1: 0.6569888472619985\n",
      "score2: 0.41875069491911604\n",
      "score1: 0.6569888472619985\n",
      "score2: 0.3067422602089269\n",
      "score1: 0.6569888472619985\n",
      "score2: 0.39685222039785667\n",
      "score1: 0.6569888472619985\n",
      "score2: 0.6128454017927704\n",
      "score1: 0.6569888472619985\n",
      "score2: 0.25926833716307407\n",
      "score1: 0.6569888472619985\n",
      "score2: 0.42401347348715773\n",
      "score1: 0.6569888472619985\n",
      "score2: 0.2710845759007259\n",
      "score1: 0.6569888472619985\n",
      "score2: 0.551959151959152\n",
      "score1: 0.6569888472619985\n",
      "score2: 0.45623764038010617\n",
      "score1: 0.6569888472619985\n",
      "score2: 0.4969903393447697\n",
      "score1: 0.6569888472619985\n",
      "score2: 0.6095317840054683\n",
      "score1: 0.6569888472619985\n",
      "score2: 0.36648185387425897\n",
      "score1: 0.6569888472619985\n",
      "score2: 0.39740158575601614\n",
      "score1: 0.6569888472619985\n",
      "score2: 0.2849604495498721\n",
      "score1: 0.6569888472619985\n",
      "score2: 0.5966103002688369\n",
      "score1: 0.6569888472619985\n",
      "score2: 0.1620848172587303\n",
      "score1: 0.6569888472619985\n",
      "score2: 0.16448313090418357\n",
      "score1: 0.6569888472619985\n",
      "score2: 0.44575119617224884\n",
      "score1: 0.6569888472619985\n",
      "score2: 0.36522776184400146\n",
      "score1: 0.6569888472619985\n",
      "score2: 0.4369313598258338\n",
      "score1: 0.6569888472619985\n",
      "score2: 0.5218286880147011\n",
      "score1: 0.6569888472619985\n",
      "score2: 0.2617612212349055\n",
      "score1: 0.6569888472619985\n",
      "score2: 0.4578101839965769\n",
      "score1: 0.6569888472619985\n",
      "score2: 0.45035550424576193\n",
      "score1: 0.6569888472619985\n",
      "score2: 0.6228262013987504\n",
      "score1: 0.6569888472619985\n",
      "score2: 0.3954212110797477\n",
      "score1: 0.6569888472619985\n",
      "score2: 0.41767252538299243\n",
      "score1: 0.6569888472619985\n",
      "score2: 0.4711416638823923\n",
      "score1: 0.6569888472619985\n",
      "score2: 0.3816973442718198\n",
      "score1: 0.6569888472619985\n",
      "score2: 0.6103520050263592\n",
      "score1: 0.6569888472619985\n",
      "score2: 0.4418865306559686\n",
      "score1: 0.6569888472619985\n",
      "score2: 0.3112983717928598\n",
      "score1: 0.6569888472619985\n",
      "score2: 0.2922736369543387\n",
      "score1: 0.6569888472619985\n",
      "score2: 0.4959735926402593\n",
      "score1: 0.6569888472619985\n",
      "score2: 0.1580977909020405\n",
      "score1: 0.6569888472619985\n",
      "score2: 0.3289578247350399\n",
      "score1: 0.6569888472619985\n",
      "score2: 0.292878795992049\n",
      "score1: 0.6569888472619985\n",
      "score2: 0.6291300439854657\n",
      "score1: 0.6569888472619985\n",
      "score2: 0.35857592724513976\n",
      "score1: 0.6569888472619985\n",
      "score2: 0.5087938748212721\n",
      "score1: 0.6569888472619985\n",
      "score2: 0.6190537037216114\n",
      "score1: 0.6569888472619985\n",
      "score2: 0.5496183362850029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jacob\\AppData\\Local\\Temp/ipykernel_17184/519229823.py:83: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  randomForest_Base = randomForest.fit(data_train.drop([\"5\"], axis=1), data_train.drop(data_train_AIS.columns[0:-1],axis=1))\n",
      "c:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score GradientBoosting: \n",
      "0.7605761054421768\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score GradientBoosting AIS: \n",
      "0.8675595238095237\n",
      "\n",
      "Best score KNeighbors: \n",
      "0.8144132653061225\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score KNeighbors AIS: \n",
      "0.8492772108843538\n",
      "\n",
      "Best score Logistic Regression: \n",
      "0.5026041666666667\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score Logistic Regression AIS: \n",
      "0.7128507653061225\n",
      "\n",
      "Best score RandomForest: \n",
      "0.7605229591836734\n",
      "\n",
      "Best score RandomForest AIS: \n",
      "0.8778698979591837\n",
      "\n",
      "score1: 0.5602699380518024\n",
      "score2: 0.5575746280247259\n",
      "score1: 0.5602699380518024\n",
      "score2: 0.3374743198217745\n",
      "score1: 0.5602699380518024\n",
      "score2: 0.42711990830069163\n",
      "score1: 0.5602699380518024\n",
      "score2: 0.1662328003149921\n",
      "score1: 0.5602699380518024\n",
      "score2: 0.5869646317114672\n",
      "score1: 0.5869646317114672\n",
      "score2: 0.5267927688749607\n",
      "score1: 0.5869646317114672\n",
      "score2: 0.6323524396840853\n",
      "score1: 0.6323524396840853\n",
      "score2: 0.35626711138906264\n",
      "score1: 0.6323524396840853\n",
      "score2: 0.2641030833349653\n",
      "score1: 0.6323524396840853\n",
      "score2: 0.6082827638717047\n",
      "score1: 0.6323524396840853\n",
      "score2: 0.5399785411642997\n",
      "score1: 0.6323524396840853\n",
      "score2: 0.3053030663244981\n",
      "score1: 0.6323524396840853\n",
      "score2: 0.50786223004809\n",
      "score1: 0.6323524396840853\n",
      "score2: 0.38741786886217733\n",
      "score1: 0.6323524396840853\n",
      "score2: 0.2862132827167179\n",
      "score1: 0.6323524396840853\n",
      "score2: 0.44426535591011723\n",
      "score1: 0.6323524396840853\n",
      "score2: 0.44264895663962955\n",
      "score1: 0.6323524396840853\n",
      "score2: 0.38452139730188517\n",
      "score1: 0.6323524396840853\n",
      "score2: 0.32878380816855907\n",
      "score1: 0.6323524396840853\n",
      "score2: 0.29789143471787294\n",
      "score1: 0.6323524396840853\n",
      "score2: 0.47277460317460324\n",
      "score1: 0.6323524396840853\n",
      "score2: 0.3227324675324676\n",
      "score1: 0.6323524396840853\n",
      "score2: 0.3326742270075604\n",
      "score1: 0.6323524396840853\n",
      "score2: 0.44686629404350925\n",
      "score1: 0.6323524396840853\n",
      "score2: 0.5555059210831363\n",
      "score1: 0.6323524396840853\n",
      "score2: 0.31636432952974175\n",
      "score1: 0.6323524396840853\n",
      "score2: 0.4278875251472224\n",
      "score1: 0.6323524396840853\n",
      "score2: 0.3160222438443462\n",
      "score1: 0.6323524396840853\n",
      "score2: 0.5897781106219925\n",
      "score1: 0.6323524396840853\n",
      "score2: 0.460452109131179\n",
      "score1: 0.6323524396840853\n",
      "score2: 0.33477728157428366\n",
      "score1: 0.6323524396840853\n",
      "score2: 0.5264450930546403\n",
      "score1: 0.6323524396840853\n",
      "score2: 0.3038485458203768\n",
      "score1: 0.6323524396840853\n",
      "score2: 0.6863353394572906\n",
      "score1: 0.6863353394572906\n",
      "score2: 0.49363534431247136\n",
      "score1: 0.6863353394572906\n",
      "score2: 0.5514911693225988\n",
      "score1: 0.6863353394572906\n",
      "score2: 0.29740391254315307\n",
      "score1: 0.6863353394572906\n",
      "score2: 0.3965642145968515\n",
      "score1: 0.6863353394572906\n",
      "score2: 0.47541325536062384\n",
      "score1: 0.6863353394572906\n",
      "score2: 0.504662293778573\n",
      "score1: 0.6863353394572906\n",
      "score2: 0.5860518707827944\n",
      "score1: 0.6863353394572906\n",
      "score2: 0.31317132764203715\n",
      "score1: 0.6863353394572906\n",
      "score2: 0.47188158472060915\n",
      "score1: 0.6863353394572906\n",
      "score2: 0.5870813643553958\n",
      "score1: 0.6863353394572906\n",
      "score2: 0.47220466840528486\n",
      "score1: 0.6863353394572906\n",
      "score2: 0.3350458837261864\n",
      "score1: 0.6863353394572906\n",
      "score2: 0.2932282686803784\n",
      "score1: 0.6863353394572906\n",
      "score2: 0.40699445293041736\n",
      "score1: 0.6863353394572906\n",
      "score2: 0.3855704789038123\n",
      "score1: 0.6863353394572906\n",
      "score2: 0.3143508465280617\n",
      "score1: 0.6863353394572906\n",
      "score2: 0.38895169742538166\n",
      "score1: 0.6863353394572906\n",
      "score2: 0.3292203469292077\n",
      "score1: 0.6863353394572906\n",
      "score2: 0.5265114755574775\n",
      "score1: 0.6863353394572906\n",
      "score2: 0.47635647279549725\n",
      "score1: 0.6863353394572906\n",
      "score2: 0.4748317113400555\n",
      "score1: 0.6863353394572906\n",
      "score2: 0.6095213056985209\n",
      "score1: 0.6863353394572906\n",
      "score2: 0.6108283216584778\n",
      "score1: 0.6863353394572906\n",
      "score2: 0.532992247389453\n",
      "score1: 0.6863353394572906\n",
      "score2: 0.548744693057946\n",
      "score1: 0.6863353394572906\n",
      "score2: 0.5646133303660844\n",
      "score1: 0.6863353394572906\n",
      "score2: 0.5419580977937482\n",
      "score1: 0.6863353394572906\n",
      "score2: 0.5205664254444742\n",
      "score1: 0.6863353394572906\n",
      "score2: 0.44140135532540603\n",
      "score1: 0.6863353394572906\n",
      "score2: 0.6330252935862692\n",
      "score1: 0.6863353394572906\n",
      "score2: 0.15347347832890001\n",
      "score1: 0.6863353394572906\n",
      "score2: 0.37084651017915976\n",
      "score1: 0.6863353394572906\n",
      "score2: 0.5177640772278849\n",
      "score1: 0.6863353394572906\n",
      "score2: 0.49775439750123296\n",
      "score1: 0.6863353394572906\n",
      "score2: 0.1493124733929332\n",
      "score1: 0.6863353394572906\n",
      "score2: 0.3700860274102734\n",
      "score1: 0.6863353394572906\n",
      "score2: 0.6320972752737458\n",
      "score1: 0.6863353394572906\n",
      "score2: 0.4191700943483262\n",
      "score1: 0.6863353394572906\n",
      "score2: 0.4752234510454123\n",
      "score1: 0.6863353394572906\n",
      "score2: 0.3418108168870731\n",
      "score1: 0.6863353394572906\n",
      "score2: 0.7336779676020184\n",
      "score1: 0.7336779676020184\n",
      "score2: 0.2844452490408845\n",
      "score1: 0.7336779676020184\n",
      "score2: 0.4207520268029685\n",
      "score1: 0.7336779676020184\n",
      "score2: 0.38412445052117794\n",
      "score1: 0.7336779676020184\n",
      "score2: 0.28192673052236594\n",
      "score1: 0.7336779676020184\n",
      "score2: 0.5553130160978264\n",
      "score1: 0.7336779676020184\n",
      "score2: 0.3342830009496676\n",
      "score1: 0.7336779676020184\n",
      "score2: 0.614153952040131\n",
      "score1: 0.7336779676020184\n",
      "score2: 0.3535019146709998\n",
      "score1: 0.7336779676020184\n",
      "score2: 0.15898669232002566\n",
      "score1: 0.7336779676020184\n",
      "score2: 0.4193672249975512\n",
      "score1: 0.7336779676020184\n",
      "score2: 0.6468996826720405\n",
      "score1: 0.7336779676020184\n",
      "score2: 0.2989718131913254\n",
      "score1: 0.7336779676020184\n",
      "score2: 0.5378278274872702\n",
      "score1: 0.7336779676020184\n",
      "score2: 0.552662617124875\n",
      "score1: 0.7336779676020184\n",
      "score2: 0.3177687690863352\n",
      "score1: 0.7336779676020184\n",
      "score2: 0.47546724848834565\n",
      "score1: 0.7336779676020184\n",
      "score2: 0.44583166200887725\n",
      "score1: 0.7336779676020184\n",
      "score2: 0.5539188522321054\n",
      "score1: 0.7336779676020184\n",
      "score2: 0.15123394387287262\n",
      "score1: 0.7336779676020184\n",
      "score2: 0.33192156862745104\n",
      "score1: 0.7336779676020184\n",
      "score2: 0.5609583517257936\n",
      "score1: 0.7336779676020184\n",
      "score2: 0.4519385267620562\n",
      "score1: 0.7336779676020184\n",
      "score2: 0.3134428817002657\n",
      "score1: 0.7336779676020184\n",
      "score2: 0.27882501012417654\n",
      "score1: 0.7336779676020184\n",
      "score2: 0.33290782041836897\n",
      "score1: 0.7336779676020184\n",
      "score2: 0.5309272153428762\n",
      "score1: 0.7336779676020184\n",
      "score2: 0.5919410485572881\n",
      "score1: 0.7336779676020184\n",
      "score2: 0.4499079726337111\n",
      "score1: 0.7336779676020184\n",
      "score2: 0.3169985929438436\n",
      "score1: 0.7336779676020184\n",
      "score2: 0.42204761678580766\n",
      "score1: 0.7336779676020184\n",
      "score2: 0.3544753327885858\n",
      "score1: 0.7336779676020184\n",
      "score2: 0.559889131344416\n",
      "score1: 0.7336779676020184\n",
      "score2: 0.41867654625913353\n",
      "score1: 0.7336779676020184\n",
      "score2: 0.5042810746137664\n",
      "score1: 0.7336779676020184\n",
      "score2: 0.6459233144132804\n",
      "score1: 0.7336779676020184\n",
      "score2: 0.5266943426943428\n",
      "score1: 0.7336779676020184\n",
      "score2: 0.35507273538598844\n",
      "score1: 0.7336779676020184\n",
      "score2: 0.40007594843037875\n",
      "score1: 0.7336779676020184\n",
      "score2: 0.41935076252723313\n",
      "score1: 0.7336779676020184\n",
      "score2: 0.5928804578710544\n",
      "score1: 0.7336779676020184\n",
      "score2: 0.3308744125415938\n",
      "score1: 0.7336779676020184\n",
      "score2: 0.3869497385998934\n",
      "score1: 0.7336779676020184\n",
      "score2: 0.44960256199496706\n",
      "score1: 0.7336779676020184\n",
      "score2: 0.3179464187534363\n",
      "score1: 0.7336779676020184\n",
      "score2: 0.47109500450037667\n",
      "score1: 0.7336779676020184\n",
      "score2: 0.4079433837748132\n",
      "score1: 0.7336779676020184\n",
      "score2: 0.31444984616829896\n",
      "score1: 0.7336779676020184\n",
      "score2: 0.3835578326970732\n",
      "score1: 0.7336779676020184\n",
      "score2: 0.316096679400529\n",
      "score1: 0.7336779676020184\n",
      "score2: 0.15344271340473875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jacob\\AppData\\Local\\Temp/ipykernel_17184/519229823.py:83: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  randomForest_Base = randomForest.fit(data_train.drop([\"5\"], axis=1), data_train.drop(data_train_AIS.columns[0:-1],axis=1))\n",
      "c:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score GradientBoosting: \n",
      "0.7825\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score GradientBoosting AIS: \n",
      "0.905\n",
      "\n",
      "Best score KNeighbors: \n",
      "0.7975\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score KNeighbors AIS: \n",
      "0.865\n",
      "\n",
      "Best score Logistic Regression: \n",
      "0.5750000000000001\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score Logistic Regression AIS: \n",
      "0.655\n",
      "\n",
      "Best score RandomForest: \n",
      "0.765\n",
      "\n",
      "Best score RandomForest AIS: \n",
      "0.9175\n",
      "\n",
      "score1: 0.3930305110540405\n",
      "score2: 0.3135912270654795\n",
      "score1: 0.3930305110540405\n",
      "score2: 0.5187975328154433\n",
      "score1: 0.5187975328154433\n",
      "score2: 0.5274051914262441\n",
      "score1: 0.5274051914262441\n",
      "score2: 0.15891713630954138\n",
      "score1: 0.5274051914262441\n",
      "score2: 0.5542607764806171\n",
      "score1: 0.5542607764806171\n",
      "score2: 0.5372374942718523\n",
      "score1: 0.5542607764806171\n",
      "score2: 0.15656829408225237\n",
      "score1: 0.5542607764806171\n",
      "score2: 0.1584786481064275\n",
      "score1: 0.5542607764806171\n",
      "score2: 0.5592124341521932\n",
      "score1: 0.5592124341521932\n",
      "score2: 0.38251106478150265\n",
      "score1: 0.5592124341521932\n",
      "score2: 0.5546738327517258\n",
      "score1: 0.5592124341521932\n",
      "score2: 0.43011516410869544\n",
      "score1: 0.5592124341521932\n",
      "score2: 0.16796427633307065\n",
      "score1: 0.5592124341521932\n",
      "score2: 0.33160410830999065\n",
      "score1: 0.5592124341521932\n",
      "score2: 0.5672559044331196\n",
      "score1: 0.5672559044331196\n",
      "score2: 0.44349086091066325\n",
      "score1: 0.5672559044331196\n",
      "score2: 0.33815137437088655\n",
      "score1: 0.5672559044331196\n",
      "score2: 0.36580357363259186\n",
      "score1: 0.5672559044331196\n",
      "score2: 0.32352474323062563\n",
      "score1: 0.5672559044331196\n",
      "score2: 0.509437908496732\n",
      "score1: 0.5672559044331196\n",
      "score2: 0.42384234612870086\n",
      "score1: 0.5672559044331196\n",
      "score2: 0.16324965583360776\n",
      "score1: 0.5672559044331196\n",
      "score2: 0.4538194331326862\n",
      "score1: 0.5672559044331196\n",
      "score2: 0.16012869177527814\n",
      "score1: 0.5672559044331196\n",
      "score2: 0.15794051041692575\n",
      "score1: 0.5672559044331196\n",
      "score2: 0.5211968077999181\n",
      "score1: 0.5672559044331196\n",
      "score2: 0.2954907737691045\n",
      "score1: 0.5672559044331196\n",
      "score2: 0.15998763052336268\n",
      "score1: 0.5672559044331196\n",
      "score2: 0.16375692318043464\n",
      "score1: 0.5672559044331196\n",
      "score2: 0.3116750074196883\n",
      "score1: 0.5672559044331196\n",
      "score2: 0.5570245326893589\n",
      "score1: 0.5672559044331196\n",
      "score2: 0.4530356352836863\n",
      "score1: 0.5672559044331196\n",
      "score2: 0.17401591741591743\n",
      "score1: 0.5672559044331196\n",
      "score2: 0.3179850242236718\n",
      "score1: 0.5672559044331196\n",
      "score2: 0.3411427579814445\n",
      "score1: 0.5672559044331196\n",
      "score2: 0.2643229737261912\n",
      "score1: 0.5672559044331196\n",
      "score2: 0.2928774928774929\n",
      "score1: 0.5672559044331196\n",
      "score2: 0.3395630352096216\n",
      "score1: 0.5672559044331196\n",
      "score2: 0.42824199153516423\n",
      "score1: 0.5672559044331196\n",
      "score2: 0.5127064695367488\n",
      "score1: 0.5672559044331196\n",
      "score2: 0.29558990433277826\n",
      "score1: 0.5672559044331196\n",
      "score2: 0.167739837398374\n",
      "score1: 0.5672559044331196\n",
      "score2: 0.298561177116158\n",
      "score1: 0.5672559044331196\n",
      "score2: 0.16434083743920408\n",
      "score1: 0.5672559044331196\n",
      "score2: 0.3442898576385717\n",
      "score1: 0.5672559044331196\n",
      "score2: 0.4228567378758733\n",
      "score1: 0.5672559044331196\n",
      "score2: 0.35715981989080803\n",
      "score1: 0.5672559044331196\n",
      "score2: 0.16377051561365286\n",
      "score1: 0.5672559044331196\n",
      "score2: 0.16195518940438078\n",
      "score1: 0.5672559044331196\n",
      "score2: 0.1628500250341683\n",
      "score1: 0.5672559044331196\n",
      "score2: 0.2795184291769658\n",
      "score1: 0.5672559044331196\n",
      "score2: 0.40306652827354583\n",
      "score1: 0.5672559044331196\n",
      "score2: 0.16511769006268745\n",
      "score1: 0.5672559044331196\n",
      "score2: 0.1570122197232795\n",
      "score1: 0.5672559044331196\n",
      "score2: 0.31607797884101124\n",
      "score1: 0.5672559044331196\n",
      "score2: 0.16492093070482725\n",
      "score1: 0.5672559044331196\n",
      "score2: 0.41512912947784353\n",
      "score1: 0.5672559044331196\n",
      "score2: 0.4306918877438496\n",
      "score1: 0.5672559044331196\n",
      "score2: 0.16323237089465603\n",
      "score1: 0.5672559044331196\n",
      "score2: 0.32527425928528536\n",
      "score1: 0.5672559044331196\n",
      "score2: 0.5636865319029628\n",
      "score1: 0.5672559044331196\n",
      "score2: 0.3311619074114553\n",
      "score1: 0.5672559044331196\n",
      "score2: 0.4837605660738191\n",
      "score1: 0.5672559044331196\n",
      "score2: 0.3375011056990861\n",
      "score1: 0.5672559044331196\n",
      "score2: 0.3143425472641871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jacob\\AppData\\Local\\Temp/ipykernel_17184/519229823.py:83: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  randomForest_Base = randomForest.fit(data_train.drop([\"5\"], axis=1), data_train.drop(data_train_AIS.columns[0:-1],axis=1))\n",
      "c:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score GradientBoosting: \n",
      "0.7352941176470589\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score GradientBoosting AIS: \n",
      "0.9019607843137255\n",
      "\n",
      "Best score KNeighbors: \n",
      "0.7598039215686274\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score KNeighbors AIS: \n",
      "0.8872549019607844\n",
      "\n",
      "Best score Logistic Regression: \n",
      "0.5024509803921569\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score Logistic Regression AIS: \n",
      "0.696078431372549\n",
      "\n",
      "Best score RandomForest: \n",
      "0.7352941176470589\n",
      "\n",
      "Best score RandomForest AIS: \n",
      "0.9215686274509804\n",
      "\n",
      "score1: 0.40469181269181276\n",
      "score2: 0.45600238856677827\n",
      "score1: 0.45600238856677827\n",
      "score2: 0.4233725596197722\n",
      "score1: 0.45600238856677827\n",
      "score2: 0.5723478696741855\n",
      "score1: 0.5723478696741855\n",
      "score2: 0.4494260071876567\n",
      "score1: 0.5723478696741855\n",
      "score2: 0.567683891941551\n",
      "score1: 0.5723478696741855\n",
      "score2: 0.6551541038004899\n",
      "score1: 0.6551541038004899\n",
      "score2: 0.4705375872112715\n",
      "score1: 0.6551541038004899\n",
      "score2: 0.2843388485916656\n",
      "score1: 0.6551541038004899\n",
      "score2: 0.546369476565555\n",
      "score1: 0.6551541038004899\n",
      "score2: 0.35289435240490097\n",
      "score1: 0.6551541038004899\n",
      "score2: 0.40010089974579516\n",
      "score1: 0.6551541038004899\n",
      "score2: 0.2735383824415843\n",
      "score1: 0.6551541038004899\n",
      "score2: 0.39434809440871127\n",
      "score1: 0.6551541038004899\n",
      "score2: 0.37416573487589044\n",
      "score1: 0.6551541038004899\n",
      "score2: 0.45025557038349673\n",
      "score1: 0.6551541038004899\n",
      "score2: 0.4194604722754557\n",
      "score1: 0.6551541038004899\n",
      "score2: 0.2992507841217287\n",
      "score1: 0.6551541038004899\n",
      "score2: 0.6566385863215133\n",
      "score1: 0.6566385863215133\n",
      "score2: 0.3529928486525459\n",
      "score1: 0.6566385863215133\n",
      "score2: 0.26308536975203645\n",
      "score1: 0.6566385863215133\n",
      "score2: 0.518852540260991\n",
      "score1: 0.6566385863215133\n",
      "score2: 0.4414093780103433\n",
      "score1: 0.6566385863215133\n",
      "score2: 0.2650395850395851\n",
      "score1: 0.6566385863215133\n",
      "score2: 0.32547930539234887\n",
      "score1: 0.6566385863215133\n",
      "score2: 0.3674112577406078\n",
      "score1: 0.6566385863215133\n",
      "score2: 0.3106190751816837\n",
      "score1: 0.6566385863215133\n",
      "score2: 0.47085143085143083\n",
      "score1: 0.6566385863215133\n",
      "score2: 0.343071834608883\n",
      "score1: 0.6566385863215133\n",
      "score2: 0.4097176567227601\n",
      "score1: 0.6566385863215133\n",
      "score2: 0.3897190861547958\n",
      "score1: 0.6566385863215133\n",
      "score2: 0.4750274039685805\n",
      "score1: 0.6566385863215133\n",
      "score2: 0.6383479530925871\n",
      "score1: 0.6566385863215133\n",
      "score2: 0.68399333999334\n",
      "score1: 0.68399333999334\n",
      "score2: 0.43374290256643205\n",
      "score1: 0.68399333999334\n",
      "score2: 0.6882921001214892\n",
      "score1: 0.6882921001214892\n",
      "score2: 0.42716561843170775\n",
      "score1: 0.6882921001214892\n",
      "score2: 0.4542754861885297\n",
      "score1: 0.6882921001214892\n",
      "score2: 0.5513039364391477\n",
      "score1: 0.6882921001214892\n",
      "score2: 0.5066079813905902\n",
      "score1: 0.6882921001214892\n",
      "score2: 0.432286171968238\n",
      "score1: 0.6882921001214892\n",
      "score2: 0.3818009441538854\n",
      "score1: 0.6882921001214892\n",
      "score2: 0.41449002166723686\n",
      "score1: 0.6882921001214892\n",
      "score2: 0.48177284729000974\n",
      "score1: 0.6882921001214892\n",
      "score2: 0.38336713692811253\n",
      "score1: 0.6882921001214892\n",
      "score2: 0.3442916321458161\n",
      "score1: 0.6882921001214892\n",
      "score2: 0.6178748955402781\n",
      "score1: 0.6882921001214892\n",
      "score2: 0.4916432489234183\n",
      "score1: 0.6882921001214892\n",
      "score2: 0.296634260735257\n",
      "score1: 0.6882921001214892\n",
      "score2: 0.31208140496229325\n",
      "score1: 0.6882921001214892\n",
      "score2: 0.43549168371247343\n",
      "score1: 0.6882921001214892\n",
      "score2: 0.46034669913636456\n",
      "score1: 0.6882921001214892\n",
      "score2: 0.4208222779170148\n",
      "score1: 0.6882921001214892\n",
      "score2: 0.3566109830252532\n",
      "score1: 0.6882921001214892\n",
      "score2: 0.4233268722164162\n",
      "score1: 0.6882921001214892\n",
      "score2: 0.3885601082050604\n",
      "score1: 0.6882921001214892\n",
      "score2: 0.48970823219966936\n",
      "score1: 0.6882921001214892\n",
      "score2: 0.29613345423818804\n",
      "score1: 0.6882921001214892\n",
      "score2: 0.35608625201386834\n",
      "score1: 0.6882921001214892\n",
      "score2: 0.6061315902835742\n",
      "score1: 0.6882921001214892\n",
      "score2: 0.4575405927405927\n",
      "score1: 0.6882921001214892\n",
      "score2: 0.5540737322758954\n",
      "score1: 0.6882921001214892\n",
      "score2: 0.5747711866743884\n",
      "score1: 0.6882921001214892\n",
      "score2: 0.25142097339280445\n",
      "score1: 0.6882921001214892\n",
      "score2: 0.3295907647907648\n",
      "score1: 0.6882921001214892\n",
      "score2: 0.5881711052285608\n",
      "score1: 0.6882921001214892\n",
      "score2: 0.4216248196248197\n",
      "score1: 0.6882921001214892\n",
      "score2: 0.5473870526883655\n",
      "score1: 0.6882921001214892\n",
      "score2: 0.3820949853402257\n",
      "score1: 0.6882921001214892\n",
      "score2: 0.549835575874535\n",
      "score1: 0.6882921001214892\n",
      "score2: 0.4094740419021578\n",
      "score1: 0.6882921001214892\n",
      "score2: 0.3053305573853519\n",
      "score1: 0.6882921001214892\n",
      "score2: 0.35031962724964827\n",
      "score1: 0.6882921001214892\n",
      "score2: 0.5366701414743112\n",
      "score1: 0.6882921001214892\n",
      "score2: 0.2932665273579049\n",
      "score1: 0.6882921001214892\n",
      "score2: 0.3798353095705208\n",
      "score1: 0.6882921001214892\n",
      "score2: 0.2939518103180441\n",
      "score1: 0.6882921001214892\n",
      "score2: 0.49251462731434037\n",
      "score1: 0.6882921001214892\n",
      "score2: 0.42019297549214196\n",
      "score1: 0.6882921001214892\n",
      "score2: 0.44383866837387964\n",
      "score1: 0.6882921001214892\n",
      "score2: 0.5260048593381927\n",
      "score1: 0.6882921001214892\n",
      "score2: 0.5860587954563858\n",
      "score1: 0.6882921001214892\n",
      "score2: 0.47501968894730534\n",
      "score1: 0.6882921001214892\n",
      "score2: 0.4317353017353017\n",
      "score1: 0.6882921001214892\n",
      "score2: 0.5046122494789161\n",
      "score1: 0.6882921001214892\n",
      "score2: 0.28211405862841493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\jacob\\AppData\\Local\\Temp/ipykernel_17184/519229823.py:83: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  randomForest_Base = randomForest.fit(data_train.drop([\"5\"], axis=1), data_train.drop(data_train_AIS.columns[0:-1],axis=1))\n",
      "c:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\sklearn\\neighbors\\_classification.py:198: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n",
      "c:\\Users\\jacob\\anaconda3\\envs\\csi4106\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score GradientBoosting: \n",
      "0.7135416666666666\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score GradientBoosting AIS: \n",
      "0.8463541666666667\n",
      "\n",
      "Best score KNeighbors: \n",
      "0.7473958333333334\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score KNeighbors AIS: \n",
      "0.8385416666666667\n",
      "\n",
      "Best score Logistic Regression: \n",
      "0.6510416666666666\n",
      "\n",
      "_____________________________________________\n",
      "\n",
      "Best score Logistic Regression AIS: \n",
      "0.6875\n",
      "\n",
      "Best score RandomForest: \n",
      "0.7161458333333335\n",
      "\n",
      "Best score RandomForest AIS: \n",
      "0.8958333333333335\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "dataAIS = []\n",
    "dataSMOTE = []\n",
    "dataBase = []\n",
    "data = []\n",
    "fold = 0\n",
    "\n",
    "for result in kf.split(df):\n",
    "    fold = fold+1\n",
    "    #Print the shape of the train and test set\n",
    "    data_train = df.iloc[result[0]]\n",
    "    data_test =  df.iloc[result[1]]\n",
    "    #print(f\"Train Data shape: \\n{data_train}\\n\")\n",
    "    #print(f\"Test Data shape: \\n{data_test}\\n\")\n",
    "\n",
    "\n",
    "    data_train_AIS = data_train.copy()\n",
    "    data_train_SMOTE = data_train.copy()\n",
    "\n",
    "    #Create an oversampling object\n",
    "    \n",
    "    oversample = SMOTE()\n",
    "    \n",
    "\n",
    "\n",
    "    oversample_AIS = ArtificialImmuneSystem()\n",
    "    #Oversample and add to the dataframe to fix the class imbalance\n",
    "    randomForest = RandomForestClassifier()\n",
    "    logisticRegression = LogisticRegression()\n",
    "    kNeighbors = KNeighborsClassifier()\n",
    "    gradientBoosting = GradientBoostingClassifier()\n",
    "\n",
    "    st = time.time()\n",
    "    x_over, y_over = oversample.fit_resample(data_train_SMOTE.drop([\"5\"], axis=1), data_train_SMOTE.drop(data_train_SMOTE.columns[0:-1],axis=1))\n",
    "    elapsed_time_SMOTE = time.time() - st\n",
    "\n",
    "    st = time.time()\n",
    "    input_x_over_AIS, y_over_AIS = oversample_AIS.AIS_Resample(data_train_AIS.drop([\"5\"], axis=1), data_train_AIS.drop(data_train_AIS.columns[0:-1],axis=1),max_rounds = 200, stopping_cond = 50, model = kNeighbors,K_folds = 5,scorer = 'f1',min_change = 0.001, use_lof = False)\n",
    "    elapsed_time_AIS = time.time() - st\n",
    "\n",
    "    smote_df = pd.concat([x_over, y_over], axis=1)\n",
    "    ais_df = pd.concat([input_x_over_AIS, y_over_AIS], axis=1)\n",
    "\n",
    "    # print the dimensionality of the oversampled dataset\n",
    "    #print(f\"SMOTE Oversampled Data shape: \\n{smote_df.shape}\\n\")\n",
    "    #print(f\"SMOTE Oversampled Data size: \\n{smote_df.size}\\n\")\n",
    "    #print(f\"SMOTE Oversampled Data ndim: \\n{smote_df.ndim}\\n\")\n",
    "    #print(\"_____________________________________________\\n\")\n",
    "\n",
    "    # print the dimensionality of the oversampled dataset\n",
    "    #print(f\"AIS Oversampled Data shape: \\n{ais_df.shape}\\n\")\n",
    "    #print(f\"AIS Oversampled Data size: \\n{ais_df.size}\\n\")\n",
    "    #print(f\"AIS Oversampled Data ndim: \\n{ais_df.ndim}\\n\")\n",
    "    #print(\"_____________________________________________\\n\")\n",
    "\n",
    "\n",
    "    # print the new class distribution using a Counter\n",
    "    #print(f\"New SMOTE Class Distribution: {Counter(smote_df['5'])}\")\n",
    "    #print(f\"New AIS Class Distribution: {Counter(ais_df['5'])}\")\n",
    "    ## print the new class distribution using a Counter\n",
    "    #print(f\"Old Class Distribution: {Counter(data_train['5'])}\")\n",
    "\n",
    "    #print(\"_____________________________________________\\n\")\n",
    "\n",
    "    #labelTrainFlat = labels_train.values.ravel()\n",
    "\n",
    "    #Fit one vs rest Gradient Boosting classification\n",
    "    gradientBoosting = GradientBoostingClassifier()\n",
    "    gradientBoosting = gradientBoosting.fit(x_over, y_over.values.ravel())\n",
    "\n",
    "    gradientBoosting_AIS = GradientBoostingClassifier()\n",
    "    gradientBoosting_AIS = gradientBoosting.fit(input_x_over_AIS, y_over_AIS.values.ravel())\n",
    "\n",
    "    gradientBoosting_Base = gradientBoosting.fit(data_train.drop([\"5\"], axis=1), data_train.drop(data_train_AIS.columns[0:-1],axis=1))\n",
    "\n",
    "    #Fit RandomForestClassifier classification\n",
    "    randomForest = RandomForestClassifier()\n",
    "    randomForest = randomForest.fit(x_over,y_over.values.ravel())\n",
    "\n",
    "    randomForest = RandomForestClassifier()\n",
    "    randomForest_AIS  = randomForest.fit(input_x_over_AIS,y_over_AIS.values.ravel())\n",
    "\n",
    "    randomForest_Base = randomForest.fit(data_train.drop([\"5\"], axis=1), data_train.drop(data_train_AIS.columns[0:-1],axis=1))\n",
    "    #randomForest_Base  = randomForest.fit(data_train.drop([\"5\"], axis=1), data_train.drop(data_train_AIS.columns[0:-1]).values.ravel())\n",
    "\n",
    "    #Create a KNeighbors classification object\n",
    "    kNeighbors = KNeighborsClassifier()\n",
    "    kNeighbors = kNeighbors.fit(x_over,y_over.values.ravel())\n",
    "\n",
    "    kNeighbors = KNeighborsClassifier()\n",
    "    kNeighbors_AIS  = kNeighbors.fit(input_x_over_AIS,y_over_AIS.values.ravel())\n",
    "    kNeighbors_Base = kNeighbors.fit(data_train.drop([\"5\"], axis=1), data_train.drop(data_train_AIS.columns[0:-1],axis=1))\n",
    "    #kNeighbors_base  = kNeighbors.fit(data_train.drop([\"5\"], axis=1), data_train.drop(data_train_AIS.columns[0:-1]).values.ravel())\n",
    "\n",
    "    #Create an LogisticRegression object\n",
    "    logisticRegression = LogisticRegression(max_iter=5000)\n",
    "    logisticRegression = logisticRegression.fit(x_over,y_over.values.ravel())\n",
    "\n",
    "    logisticRegression = LogisticRegression(max_iter=5000)\n",
    "    logisticRegression_AIS  = logisticRegression.fit(input_x_over_AIS,y_over_AIS.values.ravel())\n",
    "    logisticRegression_Base = logisticRegression.fit(data_train.drop([\"5\"], axis=1), data_train.drop(data_train_AIS.columns[0:-1],axis=1))\n",
    "    #logisticRegression_Base  = logisticRegression.fit(data_train.drop([\"5\"], axis=1), data_train.drop(data_train_AIS.columns[0:-1]).values.ravel())\n",
    "\n",
    "    #Set the parameters of GradientBoosting for GridSearchCV\n",
    "    parametersGradientBoosting = [\n",
    "        {'learning_rate': [0.44,0.45,0.46],'min_samples_leaf': [5,6,7],'min_samples_split': [7,8,9,10], 'n_estimators': [57,58,59,60]}\n",
    "    ]\n",
    "\n",
    "    #Set the scoring parameters\n",
    "    scoringX = {\"roc_auc\": \"roc_auc\", \"bal_accuracy\": \"balanced_accuracy\"}\n",
    "\n",
    "    #Preform Gridsearch to find best parameters\n",
    "    grid_searchGradientBoosting = GridSearchCV(gradientBoosting, parametersGradientBoosting, cv=4, scoring = scoringX, return_train_score=True, n_jobs=-1, refit='bal_accuracy')\n",
    "    grid_searchGradientBoosting_AIS = GridSearchCV(gradientBoosting_AIS, parametersGradientBoosting, cv=4, scoring = scoringX, return_train_score=True, n_jobs=-1, refit='bal_accuracy')\n",
    "    #grid_searchGradientBoosting_Base = GridSearchCV(gradientBoosting_Base, parametersGradientBoosting, cv=4, scoring = scoringX, return_train_score=True, n_jobs=-1, refit='bal_accuracy')\n",
    "    #Fit the GradientBoosting \n",
    "    grid_searchGradientBoosting.fit(x_over, y_over.values.ravel())\n",
    "    grid_searchGradientBoosting_AIS.fit(input_x_over_AIS,y_over_AIS.values.ravel())\n",
    "  \n",
    "    \n",
    "\n",
    "    #Print GridSearchCV Results\n",
    "    \n",
    "    print(f\"Best score GradientBoosting: \\n{grid_searchGradientBoosting.best_score_}\\n\")\n",
    "    print(\"_____________________________________________\\n\")\n",
    "    \n",
    "    print(f\"Best score GradientBoosting AIS: \\n{grid_searchGradientBoosting_AIS.best_score_}\\n\")\n",
    "\n",
    "    #Set the parameters of KNeighbors for GridSearchCV\n",
    "    parametersKNeighbors = [\n",
    "        {'n_neighbors': [1,2,3],'weights':['uniform', 'distance'],'algorithm':['auto'], 'p': [1,2,3]}\n",
    "    ]\n",
    "\n",
    "    #Set the scoring parameters\n",
    "    scoringX = {\"roc_auc\": \"roc_auc\", \"bal_accuracy\": \"balanced_accuracy\"}\n",
    "\n",
    "    #Preform KNeighbors to find best parameters\n",
    "    grid_searchKNeighbors = GridSearchCV(kNeighbors, parametersKNeighbors, cv=4, scoring = scoringX, return_train_score=True, n_jobs=-1, refit='bal_accuracy')\n",
    "    grid_searchKNeighbors_AIS = GridSearchCV(kNeighbors_AIS, parametersKNeighbors, cv=4, scoring = scoringX, return_train_score=True, n_jobs=-1, refit='bal_accuracy')\n",
    "\n",
    "    #Fit the KNeighbors \n",
    "    grid_searchKNeighbors.fit(x_over, y_over.values.ravel())\n",
    "    grid_searchKNeighbors_AIS.fit(input_x_over_AIS,y_over_AIS.values.ravel())\n",
    "\n",
    "    #Print GridSearchCV Results\n",
    "   \n",
    "    print(f\"Best score KNeighbors: \\n{grid_searchKNeighbors.best_score_}\\n\")\n",
    "    print(\"_____________________________________________\\n\")\n",
    "   \n",
    "    print(f\"Best score KNeighbors AIS: \\n{grid_searchKNeighbors_AIS.best_score_}\\n\")\n",
    "    \n",
    "    #Set the parameters of LogisticRegression for GridSearchCV\n",
    "    parametersLogisticRegression = [\n",
    "        {'multi_class': ['ovr'],'penalty':['none','l2'], 'C': [1,2,3]}\n",
    "    ]\n",
    "    scoringX = {\"roc_auc\": \"roc_auc\", \"bal_accuracy\": \"balanced_accuracy\"}\n",
    "\n",
    "    #Preform LogisticRegression to find best parameters\n",
    "    grid_searchLogisticRegression = GridSearchCV(logisticRegression, parametersLogisticRegression, cv=4, scoring = scoringX, return_train_score=True, n_jobs=-1, refit='bal_accuracy')\n",
    "    grid_searchLogisticRegression_AIS = GridSearchCV(logisticRegression_AIS, parametersLogisticRegression, cv=4, scoring = scoringX, return_train_score=True, n_jobs=-1, refit='bal_accuracy')\n",
    "\n",
    "    #Fit the LogisticRegression \n",
    "    grid_searchLogisticRegression.fit(x_over, y_over.values.ravel())\n",
    "    grid_searchLogisticRegression_AIS.fit(input_x_over_AIS,y_over_AIS.values.ravel())\n",
    "\n",
    "    #Print LogisticRegression Results\n",
    "    \n",
    "    print(f\"Best score Logistic Regression: \\n{grid_searchLogisticRegression.best_score_}\\n\")\n",
    "    print(\"_____________________________________________\\n\")\n",
    "   \n",
    "    print(f\"Best score Logistic Regression AIS: \\n{grid_searchLogisticRegression_AIS.best_score_}\\n\")\n",
    "\n",
    "    #Set the parameters of RandomForest for GridSearchCV\n",
    "    parametersRandomForest = [\n",
    "        {'n_estimators': [145,150,155,190],'max_depth': [10,12], 'bootstrap': [True, False],\n",
    "        'min_samples_split': [0.05,2], 'max_features': ['auto']}\n",
    "    ]\n",
    "\n",
    "    #Preform Gridsearch to find best parameters\n",
    "    grid_searchRandomForest = GridSearchCV(randomForest, parametersRandomForest, cv=4, scoring = scoringX, return_train_score=True, n_jobs=-1, refit='bal_accuracy')\n",
    "    grid_searchRandomForest_AIS = GridSearchCV(randomForest_AIS, parametersRandomForest, cv=4, scoring = scoringX, return_train_score=True, n_jobs=-1, refit='bal_accuracy')\n",
    "\n",
    "    #Fit the RandomForest \n",
    "    grid_searchRandomForest.fit(x_over, y_over.values.ravel())\n",
    "    grid_searchRandomForest_AIS.fit(input_x_over_AIS,y_over_AIS.values.ravel())\n",
    "\n",
    "    #Print GridSearchCV Results\n",
    "\n",
    "    print(f\"Best score RandomForest: \\n{grid_searchRandomForest.best_score_}\\n\")\n",
    "\n",
    "    print(f\"Best score RandomForest AIS: \\n{grid_searchRandomForest_AIS.best_score_}\\n\")\n",
    "\n",
    "    #Get the results for all classifiers \n",
    "    cross_val_resultsGB = grid_searchGradientBoosting.cv_results_\n",
    "    cross_val_resultsRF = grid_searchRandomForest.cv_results_\n",
    "    cross_val_resultsLR = grid_searchLogisticRegression.cv_results_\n",
    "    cross_val_resultsKN = grid_searchKNeighbors.cv_results_\n",
    "\n",
    "    cross_val_resultsGB_AIS = grid_searchGradientBoosting_AIS.cv_results_\n",
    "    cross_val_resultsRF_AIS = grid_searchRandomForest_AIS.cv_results_\n",
    "    cross_val_resultsLR_AIS = grid_searchLogisticRegression_AIS.cv_results_\n",
    "    cross_val_resultsKN_AIS = grid_searchKNeighbors_AIS.cv_results_\n",
    "\n",
    "\n",
    "    #Print the results of all classiifiers\n",
    "    #GBC\n",
    "    mean_test_roc_aucGB = mean(cross_val_resultsGB['mean_test_roc_auc'])\n",
    "    mean_test_bal_accuracyGB = mean(cross_val_resultsGB['mean_test_bal_accuracy'])\n",
    "    \n",
    "    mean_test_roc_aucGB_AIS = mean(cross_val_resultsGB_AIS['mean_test_roc_auc'])\n",
    "    mean_test_bal_accuracyGB_AIS = mean(cross_val_resultsGB_AIS['mean_test_bal_accuracy'])\n",
    "   \n",
    "    #RFC\n",
    "    mean_test_roc_aucRF = mean(cross_val_resultsRF['mean_test_roc_auc'])\n",
    "    mean_test_bal_accuracyRF = mean(cross_val_resultsRF['mean_test_bal_accuracy'])\n",
    "    \n",
    "    mean_test_roc_aucRF_AIS = mean(cross_val_resultsRF_AIS['mean_test_roc_auc'])\n",
    "    mean_test_bal_accuracyRF_AIS = mean(cross_val_resultsRF_AIS['mean_test_bal_accuracy'])\n",
    "    #LRC\n",
    "    mean_test_roc_aucLR = mean(cross_val_resultsLR['mean_test_roc_auc'])\n",
    "    mean_test_bal_accuracyLR = mean(cross_val_resultsLR['mean_test_bal_accuracy'])\n",
    "    \n",
    "    mean_test_roc_aucLR_AIS = mean(cross_val_resultsLR_AIS['mean_test_roc_auc'])\n",
    "    mean_test_bal_accuracyLR_AIS = mean(cross_val_resultsLR_AIS['mean_test_bal_accuracy'])\n",
    "\n",
    "    #KNC\n",
    "    mean_test_roc_aucKN = mean(cross_val_resultsKN['mean_test_roc_auc'])\n",
    "    mean_test_bal_accuracyKN = mean(cross_val_resultsKN['mean_test_bal_accuracy'])\n",
    "    \n",
    "    mean_test_roc_aucKN_AIS = mean(cross_val_resultsKN_AIS['mean_test_roc_auc'])\n",
    "    mean_test_bal_accuracyKN_AIS = mean(cross_val_resultsKN_AIS['mean_test_bal_accuracy'])\n",
    "\n",
    "    predictions_test_over_GB = grid_searchGradientBoosting.best_estimator_.predict(data_test.drop([\"5\"],axis=1))\n",
    "    predictions_test_over_RF = grid_searchRandomForest.best_estimator_.predict(data_test.drop([\"5\"],axis=1))\n",
    "    predictions_test_over_LR = grid_searchLogisticRegression.best_estimator_.predict(data_test.drop([\"5\"],axis=1))\n",
    "    predictions_test_over_KN = grid_searchKNeighbors.best_estimator_.predict(data_test.drop([\"5\"],axis=1))\n",
    "\n",
    "    predictions_test_over_GB_AIS = grid_searchGradientBoosting_AIS.best_estimator_.predict(data_test.drop([\"5\"],axis=1))\n",
    "    predictions_test_over_RF_AIS = grid_searchRandomForest_AIS.best_estimator_.predict(data_test.drop([\"5\"],axis=1))\n",
    "    predictions_test_over_LR_AIS = grid_searchLogisticRegression_AIS.best_estimator_.predict(data_test.drop([\"5\"],axis=1))\n",
    "    predictions_test_over_KN_AIS = grid_searchKNeighbors_AIS.best_estimator_.predict(data_test.drop([\"5\"],axis=1))\n",
    "\n",
    "    predictions_GB = gradientBoosting_Base.predict(data_test.drop([\"5\"],axis=1))\n",
    "    predictions_RF = randomForest_Base.predict(data_test.drop([\"5\"],axis=1))\n",
    "    predictions_LR = logisticRegression_Base.predict(data_test.drop([\"5\"],axis=1))\n",
    "    predictions_KN = kNeighbors_Base.predict(data_test.drop([\"5\"],axis=1))\n",
    "\n",
    "    f1_score_GB = f1_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_GB)\n",
    "    f1_score_RF = f1_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_RF)\n",
    "    f1_score_LR = f1_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_LR)\n",
    "    f1_score_KN = f1_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_KN)\n",
    "\n",
    "    f1_score_GB_AIS = f1_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_GB_AIS) \n",
    "    f1_score_RF_AIS = f1_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_RF_AIS)\n",
    "    f1_score_LR_AIS = f1_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_LR_AIS)\n",
    "    f1_score_KN_AIS = f1_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_KN_AIS)\n",
    "\n",
    "    f1_score_GB_Base = f1_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_GB)\n",
    "    f1_score_RF_Base = f1_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_RF)\n",
    "    f1_score_LR_Base = f1_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_LR)\n",
    "    f1_score_KN_Base = f1_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_KN)\n",
    "\n",
    "    geometric_mean_score_GB = geometric_mean_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_GB, labels=None, pos_label=1, average='binary',)\n",
    "    geometric_mean_score_RF = geometric_mean_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_RF, labels=None, pos_label=1, average='binary',)\n",
    "    geometric_mean_score_LR = geometric_mean_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_LR, labels=None, pos_label=1, average='binary',)\n",
    "    geometric_mean_score_KN = geometric_mean_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_KN, labels=None, pos_label=1, average='binary',)\n",
    "\n",
    "    geometric_mean_score_GB_AIS = geometric_mean_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_GB_AIS, labels=None, pos_label=1, average='binary',)\n",
    "    geometric_mean_score_RF_AIS = geometric_mean_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_RF_AIS, labels=None, pos_label=1, average='binary',)\n",
    "    geometric_mean_score_LR_AIS = geometric_mean_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_LR_AIS, labels=None, pos_label=1, average='binary',)\n",
    "    geometric_mean_score_KN_AIS = geometric_mean_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_KN_AIS, labels=None, pos_label=1, average='binary',)\n",
    "\n",
    "    geometric_mean_score_GB_Base = geometric_mean_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_GB, labels=None, pos_label=1, average='binary',)\n",
    "    geometric_mean_score_RF_Base = geometric_mean_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_RF, labels=None, pos_label=1, average='binary',)\n",
    "    geometric_mean_score_LR_Base = geometric_mean_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_LR, labels=None, pos_label=1, average='binary',)\n",
    "    geometric_mean_score_KN_Base = geometric_mean_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_KN, labels=None, pos_label=1, average='binary',)\n",
    "\n",
    "    \n",
    "    roc_auc_GB_AIS = roc_auc_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_GB_AIS)\n",
    "    roc_auc_RF_AIS = roc_auc_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_RF_AIS)\n",
    "    roc_auc_LR_AIS = roc_auc_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_LR_AIS)\n",
    "    roc_auc_KN_AIS = roc_auc_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_KN_AIS)\n",
    " \n",
    "    roc_auc_GB_Base = roc_auc_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_GB)\n",
    "    roc_auc_RF_Base = roc_auc_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_RF)\n",
    "    roc_auc_LR_Base = roc_auc_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_LR)\n",
    "    roc_auc_KN_Base = roc_auc_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_KN)\n",
    "\n",
    "    roc_auc_GB = roc_auc_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_GB)\n",
    "    roc_auc_RF = roc_auc_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_RF)\n",
    "    roc_auc_LR = roc_auc_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_LR)\n",
    "    roc_auc_KN = roc_auc_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_KN)\n",
    "\n",
    "    \n",
    "\n",
    "    balanced_acc_GB_AIS = balanced_accuracy_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_GB_AIS)\n",
    "    balanced_acc_RF_AIS = balanced_accuracy_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_RF_AIS)\n",
    "    balanced_acc_LR_AIS = balanced_accuracy_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_LR_AIS)\n",
    "    balanced_acc_KN_AIS = balanced_accuracy_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_KN_AIS)\n",
    " \n",
    "    balanced_acc_GB = balanced_accuracy_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_GB)\n",
    "    balanced_acc_RF = balanced_accuracy_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_RF)\n",
    "    balanced_acc_LR = balanced_accuracy_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_LR)\n",
    "    balanced_acc_KN = balanced_accuracy_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_test_over_KN)\n",
    "\n",
    "    \n",
    "    balanced_acc_GB_Base = balanced_accuracy_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_GB)\n",
    "    balanced_acc_RF_Base = balanced_accuracy_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_RF)\n",
    "    balanced_acc_LR_Base = balanced_accuracy_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_LR)\n",
    "    balanced_acc_KN_Base = balanced_accuracy_score(data_test.drop(data_test.columns[0:-1],axis=1), predictions_KN)\n",
    "\n",
    "    \n",
    "    dataAIS.append( [fold,dataset,\"AIS\", elapsed_time_AIS,\"max_rounds = 200, stopping_cond = 50, model = kNeighbors,K_folds = 5,scorer = 'f1',min_change = 0.001, use_lof = False, This is testing Niks changes in fitness\", roc_auc_GB_AIS, roc_auc_RF_AIS, roc_auc_LR_AIS, roc_auc_KN_AIS, balanced_acc_GB_AIS, balanced_acc_RF_AIS,  balanced_acc_LR_AIS,  balanced_acc_KN_AIS, geometric_mean_score_GB_AIS, geometric_mean_score_RF_AIS, geometric_mean_score_LR_AIS, geometric_mean_score_KN_AIS,f1_score_GB_AIS,f1_score_RF_AIS,f1_score_LR_AIS,f1_score_KN_AIS ])\n",
    "    dataSMOTE.append([fold,dataset,\"SMOTE\", elapsed_time_SMOTE,\"NA\", roc_auc_GB,  roc_auc_RF, roc_auc_LR,roc_auc_KN, balanced_acc_GB, balanced_acc_RF,  balanced_acc_LR,  balanced_acc_KN, geometric_mean_score_GB, geometric_mean_score_RF, geometric_mean_score_LR, geometric_mean_score_KN,f1_score_GB,f1_score_RF,f1_score_LR,f1_score_KN])\n",
    "    dataBase.append([fold,dataset,\"BASE\", \"NA\",\"NA\", roc_auc_GB_Base, roc_auc_RF_Base, roc_auc_LR_Base, roc_auc_KN_Base, balanced_acc_GB_Base, balanced_acc_RF_Base,balanced_acc_LR_Base,  balanced_acc_KN_Base, geometric_mean_score_GB_Base, geometric_mean_score_RF_Base, geometric_mean_score_LR_Base, geometric_mean_score_KN_Base,f1_score_GB_Base,f1_score_RF_Base,f1_score_LR_Base,f1_score_KN_Base])\n",
    "    data.append(dataAIS[fold-1])\n",
    "    data.append(dataSMOTE[fold-1])\n",
    "    data.append(dataBase[fold-1])\n",
    "    data.append([\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"])\n",
    "\n",
    "average_AIS_Runtime = 0\n",
    "\n",
    "average_roc_auc_GB_AIS = 0\n",
    "average_roc_auc_RF_AIS = 0\n",
    "average_roc_auc_LR_AIS = 0\n",
    "average_roc_auc_KN_AIS = 0\n",
    "\n",
    "average_balanced_acc_GB_AIS = 0\n",
    "average_balanced_acc_RF_AIS = 0\n",
    "average_balanced_acc_LR_AIS = 0\n",
    "average_balanced_acc_KN_AIS = 0\n",
    "\n",
    "average_geometric_mean_score_GB_AIS = 0\n",
    "average_geometric_mean_score_RF_AIS = 0\n",
    "average_geometric_mean_score_LR_AIS = 0\n",
    "average_geometric_mean_score_KN_AIS = 0\n",
    "    \n",
    "average_f1_score_GB_AIS = 0\n",
    "average_f1_score_RF_AIS = 0\n",
    "average_f1_score_LR_AIS = 0\n",
    "average_f1_score_KN_AIS = 0\n",
    "\n",
    "\n",
    "average_SMOTE_Runtime = 0\n",
    "\n",
    "average_roc_auc_GB = 0\n",
    "average_roc_auc_RF = 0\n",
    "average_roc_auc_LR = 0\n",
    "average_roc_auc_KN = 0\n",
    "\n",
    "average_balanced_acc_GB = 0\n",
    "average_balanced_acc_RF = 0\n",
    "average_balanced_acc_LR = 0\n",
    "average_balanced_acc_KN = 0\n",
    "\n",
    "average_geometric_mean_score_GB = 0\n",
    "average_geometric_mean_score_RF = 0\n",
    "average_geometric_mean_score_LR = 0\n",
    "average_geometric_mean_score_KN = 0\n",
    "    \n",
    "average_f1_score_GB = 0\n",
    "average_f1_score_RF = 0\n",
    "average_f1_score_LR = 0\n",
    "average_f1_score_KN = 0\n",
    "\n",
    "average_roc_auc_GB_Base = 0\n",
    "average_roc_auc_RF_Base = 0\n",
    "average_roc_auc_LR_Base = 0\n",
    "average_roc_auc_KN_Base = 0\n",
    "\n",
    "average_balanced_acc_GB_Base = 0\n",
    "average_balanced_acc_RF_Base = 0\n",
    "average_balanced_acc_LR_Base = 0\n",
    "average_balanced_acc_KN_Base = 0\n",
    "\n",
    "average_geometric_mean_score_GB_Base = 0\n",
    "average_geometric_mean_score_RF_Base = 0\n",
    "average_geometric_mean_score_LR_Base = 0\n",
    "average_geometric_mean_score_KN_Base = 0\n",
    "    \n",
    "average_f1_score_GB_Base = 0\n",
    "average_f1_score_RF_Base = 0\n",
    "average_f1_score_LR_Base = 0\n",
    "average_f1_score_KN_Base = 0\n",
    "\n",
    "for array in dataAIS:\n",
    "\n",
    "    average_AIS_Runtime = average_AIS_Runtime + array[3]\n",
    "\n",
    "    average_roc_auc_GB_AIS = average_roc_auc_GB_AIS + array[5]\n",
    "    average_roc_auc_RF_AIS = average_roc_auc_RF_AIS + array[6]\n",
    "    average_roc_auc_LR_AIS = average_roc_auc_LR_AIS + array[7]\n",
    "    average_roc_auc_KN_AIS = average_roc_auc_KN_AIS + array[8]\n",
    "\n",
    "    average_balanced_acc_GB_AIS = average_balanced_acc_GB_AIS + array[9]\n",
    "    average_balanced_acc_RF_AIS = average_balanced_acc_RF_AIS + array[10]\n",
    "    average_balanced_acc_LR_AIS = average_balanced_acc_LR_AIS + array[11]\n",
    "    average_balanced_acc_KN_AIS = average_balanced_acc_KN_AIS + array[12]\n",
    "\n",
    "    average_geometric_mean_score_GB_AIS = average_geometric_mean_score_GB_AIS + array[13]\n",
    "    average_geometric_mean_score_RF_AIS = average_geometric_mean_score_RF_AIS + array[14]\n",
    "    average_geometric_mean_score_LR_AIS = average_geometric_mean_score_LR_AIS + array[15]\n",
    "    average_geometric_mean_score_KN_AIS = average_geometric_mean_score_KN_AIS + array[16]\n",
    "    \n",
    "    average_f1_score_GB_AIS = average_f1_score_GB_AIS + array[17]\n",
    "    average_f1_score_RF_AIS = average_f1_score_RF_AIS + array[18]\n",
    "    average_f1_score_LR_AIS = average_f1_score_LR_AIS + array[19]\n",
    "    average_f1_score_KN_AIS = average_f1_score_KN_AIS + array[20]\n",
    "\n",
    "for array in dataSMOTE:\n",
    "\n",
    "    average_SMOTE_Runtime = average_SMOTE_Runtime + array[3]\n",
    "\n",
    "    average_roc_auc_GB = average_roc_auc_GB + array[5]\n",
    "    average_roc_auc_RF = average_roc_auc_RF + array[6]\n",
    "    average_roc_auc_LR = average_roc_auc_LR + array[7]\n",
    "    average_roc_auc_KN = average_roc_auc_KN + array[8]\n",
    "\n",
    "    average_balanced_acc_GB = average_balanced_acc_GB + array[9]\n",
    "    average_balanced_acc_RF = average_balanced_acc_RF + array[10]\n",
    "    average_balanced_acc_LR = average_balanced_acc_LR + array[11]\n",
    "    average_balanced_acc_KN = average_balanced_acc_KN + array[12]\n",
    "\n",
    "    average_geometric_mean_score_GB = average_geometric_mean_score_GB + array[13]\n",
    "    average_geometric_mean_score_RF = average_geometric_mean_score_RF + array[14]\n",
    "    average_geometric_mean_score_LR = average_geometric_mean_score_LR + array[15]\n",
    "    average_geometric_mean_score_KN = average_geometric_mean_score_KN + array[16]\n",
    "    \n",
    "    average_f1_score_GB = average_f1_score_GB + array[17]\n",
    "    average_f1_score_RF = average_f1_score_RF + array[18]\n",
    "    average_f1_score_LR = average_f1_score_LR + array[19]\n",
    "    average_f1_score_KN = average_f1_score_KN + array[20]\n",
    "\n",
    "for array in dataBase:\n",
    "\n",
    "    average_roc_auc_GB_Base = average_roc_auc_GB_Base + array[5]\n",
    "    average_roc_auc_RF_Base = average_roc_auc_RF_Base + array[6]\n",
    "    average_roc_auc_LR_Base = average_roc_auc_LR_Base + array[7]\n",
    "    average_roc_auc_KN_Base = average_roc_auc_KN_Base + array[8]\n",
    "\n",
    "    average_balanced_acc_GB_Base = average_balanced_acc_GB_Base + array[9]\n",
    "    average_balanced_acc_RF_Base = average_balanced_acc_RF_Base + array[10]\n",
    "    average_balanced_acc_LR_Base = average_balanced_acc_LR_Base + array[11]\n",
    "    average_balanced_acc_KN_Base = average_balanced_acc_KN_Base + array[12]\n",
    "\n",
    "    average_geometric_mean_score_GB_Base = average_geometric_mean_score_GB_Base + array[13]\n",
    "    average_geometric_mean_score_RF_Base = average_geometric_mean_score_RF_Base + array[14]\n",
    "    average_geometric_mean_score_LR_Base = average_geometric_mean_score_LR_Base + array[15]\n",
    "    average_geometric_mean_score_KN_Base = average_geometric_mean_score_KN_Base + array[16]\n",
    "    \n",
    "    average_f1_score_GB_Base = average_f1_score_GB_Base + array[17]\n",
    "    average_f1_score_RF_Base = average_f1_score_RF_Base + array[18]\n",
    "    average_f1_score_LR_Base = average_f1_score_LR_Base + array[19]\n",
    "    average_f1_score_KN_Base = average_f1_score_KN_Base + array[20]\n",
    "\n",
    "average_f1_score_GB = average_f1_score_GB / fold\n",
    "average_f1_score_RF = average_f1_score_RF / fold\n",
    "average_f1_score_LR = average_f1_score_LR / fold\n",
    "average_f1_score_KN= average_f1_score_KN / fold\n",
    "\n",
    "average_f1_score_GB_AIS = average_f1_score_GB_AIS / fold\n",
    "average_f1_score_RF_AIS = average_f1_score_RF_AIS / fold\n",
    "average_f1_score_LR_AIS = average_f1_score_LR_AIS / fold\n",
    "average_f1_score_KN_AIS = average_f1_score_KN_AIS / fold\n",
    "\n",
    "average_f1_score_GB_Base = average_f1_score_GB_Base / fold\n",
    "average_f1_score_RF_Base = average_f1_score_RF_Base / fold\n",
    "average_f1_score_LR_Base = average_f1_score_LR_Base / fold\n",
    "average_f1_score_KN_Base= average_f1_score_KN_Base / fold\n",
    "\n",
    "average_geometric_mean_score_GB = average_geometric_mean_score_GB / fold\n",
    "average_geometric_mean_score_RF= average_geometric_mean_score_RF / fold\n",
    "average_geometric_mean_score_LR= average_geometric_mean_score_LR / fold\n",
    "average_geometric_mean_score_KN = average_geometric_mean_score_KN / fold\n",
    "\n",
    "average_geometric_mean_score_GB_AIS= average_geometric_mean_score_GB_AIS / fold\n",
    "average_geometric_mean_score_RF_AIS= average_geometric_mean_score_RF_AIS / fold\n",
    "average_geometric_mean_score_LR_AIS = average_geometric_mean_score_LR_AIS / fold\n",
    "average_geometric_mean_score_KN_AIS = average_geometric_mean_score_KN_AIS / fold\n",
    "\n",
    "average_geometric_mean_score_GB_Base = average_geometric_mean_score_GB_Base / fold\n",
    "average_geometric_mean_score_RF_Base= average_geometric_mean_score_RF_Base / fold\n",
    "average_geometric_mean_score_LR_Base= average_geometric_mean_score_LR_Base / fold\n",
    "average_geometric_mean_score_KN_Base= average_geometric_mean_score_KN_Base / fold\n",
    "\n",
    "    \n",
    "average_roc_auc_GB_AIS= average_roc_auc_GB_AIS / fold\n",
    "average_roc_auc_RF_AIS= average_roc_auc_RF_AIS / fold\n",
    "average_roc_auc_LR_AIS= average_roc_auc_LR_AIS / fold\n",
    "average_roc_auc_KN_AIS= average_roc_auc_KN_AIS / fold\n",
    " \n",
    "average_roc_auc_GB_Base = average_roc_auc_GB_Base / fold\n",
    "average_roc_auc_RF_Base= average_roc_auc_RF_Base / fold\n",
    "average_roc_auc_LR_Base= average_roc_auc_LR_Base / fold\n",
    "average_roc_auc_KN_Base= average_roc_auc_KN_Base / fold\n",
    "\n",
    "average_roc_auc_GB= average_roc_auc_GB / fold\n",
    "average_roc_auc_RF= average_roc_auc_RF / fold\n",
    "average_roc_auc_LR= average_roc_auc_LR / fold\n",
    "average_roc_auc_KN= average_roc_auc_KN / fold\n",
    "\n",
    "    \n",
    "\n",
    "average_balanced_acc_GB_AIS= average_balanced_acc_GB_AIS / fold\n",
    "average_balanced_acc_RF_AIS= average_balanced_acc_RF_AIS / fold\n",
    "average_balanced_acc_LR_AIS= average_balanced_acc_LR_AIS / fold\n",
    "average_balanced_acc_KN_AIS= average_balanced_acc_KN_AIS / fold\n",
    " \n",
    "average_balanced_acc_GB= average_balanced_acc_GB / fold\n",
    "average_balanced_acc_RF= average_balanced_acc_RF / fold\n",
    "average_balanced_acc_LR= average_balanced_acc_LR / fold\n",
    "average_balanced_acc_KN= average_balanced_acc_KN / fold\n",
    "\n",
    "    \n",
    "average_balanced_acc_GB_Base= average_balanced_acc_GB_Base / fold\n",
    "average_balanced_acc_RF_Base= average_balanced_acc_RF_Base / fold\n",
    "average_balanced_acc_LR_Base= average_balanced_acc_LR_Base / fold\n",
    "average_balanced_acc_KN_Base= average_balanced_acc_KN_Base / fold\n",
    "\n",
    "\n",
    "\n",
    "data.append( [\"\",\"\",\"AIS\", \"\",\"AVERAGE:\", average_roc_auc_GB_AIS, average_roc_auc_RF_AIS, average_roc_auc_LR_AIS, average_roc_auc_KN_AIS, average_balanced_acc_GB_AIS, average_balanced_acc_RF_AIS,  average_balanced_acc_LR_AIS,  average_balanced_acc_KN_AIS, average_geometric_mean_score_GB_AIS, average_geometric_mean_score_RF_AIS, average_geometric_mean_score_LR_AIS, average_geometric_mean_score_KN_AIS,average_f1_score_GB_AIS,average_f1_score_RF_AIS,average_f1_score_LR_AIS,average_f1_score_KN_AIS ])\n",
    "data.append([\"\",\"\",\"SMOTE\", \"\",\"AVERAGE:\", average_roc_auc_GB,  average_roc_auc_RF, average_roc_auc_LR,average_roc_auc_KN, average_balanced_acc_GB, average_balanced_acc_RF,  average_balanced_acc_LR,  average_balanced_acc_KN, average_geometric_mean_score_GB, average_geometric_mean_score_RF, average_geometric_mean_score_LR, average_geometric_mean_score_KN,average_f1_score_GB,average_f1_score_RF,average_f1_score_LR,average_f1_score_KN])\n",
    "data.append([\"\",\"\",\"BASE\", \"\",\"AVERAGE:\", average_roc_auc_GB_Base, average_roc_auc_RF_Base, average_roc_auc_LR_Base, average_roc_auc_KN_Base, average_balanced_acc_GB_Base, average_balanced_acc_RF_Base,balanced_acc_LR_Base,  average_balanced_acc_KN_Base, average_geometric_mean_score_GB_Base, average_geometric_mean_score_RF_Base, average_geometric_mean_score_LR_Base, average_geometric_mean_score_KN_Base,average_f1_score_GB_Base,average_f1_score_RF_Base,average_f1_score_LR_Base,average_f1_score_KN_Base])\n",
    "data.append([\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "col_names = [\"Fold\", \"Dataset\",\"Oversample\",\"Oversample Run Time\", \"Oversample Paramaters\", \"ROC AUC for Gradient Boosting\",  \"ROC AUC for Random Forests\", \"ROC AUC for Logistic Regression\",  \"ROC AUC for K Nearest Neighbours\", \"Balanced Accuracy for Gradient Boosting\", \"Balanced Accuracy for Random Forests\" ,\"Balanced Accuracy for Logistic Regression\",\"Balanced Accuracy for K Nearest Neighbours\", \"Geometric Mean Score for Gradient Boosting\", \"Geometric Mean Score for Random Forest\", \"Geometric Mean Score for Logestic Regression\", \"Geometric Mean Score for K Neighbors\", \"F1 Score for Gradient Boosting\", \"F1 Score for Random Forest\", \"F1 Score for Logestic Regression\", \"F1 Score for K Neighbors\"]\n",
    "dfoutput=pd.DataFrame(data,columns=col_names)\n",
    "title = \"ExperimentalResults/ExperimentalComparisons-TestingOverlapingData.csv\"\n",
    "dfoutput.to_csv(title, mode='a',index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aisOversample = ArtificialImmuneSystem()\n",
    "#minority_class = df[df['5'] == 1]\n",
    "#majority_class = df[df['5'] == 0]\n",
    "\n",
    "#requiredPopulation = len(majority_class)-len(minority_class)\n",
    "#population = aisOversample.AIS(minority_class, max_rounds=100, totalPopulation=requiredPopulation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting Labels\n",
    "#Get a list of all columns\n",
    "#columns = data_train.columns.to_list()\n",
    "#Remove the label and save it\n",
    "#columns_drop = columns.pop(-1)\n",
    "\n",
    "#Remove all labels except for the label in the train and test dataframe\n",
    "#labels_train = data_train.drop(columns, axis=1)\n",
    "#labels_test = data_test.drop(columns, axis=1)\n",
    "\n",
    "#Print the labesl of the test and train\n",
    "#print(f\"labels_train: \\n{labels_train}\\n\")\n",
    "#print(f\"labels_test: \\n{labels_test}\\n\")\n",
    "\n",
    "#Remove the label from the train and test dataframe\n",
    "#features_train = data_train.drop(['5'], axis=1)\n",
    "#features_test = data_test.drop(['5'], axis=1)\n",
    "\n",
    "#Print the features of the train and test dataset\n",
    "#print(f\"features_train: \\n{features_train }\\n\")\n",
    "#print(f\"lfeatures_test: \\n{features_test }\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('csi4106')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12 (default, Oct 12 2021, 03:01:40) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "51ea9996f2a91c7d112e626959c304b606e4bf2254e73fec145d965796b2ca69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
