{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd;\n",
    "import random;\n",
    "from statistics import fmean, stdev;\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import DistanceMetric\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "from itertools import combinations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OBJECTS/VARIABLES:\n",
    "\n",
    "Antibody - list of Numerical values (Reals?) , represented by a row of a dataframe?\n",
    "Population - List[Antibodies], represented by the total dataframe?\n",
    "\n",
    "Target Size (i.e number of antibodies to be created) = (Size of Majority Class) - (Size of minority class)\n",
    "\n",
    "\n",
    "\n",
    "FUNCTIONS:\n",
    "\n",
    "Initializing :- input: original dataframe\n",
    "\n",
    "                         do: Get bounds of minority class by taking the highest and lowest values in each of the [n] dimensions\n",
    "\n",
    "                         How: Do we take the whole minority class? or do we sample part or parts of it to generate our bounds. \n",
    "\n",
    "                         output: Upper and lower bounds of the minority class\n",
    "\n",
    "\n",
    "Creation :- Input: Bounds of the min class\n",
    "\n",
    "        do: Create a set of antibodies\n",
    "\n",
    "        input: minority Dataframe \n",
    "\n",
    "        How:\n",
    "            Possibilities:\n",
    "            (As the Malhanabois paper does it) Take a random value between the bounds of the minority class feature as the datapoint\n",
    "\n",
    "            (Nikhil Just sample minority class based on imbalance rate (doesn't require bounds)\n",
    "\n",
    "            (Adam) Take a random value, as in the paper's method, but off of a weighted curve? as in we could randomize, \n",
    "                but add some preference for values close to the boundary, or close to the center, etc.\n",
    "                        -We could set this as a parameter, bell curve, linear. This same function could be a parameter in the mutation stage.\n",
    "                        -If the density within the bounds is concentrated on one side, add bias towards that side in the random value;\n",
    "        \n",
    "        Challenges: \n",
    "            How do we deal with the different data categories (e.g nominal, ordinal, and continuous)? Continuous is easy, just a number in a range. Ordinal is ???, nominal is difficult, even if one-hot encoded, we might random to have two values that should be exclusive (e.g an item being both blue and red). How do other imputation algorithms work with these problems? DO they even work with these problems?\n",
    "        output: Initial Population as a DF?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4.539317</td>\n",
       "      <td>5.021729</td>\n",
       "      <td>-7.042357</td>\n",
       "      <td>-7.428090</td>\n",
       "      <td>4.943687</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.300671</td>\n",
       "      <td>6.131065</td>\n",
       "      <td>-6.394796</td>\n",
       "      <td>-5.981102</td>\n",
       "      <td>4.579452</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-5.004336</td>\n",
       "      <td>4.473384</td>\n",
       "      <td>-6.048647</td>\n",
       "      <td>-5.556982</td>\n",
       "      <td>4.051438</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.732848</td>\n",
       "      <td>7.791876</td>\n",
       "      <td>-7.495527</td>\n",
       "      <td>-6.541127</td>\n",
       "      <td>3.910933</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-4.193859</td>\n",
       "      <td>5.393440</td>\n",
       "      <td>-5.317542</td>\n",
       "      <td>-5.605152</td>\n",
       "      <td>4.807354</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>5.349610</td>\n",
       "      <td>4.226061</td>\n",
       "      <td>-4.841005</td>\n",
       "      <td>-6.342083</td>\n",
       "      <td>4.820905</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>-5.247255</td>\n",
       "      <td>5.149173</td>\n",
       "      <td>-6.669314</td>\n",
       "      <td>-5.848687</td>\n",
       "      <td>3.793496</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>3.308685</td>\n",
       "      <td>5.513754</td>\n",
       "      <td>-3.805559</td>\n",
       "      <td>-5.564981</td>\n",
       "      <td>4.670373</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>-4.510472</td>\n",
       "      <td>4.712267</td>\n",
       "      <td>-4.550419</td>\n",
       "      <td>-3.915542</td>\n",
       "      <td>4.798225</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>-4.630100</td>\n",
       "      <td>4.954438</td>\n",
       "      <td>-4.243112</td>\n",
       "      <td>-3.235496</td>\n",
       "      <td>4.634826</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4    5\n",
       "0   -4.539317  5.021729 -7.042357 -7.428090  4.943687  0.0\n",
       "1    4.300671  6.131065 -6.394796 -5.981102  4.579452  1.0\n",
       "2   -5.004336  4.473384 -6.048647 -5.556982  4.051438  0.0\n",
       "3    2.732848  7.791876 -7.495527 -6.541127  3.910933  1.0\n",
       "4   -4.193859  5.393440 -5.317542 -5.605152  4.807354  0.0\n",
       "..        ...       ...       ...       ...       ...  ...\n",
       "295  5.349610  4.226061 -4.841005 -6.342083  4.820905  1.0\n",
       "296 -5.247255  5.149173 -6.669314 -5.848687  3.793496  0.0\n",
       "297  3.308685  5.513754 -3.805559 -5.564981  4.670373  1.0\n",
       "298 -4.510472  4.712267 -4.550419 -3.915542  4.798225  0.0\n",
       "299 -4.630100  4.954438 -4.243112 -3.235496  4.634826  0.0\n",
       "\n",
       "[300 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(\"./Data/GeneratedSyntheticData-NosielessInformativeEasy.csv\")\n",
    "\n",
    "columns = df.columns.to_list()\n",
    "columns_drop = columns.pop(-1)\n",
    "\n",
    "#drop NaN rows, could implement imputer as well\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "labels = df.drop(columns, axis=1)\n",
    "\n",
    "#df= df.drop(\"5\", axis=1)\n",
    "#df= df.drop(\"Unnamed: 0\", axis=1)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO Gaussian generation can be optimized by altering how the loops work, putting the col loop on the outside and pre-generated fmean, stdev for the col\n",
    "        #Currently it generates those values for every antibody\n",
    "        \n",
    "\n",
    "def get_bounds(minorityDF) -> dict:\n",
    "    out = {}\n",
    "    for col in minorityDF:\n",
    "        colMax = minorityDF[col].max()\n",
    "        colMin = minorityDF[col].min()\n",
    "        out[col] = (colMin, colMax)\n",
    "    return out\n",
    "\n",
    "#This only works for continuous values. We will have to code a version for binary fields (We assume any categorical columns have been encoded)\n",
    "\n",
    "####### Creation ################\n",
    "# minorityDF - dataframe containing the minority class\n",
    "# totalPopulation - The total number of antibodies to create\n",
    "# weightingFunction - Can choose between uniform, triangular, ...\n",
    "# mode - for use with a triangular function - set to the percentage of the range you wish to be most represented (between 0.0 and 1.0)\n",
    "def Creation(minorityDF, totalPopulation : int, binaryColumns : list, weightingFunction : str = \"uniform\", mode : float = 0.5): \n",
    "    \n",
    "    if(minorityDF.isnull().values.any()):\n",
    "        raise ValueError(\"Minority Class DataFrame contains NaN\")\n",
    "    \n",
    "    population = [] #Initializing the empty population\n",
    "    if mode < 0.0 or mode > 1:\n",
    "        raise Exception(\"mode must be between float value between 0.0 and 1.0\")\n",
    "    \n",
    "    if weightingFunction not in ('uniform', 'triangular', 'gaussian'):\n",
    "        raise Exception(\"Unknown function chosen, please use one of 'uniform', 'triangular', or 'gaussian'\")\n",
    "\n",
    "    bounds = get_bounds(minorityDF)\n",
    "    \n",
    "    if weightingFunction in [\"uniform\", \"triangular\"]: #If Generating via uniform or triangular distribution, loop through bounds of columns\n",
    "        for i in range(totalPopulation): #For every antibody to be created\n",
    "\n",
    "            antibody = [] #Initializing a single antibody\n",
    "            for key,bnd in bounds.items(): #Iterate through the columns/dimensions/features of the minority class for each antibody \n",
    "                if key in binaryColumns:\n",
    "                    antibody += [random.randint(int(bnd[0]),int(bnd[1]))]\n",
    "                else:\n",
    "                    if weightingFunction == \"uniform\":\n",
    "                        antibody += [round(random.uniform(bnd[0],bnd[1]),4)] #Add a random value between the lower and upper bounds to the antibody\n",
    "\n",
    "                    elif (weightingFunction == \"triangular\"):\n",
    "                        \n",
    "                        tri_tip = ( ((bnd[1]-bnd[0]) * mode) + bnd[0] ) #multiplying the difference by the percentage, plus the low bound gives us the point between the two, but percentile\n",
    "\n",
    "                        if tri_tip < bnd[0]: #Error checks to make sure that the emphasized point isn't outside the bounds\n",
    "                            tri_tip = bnd[0]\n",
    "                        elif tri_tip > bnd[1]:\n",
    "                            tri_tip = bnd[1]\n",
    "\n",
    "                        antibody += [round( random.triangular(bnd[0],bnd[1], tri_tip), 5)]\n",
    "\n",
    "            population+=[antibody] #add the created antibody to the population\n",
    "\n",
    "    elif (weightingFunction == 'gaussian'): #If Generating via Gaussian, loop through columns of dataframe\n",
    "\n",
    "        for i in range(totalPopulation): #For every antibody to be created\n",
    "\n",
    "            antibody = [] #Initializing a single antibody\n",
    "            for bnd in minorityDF: #Iterate over columns in the dataframe\n",
    "                values = minorityDF[bnd].tolist() #convert series to list\n",
    "                if bnd in binaryColumns:\n",
    "                    antibody += [random.randint(bounds[bnd][0],bounds[bnd][1])]\n",
    "                else:\n",
    "                    antibody += [round(random.gauss(fmean(values) , stdev(values)), 5)] #using median and stdeviation of values, radomize over gauss\n",
    "\n",
    "        \n",
    "            population+=[antibody] #add the created antibody to the population\n",
    "\n",
    "            \n",
    "    popDF = pd.DataFrame(population, columns = minorityDF.columns.values)\n",
    "    return popDF, bounds\n",
    "    \n",
    "\n",
    "#Creation(df,1000,['5'], weightingFunction='gaussian')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function For Experiments with bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fitness Function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requirements: Needs to be calced fast bc of multiple iterations\n",
    "Posiibilities: - Binary Classification F1 Score, Mahalanobis Distance?\n",
    "               - Other Types as well? : Linear Regression, Multiilabel Classification\n",
    "\n",
    "Do we just impute our values and then do something similar to StudentPerformance and see what happens? No bc we need input from the fitness function to do our generations.\n",
    "\n",
    "Is the data just our training set?\n",
    "Inputs: Model(initialized outside function or inside?) fit with data that has been encoded and the label\n",
    "\n",
    "Want to do kfold cv (not every loop bc very slow, once afterwards to evaluate)\n",
    "\n",
    "when we do k fold, call fitness funciton k times i.e. once for every train test split.\n",
    "\n",
    "if doing grid search, do it before calling this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates the fitness score for one train/test split dataset\n",
    "# run on original dataset without random values first to be abe to compare\n",
    "\n",
    "def fitness( model, feat, label, iterations, scorer):\n",
    "    #scorer is the name of the function wee aree using to evaluate our dataset\n",
    "    #it should be a function with signature scorer(model, feature, label) which should return only a single value.\n",
    "    return cross_val_score(model, feat, label, cv = iterations, scoring = scorer)\n",
    "\n",
    "def distance( x, y, metric):\n",
    "    \n",
    "    #get the distance between two sets of data x and y, they should be the same size\n",
    "    #metric is the string metric to be used to measure distance\n",
    "\n",
    "    dist = DistanceMetric.get_metric(metric)\n",
    "    return dist.pairwise(x,y)\n",
    "    \n",
    "#Original features, original labels are the original df before any oversampling\n",
    "#Population_features, population_labels are the generated population we want to evaluate\n",
    "#Here scorer has to be a function that takes y_pred, y_true and returns a score, not implemented yet\n",
    "def fitnessBasic(model, original_features, original_labels, population_features, population_labels, scorer):\n",
    "\n",
    "    #train test split makes train set smaller, we should sample the population based on he difference of the majority class and minority class in origin_feat_train\n",
    "    origin_feat_train, origin_feat_test, origin_labels_train, origin_labels_test = train_test_split(original_features, original_labels, test_size=0.33)\n",
    "    \n",
    "    train_features = pd.concat([origin_feat_train, population_features],ignore_index=True)\n",
    "    train_labels = pd.concat([origin_labels_train, population_labels],ignore_index=True)\n",
    "\n",
    "    model.fit(train_features, train_labels.values.ravel())\n",
    "    predictions = model.predict(origin_feat_test)\n",
    "\n",
    "    #need more params?\n",
    "    #hard coded f1_score, find a way to pass in function for scoring?\n",
    "    score = f1_score(origin_labels_test.values.ravel(), predictions)\n",
    "    return score\n",
    "\n",
    "#Original features, original labels are the original df before any oversampling\n",
    "#Population_features, population_labels are the generated population we want to evaluate\n",
    "#Here scorer has to be a function that takes y_pred, y_true and returns a score, not implemented yet\n",
    "def fitnessCV(model, original_features, original_labels, population_features, population_labels, scorer, iterations):\n",
    "    #TODO: train_features or train_labels had 1 extra row, need to fix\n",
    "    #train test split makes train set smaller, we should sample the population based on he difference of the majority class and minority class in origin_feat_train\n",
    "    origin_feat_train, origin_feat_test, origin_labels_train, origin_labels_test = train_test_split(original_features, original_labels, test_size=0.33)\n",
    "    \n",
    "    train_features = pd.concat([origin_feat_train, population_features],ignore_index=True)\n",
    "    train_labels = pd.concat([origin_labels_train, population_labels],ignore_index=True)\n",
    "\n",
    "    #look into group parameter of cross_validate\n",
    "    #here scoring can be multiple values\n",
    "    \n",
    "    cval_scores = cross_validate(model, train_features, train_labels.values.ravel(), scoring = scorer, cv = iterations, return_train_score = True, return_estimator = True)\n",
    "\n",
    "    #look at format of scores, get estimators and use them to predict test\n",
    "\n",
    "    test_scores = []\n",
    "    cval_test_scores =cval_scores['test_score']\n",
    "    count = 0 \n",
    "    for estimator in cval_scores['estimator']:\n",
    "        \n",
    "        estimator.fit(train_features, train_labels.values.ravel())\n",
    "        predictions = estimator.predict(origin_feat_test)\n",
    "\n",
    "        #hard coded f1_score, find a way to pass in function for scoring?\n",
    "        score = f1_score(origin_labels_test, predictions) \n",
    "\n",
    "        #here I just took the mean of the 2 scores, could we use something else?\n",
    "        mean_score = (score + cval_test_scores[count])/2\n",
    "        count+=1\n",
    "        test_scores.append(mean_score)\n",
    "    \n",
    "    #here I just took the mean of the array of all scores, could we use something else?\n",
    "    return fmean(test_scores)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mutation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Mutation ################\n",
    "def mutatePopulation (antiPopulation, bounds, binaryColumns : list, mutationRate : float = 1.0):\n",
    "    #antiPopulation is the population of antibodies to be mutated\n",
    "    #bounds is a dictionary of the bounds of each column in the population\n",
    "    #binaryColumns is a list of the columns that are binary\n",
    "    #mutationRate denotes how much the antibodies can mutate each round, 1.0 is the default, 0.0 is no mutation, 2.0 is double mutation rate\n",
    "    #returns a new mutated population of antibodies\n",
    "    antiPopulation = antiPopulation.copy()\n",
    "    for col in antiPopulation:\n",
    "        if bounds[col][0] == bounds[col][1]:\n",
    "            continue\n",
    "        elif col in binaryColumns: #Binary Columns must be handled differently than continuous\n",
    "            \n",
    "            antiPopulation[col] = antiPopulation[col].map(lambda x : (random.randint(0,1)))\n",
    "        else:\n",
    "            bnd_range = (bounds[col][1] - bounds[col][0])*mutationRate #total range of bounds is high - low\n",
    "\n",
    "            #Setting the low and high bounds to be centered around 0\n",
    "            hi_bnd = bnd_range/2 \n",
    "            low_bnd = (0-bnd_range/2)\n",
    "\n",
    "            #print(\"Low bound around 0 = \" + str(low_bnd) +\"| Hi bnd around 0 = \"+ str(hi_bnd))\n",
    "            #print(round(random.uniform(low_bnd,hi_bnd),4))\n",
    "\n",
    "            antiPopulation[col] = antiPopulation[col].map(lambda x : x+round(random.uniform(low_bnd,hi_bnd),4))\n",
    "        \n",
    "    return antiPopulation\n",
    "\n",
    "#First round: Compare the base dataset, to the dataset+the created/mutated points\n",
    "#\n",
    "\n",
    "def comparePopulations(population1, population2, labels1, labels2, estimator, iterations, scorer):\n",
    "\n",
    "    score1 = fmean(fitness(estimator, population1, labels1.values.ravel(), iterations, scorer))\n",
    "    score2 = fmean(fitness(estimator, population2, labels2.values.ravel(), iterations, scorer))\n",
    "\n",
    "    if score1 > score2:\n",
    "        winning_population = population1\n",
    "        winning_labels = labels1\n",
    "    else:\n",
    "        winning_population = population2\n",
    "        winning_labels = labels2\n",
    "\n",
    "    for col in winning_labels:\n",
    "        winning_population = winning_population.join(winning_labels[col])\n",
    "\n",
    "    return winning_population\n",
    "\n",
    "def comparePopulations2(population1, population2, labels1, labels2, estimator, iterations, scorer):\n",
    "    score1 = fmean(fitness(estimator, population1, labels1.values.ravel(), iterations, scorer))\n",
    "    score2 = fmean(fitness(estimator, population2, labels2.values.ravel(), iterations, scorer))\n",
    "    \n",
    "    print(\"score1: \" +str(score1))\n",
    "    print(\"score2: \" +str(score2))\n",
    "\n",
    "    if abs(score1 - score2) < 0.005:\n",
    "        return False\n",
    "    elif (score1>score2):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "#takes in the previous population's score, will need to add variable in AIS to track this from previous round\n",
    "# original features and original labels are the original df split into features and labels\n",
    "# population features and population labels are the population df split into features and labels, this is the new population we mutated this round\n",
    "# estimator, iterations, scorer not changed from old compare populaitons\n",
    "def comparePopulationsCV(prev_score, original_features, original_labels, population_features, population_labels, estimator, iterations, scorer, min_change = 0.005):\n",
    "    score1 = prev_score\n",
    "    score2 = fitnessCV(estimator, original_features, original_labels, population_features, population_labels, scorer, iterations)\n",
    "    \n",
    "    # print(\"score1: \" +str(score1))\n",
    "    # print(\"score2: \" +str(score2))\n",
    "\n",
    "    #is 0.005 too big?\n",
    "    if abs(score1 - score2) < 0.005:\n",
    "        return False, score1\n",
    "    elif (score1>score2):\n",
    "        return False, score1\n",
    "    else:\n",
    "        return True, score2\n",
    "\n",
    "#need a comparePopulationsBasic for fitnessBasic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do we need this?\n",
    "create1 = Creation(df,10000,['5'], weightingFunction='uniform')\n",
    "create2 = Creation(df,10000,['5'], weightingFunction='uniform')\n",
    "\n",
    "pop1 = create1[0]\n",
    "pop2 = create2[0]\n",
    "bounds1 = create1[1]\n",
    "bounds2 = create2[1]\n",
    "columns1 = pop1.columns.to_list()\n",
    "columns1_drop = columns1.pop(-1)\n",
    "\n",
    "labels1 = pop1.drop(columns1, axis=1)\n",
    "pop1 = pop1.drop(columns1_drop, axis=1)\n",
    "\n",
    "columns2 = pop2.columns.to_list()\n",
    "columns2_drop = columns2.pop(-1)\n",
    "\n",
    "labels2 = pop2.drop(columns2, axis=1)\n",
    "pop2 = pop2.drop(columns2_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      5\n",
       "0     0\n",
       "1     1\n",
       "2     1\n",
       "3     1\n",
       "4     0\n",
       "...  ..\n",
       "9995  1\n",
       "9996  0\n",
       "9997  0\n",
       "9998  0\n",
       "9999  1\n",
       "\n",
       "[10000 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutatePopulation(labels1, bounds1, ['5'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4.539317</td>\n",
       "      <td>5.021729</td>\n",
       "      <td>-7.042357</td>\n",
       "      <td>-7.428090</td>\n",
       "      <td>4.943687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.300671</td>\n",
       "      <td>6.131065</td>\n",
       "      <td>-6.394796</td>\n",
       "      <td>-5.981102</td>\n",
       "      <td>4.579452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-5.004336</td>\n",
       "      <td>4.473384</td>\n",
       "      <td>-6.048647</td>\n",
       "      <td>-5.556982</td>\n",
       "      <td>4.051438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.732848</td>\n",
       "      <td>7.791876</td>\n",
       "      <td>-7.495527</td>\n",
       "      <td>-6.541127</td>\n",
       "      <td>3.910933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-4.193859</td>\n",
       "      <td>5.393440</td>\n",
       "      <td>-5.317542</td>\n",
       "      <td>-5.605152</td>\n",
       "      <td>4.807354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>5.349610</td>\n",
       "      <td>4.226061</td>\n",
       "      <td>-4.841005</td>\n",
       "      <td>-6.342083</td>\n",
       "      <td>4.820905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>-5.247255</td>\n",
       "      <td>5.149173</td>\n",
       "      <td>-6.669314</td>\n",
       "      <td>-5.848687</td>\n",
       "      <td>3.793496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>3.308685</td>\n",
       "      <td>5.513754</td>\n",
       "      <td>-3.805559</td>\n",
       "      <td>-5.564981</td>\n",
       "      <td>4.670373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>-4.510472</td>\n",
       "      <td>4.712267</td>\n",
       "      <td>-4.550419</td>\n",
       "      <td>-3.915542</td>\n",
       "      <td>4.798225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>-4.630100</td>\n",
       "      <td>4.954438</td>\n",
       "      <td>-4.243112</td>\n",
       "      <td>-3.235496</td>\n",
       "      <td>4.634826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4\n",
       "0   -4.539317  5.021729 -7.042357 -7.428090  4.943687\n",
       "1    4.300671  6.131065 -6.394796 -5.981102  4.579452\n",
       "2   -5.004336  4.473384 -6.048647 -5.556982  4.051438\n",
       "3    2.732848  7.791876 -7.495527 -6.541127  3.910933\n",
       "4   -4.193859  5.393440 -5.317542 -5.605152  4.807354\n",
       "..        ...       ...       ...       ...       ...\n",
       "295  5.349610  4.226061 -4.841005 -6.342083  4.820905\n",
       "296 -5.247255  5.149173 -6.669314 -5.848687  3.793496\n",
       "297  3.308685  5.513754 -3.805559 -5.564981  4.670373\n",
       "298 -4.510472  4.712267 -4.550419 -3.915542  4.798225\n",
       "299 -4.630100  4.954438 -4.243112 -3.235496  4.634826\n",
       "\n",
       "[300 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO : add parameter that defines which column is the label\n",
    "#separate a df into features and labels\n",
    "def separate_df(df, label_col):\n",
    "\n",
    "    columns = df.columns.to_list()\n",
    "    columns_drop = columns.pop(columns.index(label_col))\n",
    "    labels = df.drop(columns, axis=1)\n",
    "    features = df.drop(columns_drop, axis=1)\n",
    "\n",
    "    return features, labels\n",
    "\n",
    "joe = pd.read_csv(\"./Data/GeneratedSyntheticData-NosielessInformativeEasy.csv\")\n",
    "feat,labels = separate_df(joe, '5')\n",
    "feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBinaryColumns(df) -> list:\n",
    "        return list(df.columns[df.nunique() == 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractBinaryMinorityClass( preparedFeatures, labels) -> pd.DataFrame:\n",
    "        #preparedFeatures is the dataframe of features, labels is the dataframe of labels\n",
    "        #returns a dataframe of the minority class\n",
    "        #get counts of each class from labels\n",
    "        for col in labels:\n",
    "                counts = labels[col].value_counts()\n",
    "                #get the minority class\n",
    "                minorityLabel = counts.idxmin()\n",
    "\n",
    "        minorityClass = labels[labels == minorityLabel]\n",
    "        minorityClass = minorityClass.dropna()\n",
    "        minorityClass = minorityClass.index.values\n",
    "        minorityClass = preparedFeatures.loc[minorityClass]\n",
    "        minorityClass[labels.columns[0]]=minorityLabel\n",
    "        return minorityClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes a population, generates its LOF score, ranks the data by it and splits it into n_blocks groups of similar data\n",
    "def lof(original_df, population, n_neighbor:int = 20, n_blocks:int = 4):\n",
    "\n",
    "    size = len(original_df.index)\n",
    "\n",
    "    df = pd.concat([original_df,population],ignore_index=True)\n",
    "    lof = LocalOutlierFactor(n_neighbors = n_neighbor)\n",
    "    \n",
    "    y_pred = lof.fit_predict(df)\n",
    "    X_scores = lof.negative_outlier_factor_\n",
    "\n",
    "    df[\"lof\"]=X_scores\n",
    "    population_with_lof = population.copy()\n",
    "    population_with_lof[\"lof\"] = X_scores[size:]\n",
    "\n",
    "    population_with_lof = population_with_lof.sort_values(by = ['lof'], ignore_index=True)\n",
    "    population_with_lof = population_with_lof.drop(columns=['lof'])\n",
    "\n",
    "    sizeof_block = int(len(population_with_lof.index)/n_blocks)\n",
    "    i = 0 \n",
    "    j = int(0)\n",
    "    result = []\n",
    "    \n",
    "    while(i < n_blocks):\n",
    "        k = int(j+ sizeof_block)\n",
    "        p = population_with_lof.iloc[j:k]\n",
    "        result.append(p)\n",
    "        #result.append(population[j:k])\n",
    "        j+=sizeof_block\n",
    "        i+=1\n",
    "    \n",
    "\n",
    "    return result\n",
    "\n",
    "def get_best_population(df, original_features, original_labels, antibody_population, previous_result, label, model, K_folds, scorer):\n",
    "    \n",
    "    result = lof(df, antibody_population)\n",
    "    \n",
    "    \n",
    "    p1 = pd.concat([result[0],result[1],result[2],previous_result[3]],ignore_index=True)\n",
    "    p1_features, p1_labels = separate_df(p1, label_col=label)\n",
    "    p1_score = fitnessCV(model, original_features, original_labels, p1_features, p1_labels, scorer, K_folds)\n",
    "\n",
    "    p2 = pd.concat([result[0],previous_result[1],result[2],result[3]],ignore_index=True)\n",
    "    p2_features, p2_labels = separate_df(p2, label_col=label)\n",
    "    p2_score = fitnessCV(model, original_features, original_labels, p2_features, p2_labels, scorer, K_folds)\n",
    "\n",
    "    p3 = pd.concat([result[0],result[1],previous_result[2],result[3]],ignore_index=True)\n",
    "    p3_features, p3_labels = separate_df(p3, label_col=label)\n",
    "    p3_score = fitnessCV(model, original_features, original_labels, p3_features, p3_labels, scorer, K_folds)\n",
    "\n",
    "    p4 = pd.concat([previous_result[0],result[1],result[2],result[3]],ignore_index=True)\n",
    "    p4_features, p4_labels = separate_df(p4, label_col=label)\n",
    "    p4_score = fitnessCV(model, original_features, original_labels, p4_features, p4_labels, scorer, K_folds)\n",
    "\n",
    "    scores = [p1_score,p2_score,p3_score,p4_score]\n",
    "    max_score = max(scores)\n",
    "\n",
    "    if(max_score == p1_score):\n",
    "        return p1, p1_score\n",
    "        \n",
    "    if(max_score == p2_score):\n",
    "        return p2, p2_score\n",
    "\n",
    "    if(max_score == p3_score):\n",
    "        return p3, p3_score\n",
    "    \n",
    "    if(max_score == p4_score):\n",
    "        return p4, p4_score\n",
    "\n",
    "def comparePopulations_lof( population_score, old_score, min_change):\n",
    "    print(\"old_score: \" +str(old_score))\n",
    "    print(\"population_score: \" +str(population_score))\n",
    "    if abs(population_score - old_score) < min_change:\n",
    "        return False, old_score\n",
    "    elif (old_score > population_score):\n",
    "        return False, old_score\n",
    "    else:\n",
    "        return True, population_score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#minorityDF      - the minority dataframe\n",
    "#df              - the original dataframe\n",
    "#max_rounds      - the maximum number of rounds(loops) of AIS \n",
    "#stopping_cond   - the number of rounds without significant changes to accuracy before stopping the function\n",
    "#totalPopulation - the number of elements we want to add to the minority class\n",
    "#model           - the model to be used to evaluate the dataset during AIS\n",
    "#K-folds         - the number of segments for k-fold cross validation\n",
    "#scorer          - the scoring metric when evaluating the dataset\n",
    "\n",
    "def AIS(minorityDF,df, label, max_rounds, stopping_cond, totalPopulation, model, K_folds, scorer,  min_change = 0.05, use_lof : bool = True):\n",
    "\n",
    "        #add code to find binary columns for creation\n",
    "        binaryColumns = getBinaryColumns(minorityDF)\n",
    "\n",
    "        current_population, bounds = Creation(minorityDF,totalPopulation,binaryColumns, weightingFunction='uniform')\n",
    "        \n",
    "        antibody_population = mutatePopulation(current_population,bounds,binaryColumns)\n",
    "        \n",
    "        count = 0\n",
    "        no_change = 0\n",
    "\n",
    "        original_gen, original_labels = separate_df(df, label)\n",
    "        #created population split into features and labels\n",
    "        current_gen, current_labels = separate_df(current_population, label_col=label)\n",
    "\n",
    "        \n",
    "        current_score = fitnessCV(model, original_gen, original_labels, current_gen, current_labels, scorer, K_folds)\n",
    "\n",
    "        # #the next generation antibody population concatenated to the original dataframe\n",
    "        # next_df = pd.concat([df,antibody_population],ignore_index=True) #TODO:REMOVE\n",
    "        #next_df split into features and labels\n",
    "        next_gen, next_labels = separate_df(antibody_population, label_col=label)\n",
    "\n",
    "        if(use_lof==False):\n",
    "            while( (count < max_rounds) and (no_change < stopping_cond) ):\n",
    "                count+=1\n",
    "         \n",
    "                change_flg, score = comparePopulationsCV(current_score, original_gen, original_labels, next_gen, next_labels, model, K_folds, scorer, min_change)\n",
    "                if (change_flg):\n",
    "                    \n",
    "                    no_change = 0\n",
    "\n",
    "                    current_population = antibody_population.copy()\n",
    "\n",
    "                    #need to update bounds\n",
    "                    bounds = get_bounds(current_population)\n",
    "                    antibody_population = mutatePopulation(current_population,bounds,['5'])\n",
    "                    next_gen, next_labels = separate_df(antibody_population, label_col=label)\n",
    "                    \n",
    "                else:\n",
    "                 \n",
    "                    no_change+=1\n",
    "\n",
    "                    bounds = get_bounds(current_population)\n",
    "                    antibody_population = mutatePopulation(current_population,bounds,['5'])\n",
    "                    next_gen, next_labels = separate_df(antibody_population, label_col=label)\n",
    "                    \n",
    "                current_score = score #Score will only change if the new population is better than the old population\n",
    "        \n",
    "        else:\n",
    "            current_population_lof = lof(df, current_population)\n",
    "            while( (count < max_rounds) and (no_change < stopping_cond) ):\n",
    "\n",
    "                count+=1\n",
    "                \n",
    "                best_population, best_population_score = get_best_population(df, original_gen, original_labels, antibody_population, current_population_lof, label, model, K_folds, scorer)\n",
    "                \n",
    "                change_flg, score = comparePopulations_lof(best_population_score, current_score, min_change)\n",
    "                if (change_flg):\n",
    "\n",
    "                    no_change = 0\n",
    "\n",
    "                    current_population = best_population.copy()\n",
    "                    current_population_lof = lof(df, current_population)\n",
    "\n",
    "                    #need to update bounds\n",
    "                    bounds = get_bounds(current_population)\n",
    "                    antibody_population = mutatePopulation(current_population,bounds,['5'])\n",
    "                    \n",
    "                    \n",
    "                else:\n",
    "\n",
    "                    no_change+=1\n",
    "\n",
    "                    bounds = get_bounds(current_population)\n",
    "                    \n",
    "                    antibody_population = mutatePopulation(current_population,bounds,['5'])\n",
    "                    \n",
    "                current_score = score #Score will only change if the new population is better than the old population\n",
    "\n",
    "        return current_population, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AIS_Resample( preparedDF, labels, max_rounds, stopping_cond, model, K_folds, scorer):\n",
    "        #preparedDF is the dataframe of features, labels is the dataframe of labels\n",
    "        minorityDF = extractBinaryMinorityClass(preparedDF, labels)\n",
    "        \n",
    "        #PreparedDF + Labels = the overall Population\n",
    "        overallPopulation = pd.concat([preparedDF,labels],axis=1)\n",
    "        #The number of elements we want to add to the minority class\n",
    "        requiredPopulation = len(overallPopulation) - (len(minorityDF)*2)\n",
    "        \n",
    "        oversamples,_ = AIS(minorityDF,overallPopulation,labels.columns, max_rounds,stopping_cond,requiredPopulation,model,K_folds,scorer)\n",
    "        concatDF = pd.concat([overallPopulation,oversamples],ignore_index=True)\n",
    "        return (separate_df(concatDF, labels.columns[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old_score: 0.8706687866580755\n",
      "population_score: 0.877491266054345\n",
      "old_score: 0.8706687866580755\n",
      "population_score: 0.8832231192587635\n",
      "old_score: 0.8706687866580755\n",
      "population_score: 0.8694760080804285\n",
      "old_score: 0.8706687866580755\n",
      "population_score: 0.8823306071730219\n",
      "old_score: 0.8706687866580755\n",
      "population_score: 0.8844627216565139\n",
      "old_score: 0.8706687866580755\n",
      "population_score: 0.8703288631769308\n",
      "old_score: 0.8706687866580755\n",
      "population_score: 0.8742719687862461\n",
      "old_score: 0.8706687866580755\n",
      "population_score: 0.9044573153926487\n",
      "old_score: 0.8706687866580755\n",
      "population_score: 0.886414671518079\n",
      "old_score: 0.8706687866580755\n",
      "population_score: 0.8669301833335605\n"
     ]
    }
   ],
   "source": [
    "#TEST BLOCK \n",
    "\n",
    "#not imbalanced\n",
    "#df= pd.read_csv(\"./Data/GeneratedSyntheticData-NosiyEasy.csv\",index_col=0)\n",
    "\n",
    "#Gets a perfect score always\n",
    "#df= pd.read_csv(\"./Data/GeneratedSyntheticData-NosieLessInformativeEasy.csv\") \n",
    "\n",
    "#Gets a perfect score after a few iterations\n",
    "df = pd.read_csv(\"./Data/GeneratedSyntheticData-NosieLessInformativeHard.csv\",index_col=0)\n",
    "df.dropna()\n",
    "\n",
    "#not imbalanced\n",
    "#df = pd.read_csv(\"./Data/GeneratedSyntheticData-NosiyHard.csv\",index_col=0)\n",
    "\n",
    "minority = df[df['5']==1] \n",
    "majority = df[df['5']==0]\n",
    "\n",
    "data, labels = separate_df(df, '5')\n",
    "# initial_population, bounds = Creation(minority,120,['5'], weightingFunction='uniform')\n",
    "\n",
    "# antibody_population = mutatePopulation(initial_population,bounds,['5'],1.0)\n",
    "\n",
    "# current_df = pd.concat([df,initial_population],ignore_index=True)\n",
    "# current_gen, current_labels = separate_df(current_df, '5')\n",
    "\n",
    "\n",
    "# next_df = pd.concat([df,antibody_population],ignore_index=True)\n",
    "# next_gen, next_labels = separate_df(next_df, '5')\n",
    "\n",
    "randomForest = RandomForestClassifier()\n",
    "\n",
    "# AIS_Resample(data, labels, 20, 5, randomForest, 5, 'f1')\n",
    "\n",
    "x = AIS_Resample(data, labels, 20, 10, randomForest, 5, 'f1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing datasets with no oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "separate_df() missing 1 required positional argument: 'label_col'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jacob\\Documents\\GitHub\\Artificial-Immune-System-For-Class-Imbalance\\AIS.ipynb Cell 22\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jacob/Documents/GitHub/Artificial-Immune-System-For-Class-Imbalance/AIS.ipynb#X30sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m minority \u001b[39m=\u001b[39m df[df[\u001b[39m'\u001b[39m\u001b[39m5\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m==\u001b[39m\u001b[39m1\u001b[39m] \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jacob/Documents/GitHub/Artificial-Immune-System-For-Class-Imbalance/AIS.ipynb#X30sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m majority \u001b[39m=\u001b[39m df[df[\u001b[39m'\u001b[39m\u001b[39m5\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m==\u001b[39m\u001b[39m0\u001b[39m]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jacob/Documents/GitHub/Artificial-Immune-System-For-Class-Imbalance/AIS.ipynb#X30sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m joe, mama \u001b[39m=\u001b[39m separate_df(df)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jacob/Documents/GitHub/Artificial-Immune-System-For-Class-Imbalance/AIS.ipynb#X30sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m score1 \u001b[39m=\u001b[39m fitness(randomForest, joe, mama\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mravel(), \u001b[39m5\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mf1_macro\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jacob/Documents/GitHub/Artificial-Immune-System-For-Class-Imbalance/AIS.ipynb#X30sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m score1\n",
      "\u001b[1;31mTypeError\u001b[0m: separate_df() missing 1 required positional argument: 'label_col'"
     ]
    }
   ],
   "source": [
    "#df = pd.read_csv(\"./Data/GeneratedSyntheticData-NosiyHard.csv\",index_col=0)\n",
    "df= pd.read_csv(\"./Data/GeneratedSyntheticData-NosieLessInformativeHard.csv\") \n",
    "\n",
    "minority = df[df['5']==1] \n",
    "majority = df[df['5']==0]\n",
    "\n",
    "joe, mama = separate_df(df)\n",
    "score1 = fitness(randomForest, joe, mama.values.ravel(), 5, 'f1_macro')\n",
    "score1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing new fitness functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "separate_df() missing 1 required positional argument: 'label_col'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jacob\\Documents\\GitHub\\Artificial-Immune-System-For-Class-Imbalance\\AIS.ipynb Cell 24\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jacob/Documents/GitHub/Artificial-Immune-System-For-Class-Imbalance/AIS.ipynb#X32sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m initial_population, bounds \u001b[39m=\u001b[39m Creation(minority,\u001b[39m120\u001b[39m,[\u001b[39m'\u001b[39m\u001b[39m5\u001b[39m\u001b[39m'\u001b[39m], weightingFunction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39muniform\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jacob/Documents/GitHub/Artificial-Immune-System-For-Class-Imbalance/AIS.ipynb#X32sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m antibody_population \u001b[39m=\u001b[39m mutatePopulation(initial_population,bounds,[\u001b[39m'\u001b[39m\u001b[39m5\u001b[39m\u001b[39m'\u001b[39m],\u001b[39m1.0\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/jacob/Documents/GitHub/Artificial-Immune-System-For-Class-Imbalance/AIS.ipynb#X32sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m current_gen, current_labels \u001b[39m=\u001b[39m separate_df(initial_population)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jacob/Documents/GitHub/Artificial-Immune-System-For-Class-Imbalance/AIS.ipynb#X32sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m next_gen, next_labels \u001b[39m=\u001b[39m separate_df(antibody_population)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jacob/Documents/GitHub/Artificial-Immune-System-For-Class-Imbalance/AIS.ipynb#X32sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m original_feat, original_label \u001b[39m=\u001b[39m separate_df(df)\n",
      "\u001b[1;31mTypeError\u001b[0m: separate_df() missing 1 required positional argument: 'label_col'"
     ]
    }
   ],
   "source": [
    "df= pd.read_csv(\"./Data/GeneratedSyntheticData-NosieLessInformativeHard.csv\",index_col=0)\n",
    "\n",
    "randomForest = RandomForestClassifier()\n",
    "\n",
    "minority = df[df['5']==1] \n",
    "majority = df[df['5']==0]\n",
    "\n",
    "\n",
    "initial_population, bounds = Creation(minority,120,['5'], weightingFunction='uniform')\n",
    "\n",
    "antibody_population = mutatePopulation(initial_population,bounds,['5'],1.0)\n",
    "\n",
    "\n",
    "current_gen, current_labels = separate_df(initial_population)\n",
    "\n",
    "next_gen, next_labels = separate_df(antibody_population)\n",
    "\n",
    "original_feat, original_label = separate_df(df)\n",
    "\n",
    "\n",
    "\n",
    "#x = fitness2(randomForest, original_feat, original_label, next_gen, next_labels, \"not_implemented_yet\")\n",
    "\n",
    "scores = fitnessCV(randomForest, original_feat, original_label, next_gen, next_labels, 'f1', 5)\n",
    "scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying out LOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "separate_df() missing 1 required positional argument: 'label_col'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\jacob\\Documents\\GitHub\\Artificial-Immune-System-For-Class-Imbalance\\AIS.ipynb Cell 26\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jacob/Documents/GitHub/Artificial-Immune-System-For-Class-Imbalance/AIS.ipynb#X34sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m antibody_population \u001b[39m=\u001b[39m mutatePopulation(initial_population,bounds,[\u001b[39m'\u001b[39m\u001b[39m5\u001b[39m\u001b[39m'\u001b[39m],\u001b[39m1.0\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jacob/Documents/GitHub/Artificial-Immune-System-For-Class-Imbalance/AIS.ipynb#X34sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m current_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([df,initial_population],ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/jacob/Documents/GitHub/Artificial-Immune-System-For-Class-Imbalance/AIS.ipynb#X34sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m current_gen, current_labels \u001b[39m=\u001b[39m separate_df(current_df)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jacob/Documents/GitHub/Artificial-Immune-System-For-Class-Imbalance/AIS.ipynb#X34sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m next_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([df,antibody_population],ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/jacob/Documents/GitHub/Artificial-Immune-System-For-Class-Imbalance/AIS.ipynb#X34sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m next_gen, next_labels \u001b[39m=\u001b[39m separate_df(next_df)\n",
      "\u001b[1;31mTypeError\u001b[0m: separate_df() missing 1 required positional argument: 'label_col'"
     ]
    }
   ],
   "source": [
    "df= pd.read_csv(\"./Data/GeneratedSyntheticData-NosieLessInformativeHard.csv\",index_col=0) \n",
    "\n",
    "size = len(df.index)\n",
    "minority = df[df['5']==1] \n",
    "majority = df[df['5']==0]\n",
    "\n",
    "\n",
    "initial_population, bounds = Creation(minority,120,['5'], weightingFunction='uniform')\n",
    "\n",
    "antibody_population = mutatePopulation(initial_population,bounds,['5'],1.0)\n",
    "\n",
    "current_df = pd.concat([df,initial_population],ignore_index=True)\n",
    "current_gen, current_labels = separate_df(current_df)\n",
    "\n",
    "\n",
    "next_df = pd.concat([df,antibody_population],ignore_index=True)\n",
    "next_gen, next_labels = separate_df(next_df)\n",
    "\n",
    "clf = LocalOutlierFactor(n_neighbors=20)\n",
    "\n",
    "y_pred = clf.fit_predict(next_df)\n",
    "#n_errors = (y_pred != ground_truth).sum()\n",
    "X_scores = clf.negative_outlier_factor_\n",
    "\n",
    "outliers = (X_scores < -2).sum()\n",
    "outliers\n",
    "next_df[\"lof\"]=X_scores\n",
    "\n",
    "#use size of original df\n",
    "\n",
    "antibody_population[\"lof\"] = X_scores[size:]\n",
    "#print(antibody_population)\n",
    "#print(next_df[300:])\n",
    "#sorted_df = next_df.sort_values(by = ['lof'], ignore_index=True)\n",
    "#sorted_df\n",
    "sorted_pop = antibody_population.sort_values(by = ['lof'], ignore_index=True)\n",
    "sorted_pop\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST LOF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(          0       1       2       3       4  5\n",
       " 0   -0.8432 -3.5282 -0.0501  2.5187 -0.5025  1\n",
       " 1    1.2280  2.2951  3.2678 -3.2986  0.8151  1\n",
       " 2    1.7260 -2.4066  3.8643 -3.2133  1.7390  1\n",
       " 3    1.4017 -0.2919  4.6156 -2.6526 -0.3847  1\n",
       " 4    0.4966 -1.4200  1.1175  2.0849  0.1040  1\n",
       " ..      ...     ...     ...     ...     ... ..\n",
       " 115 -3.2798  0.7419  2.7816  0.9615  1.1917  1\n",
       " 116 -2.3698  1.6707  0.8360  1.0882  1.1563  1\n",
       " 117 -3.2923 -0.9204  2.7438  0.7083  0.7086  1\n",
       " 118 -1.0064 -0.4529  1.5155 -3.1937  1.4584  1\n",
       " 119 -3.0842 -0.1180  0.2250 -1.6448  1.1125  1\n",
       " \n",
       " [120 rows x 6 columns],\n",
       " 0.8754321352496983)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv(\"./Data/GeneratedSyntheticData-NosieLessInformativeHard.csv\",index_col=0) \n",
    "\n",
    "size = len(df.index)\n",
    "minority = df[df['5']==1] \n",
    "majority = df[df['5']==0]\n",
    "\n",
    "initial_population, bounds = Creation(minority,120,['5'], weightingFunction='uniform')\n",
    "\n",
    "antibody_population = mutatePopulation(initial_population,bounds,['5'],1.0)\n",
    "\n",
    "current_df = pd.concat([df,initial_population],ignore_index=True)\n",
    "current_gen, current_labels = separate_df(current_df,'5')\n",
    "\n",
    "next_df = pd.concat([df,antibody_population],ignore_index=True)\n",
    "next_gen, next_labels = separate_df(next_df,'5')\n",
    "\n",
    "original_gen, original_labels = separate_df(df,'5')\n",
    "\n",
    "previous = lof(df, initial_population)\n",
    "randomForest = RandomForestClassifier()\n",
    "rizz = get_best_population(df, original_gen, original_labels, antibody_population, previous, original_labels.columns, randomForest, 5, 'f1' )\n",
    "rizz\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('csi4106')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "51ea9996f2a91c7d112e626959c304b606e4bf2254e73fec145d965796b2ca69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
