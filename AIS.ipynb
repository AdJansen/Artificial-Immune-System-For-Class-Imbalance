{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd;\n",
    "import random;\n",
    "from statistics import fmean, stdev;\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import DistanceMetric\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OBJECTS/VARIABLES:\n",
    "\n",
    "Antibody - list of Numerical values (Reals?) , represented by a row of a dataframe?\n",
    "Population - List[Antibodies], represented by the total dataframe?\n",
    "\n",
    "Target Size (i.e number of antibodies to be created) = (Size of Majority Class) - (Size of minority class)\n",
    "\n",
    "\n",
    "\n",
    "FUNCTIONS:\n",
    "\n",
    "Initializing :- input: original dataframe\n",
    "\n",
    "                         do: Get bounds of minority class by taking the highest and lowest values in each of the [n] dimensions\n",
    "\n",
    "                         How: Do we take the whole minority class? or do we sample part or parts of it to generate our bounds. \n",
    "\n",
    "                         output: Upper and lower bounds of the minority class\n",
    "\n",
    "\n",
    "Creation :- Input: Bounds of the min class\n",
    "\n",
    "        do: Create a set of antibodies\n",
    "\n",
    "        input: minority Dataframe \n",
    "\n",
    "        How:\n",
    "            Possibilities:\n",
    "            (As the Malhanabois paper does it) Take a random value between the bounds of the minority class feature as the datapoint\n",
    "\n",
    "            (Nikhil Just sample minority class based on imbalance rate (doesn't require bounds)\n",
    "\n",
    "            (Adam) Take a random value, as in the paper's method, but off of a weighted curve? as in we could randomize, \n",
    "                but add some preference for values close to the boundary, or close to the center, etc.\n",
    "                        -We could set this as a parameter, bell curve, linear. This same function could be a parameter in the mutation stage.\n",
    "                        -If the density within the bounds is concentrated on one side, add bias towards that side in the random value;\n",
    "        \n",
    "        Challenges: \n",
    "            How do we deal with the different data categories (e.g nominal, ordinal, and continuous)? Continuous is easy, just a number in a range. Ordinal is ???, nominal is difficult, even if one-hot encoded, we might random to have two values that should be exclusive (e.g an item being both blue and red). How do other imputation algorithms work with these problems? DO they even work with these problems?\n",
    "        output: Initial Population as a DF?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class2</th>\n",
       "      <th>AGE</th>\n",
       "      <th>Sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0214</td>\n",
       "      <td>-0.228</td>\n",
       "      <td>-1.920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9650</td>\n",
       "      <td>-0.228</td>\n",
       "      <td>0.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0214</td>\n",
       "      <td>-0.228</td>\n",
       "      <td>0.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.9650</td>\n",
       "      <td>-0.228</td>\n",
       "      <td>0.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.9650</td>\n",
       "      <td>-0.228</td>\n",
       "      <td>0.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>-0.9230</td>\n",
       "      <td>-0.228</td>\n",
       "      <td>-1.920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.0214</td>\n",
       "      <td>-0.228</td>\n",
       "      <td>0.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.0214</td>\n",
       "      <td>4.380</td>\n",
       "      <td>-1.920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>-0.9230</td>\n",
       "      <td>-0.228</td>\n",
       "      <td>0.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>0.0214</td>\n",
       "      <td>-0.228</td>\n",
       "      <td>-1.920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1999 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      class2    AGE    Sex\n",
       "0     0.0214 -0.228 -1.920\n",
       "1     0.9650 -0.228  0.521\n",
       "2     0.0214 -0.228  0.521\n",
       "3     0.9650 -0.228  0.521\n",
       "4     0.9650 -0.228  0.521\n",
       "...      ...    ...    ...\n",
       "1996 -0.9230 -0.228 -1.920\n",
       "1997  0.0214 -0.228  0.521\n",
       "1998  0.0214  4.380 -1.920\n",
       "1999 -0.9230 -0.228  0.521\n",
       "2000  0.0214 -0.228 -1.920\n",
       "\n",
       "[1999 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(\"./Data/TitanicData_syn.csv\")\n",
    "\n",
    "columns = df.columns.to_list()\n",
    "columns_drop = columns.pop(-1)\n",
    "\n",
    "#drop NaN rows, could implement imputer as well\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "labels = df.drop(columns, axis=1)\n",
    "\n",
    "df= df.drop(\"Result\", axis=1)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class2    0\n",
       "AGE       0\n",
       "Sex       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "count_nan = df.isnull().sum()\n",
    "count_nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.18553, 0.6865, -1.32287], [1.36359, 0.43997, 0.32751], [-0.81489, 1.12035, -0.34511]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def get_bounds(minorityDF) -> tuple:\n",
    "    out = []\n",
    "    for col in minorityDF:\n",
    "        colMax = df[col].max()\n",
    "        colMin = df[col].min()\n",
    "        out += [(col, colMin, colMax, )]\n",
    "    return out\n",
    "\n",
    "#This only works for continuous values. We will have to code a version for binary fields (We assume any categorical columns have been encoded)\n",
    "####### Creation ################\n",
    "# minorityDF - dataframe containing the minority class\n",
    "# totalPopulation - The total number of antibodies to create\n",
    "# weightingFunction - Can choose between uniform, triangular, ...\n",
    "# mode - for use with a triangular function - set to the percentage of the range you wish to be most represented (between 0.0 and 1.0)\n",
    "def Creation(minorityDF, totalPopulation : int, weightingFunction : str = \"uniform\", mode : float = 0.5): \n",
    "    \n",
    "    if(minorityDF.isnull().values.any()):\n",
    "        raise ValueError(\"Minority Class DataFrame contains NaN\")\n",
    "    \n",
    "    population = [] #Initializing the empty population\n",
    "    if mode < 0.0 or mode > 1:\n",
    "        raise Exception(\"mode must be between float value between 0.0 and 1.0\")\n",
    "    \n",
    "\n",
    "    for i in range(totalPopulation): #For every antibody to be created\n",
    "\n",
    "        antibody = [] #Initializing a single antibody\n",
    "        if weightingFunction in [\"uniform\", \"triangular\"]: #If Generating via uniform or triangular distribution, loop through bounds of columns\n",
    "            \n",
    "            for col in get_bounds(minorityDF): #Iterate through the columns/dimensions/features of the minority class for each antibody \n",
    "                if weightingFunction == \"uniform\":\n",
    "                    antibody += [round(random.uniform(col[1],col[2]),4)] #Add a random value between the lower and upper bounds to the antibody\n",
    "\n",
    "                elif (weightingFunction == \"triangular\"):\n",
    "                    \n",
    "                    tri_tip = ( ((col[2]-col[1]) * mode) + col[1] ) #multiplying the difference by the percentage, plus the low bound gives us the point between the two, but percentile\n",
    "\n",
    "                    if tri_tip < col[1]: #Error checks to make sure that the emphasized point isn't outside the bounds\n",
    "                        tri_tip = col[1]\n",
    "                    elif tri_tip > col[2]:\n",
    "                        tri_tip = col[2]\n",
    "\n",
    "                    antibody += [round( random.triangular(col[1],col[2], tri_tip), 5)]\n",
    "\n",
    "            population+=[antibody] #add the created antibody to the population\n",
    "\n",
    "        elif (weightingFunction == 'gauss'): #If Generating via Gaussian, loop through columns of dataframe\n",
    "\n",
    "            for col in minorityDF:\n",
    "                values = minorityDF[col].tolist()\n",
    "\n",
    "                antibody += [round(random.gauss(fmean(values) , stdev(values)), 5)]\n",
    "\n",
    "        \n",
    "            population+=[antibody] #add the created antibody to the population\n",
    "\n",
    "            \n",
    "\n",
    "    return population\n",
    "    \n",
    "\n",
    "print(Creation(df,3, weightingFunction='gauss'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fitness Function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requirements: Needs to be calced fast bc of multiple iterations\n",
    "Posiibilities: - Binary Classification F1 Score, Mahalanobis Distance?\n",
    "               - Other Types as well? : Linear Regression, Multiilabel Classification\n",
    "\n",
    "Do we just impute our values and then do something similar to StudentPerformance and see what happens? No bc we need input from the fitness function to do our generations.\n",
    "\n",
    "Is the data just our training set?\n",
    "Inputs: Model(initialized outside function or inside?) fit with data that has been encoded and the label\n",
    "\n",
    "Want to do kfold cv (not every loop bc very slow, once afterwards to evaluate)\n",
    "\n",
    "when we do k fold, call fitness funciton k times i.e. once for every train test split.\n",
    "\n",
    "if doing grid search, do it before calling this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates the fitness score for one train/test split dataset\n",
    "# run on original dataset without random values first to be abe to compare\n",
    "\n",
    "\n",
    "# def fitness(train_feat, test_feat, train_label, test_label, model):\n",
    "\n",
    "#     model.fit(train_feat,train_label)\n",
    "#     predictions = model.predict(test_feat) \n",
    "\n",
    "#     return f1_score(test_label, predictions, average='macro')\n",
    "\n",
    "# def kfold_cv(n, feat, label):\n",
    "\n",
    "#     kf = KFold(n_splits = n , random_state=None, shuffle=False)\n",
    "#     for train_index, test_index in kf.split(df):\n",
    "#         train_feat, test_feat = feat[train_index], feat[test_index]\n",
    "#         train_label, test_label = label[train_index], label[test_index]\n",
    "\n",
    "def fitness( model, feat, label, iterations, scorer):\n",
    "    #scorer is the name of the function wee aree using to evaluate our dataset\n",
    "    #it should be a function with signature scorer(model, feature, label) which should return only a single value.\n",
    "    return cross_val_score(model, feat, label, cv = iterations, scoring = scorer)\n",
    "\n",
    "def distance( x, y, metric):\n",
    "    \n",
    "    #get the distance between two sets of data x and y, they should be the same size\n",
    "    #metric is the string metric to be used to measure distance\n",
    "\n",
    "    dist = DistanceMetric.get_metric(metric)\n",
    "    return dist.pairwise(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.65982906, 0.65413105, 0.68304843, 0.68490028, 0.67054264])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "randomForest = RandomForestClassifier()\n",
    "#randomForest = randomForest.fit(df,labels)\n",
    "clf = svm.SVC(random_state=0)\n",
    "\n",
    "fitness(clf, df, labels.values.ravel(), 5, 'recall_macro')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f1230bc2996daf223e6b57a912b6139c94249dacdc4187f83e6f04a96b987e10"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
