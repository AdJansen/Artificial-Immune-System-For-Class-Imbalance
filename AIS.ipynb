{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd;\n",
    "import random;\n",
    "from statistics import fmean, stdev;\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import DistanceMetric\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "from itertools import combinations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OBJECTS/VARIABLES:\n",
    "\n",
    "Antibody - list of Numerical values (Reals?) , represented by a row of a dataframe?\n",
    "Population - List[Antibodies], represented by the total dataframe?\n",
    "\n",
    "Target Size (i.e number of antibodies to be created) = (Size of Majority Class) - (Size of minority class)\n",
    "\n",
    "\n",
    "\n",
    "FUNCTIONS:\n",
    "\n",
    "Initializing :- input: original dataframe\n",
    "\n",
    "                         do: Get bounds of minority class by taking the highest and lowest values in each of the [n] dimensions\n",
    "\n",
    "                         How: Do we take the whole minority class? or do we sample part or parts of it to generate our bounds. \n",
    "\n",
    "                         output: Upper and lower bounds of the minority class\n",
    "\n",
    "\n",
    "Creation :- Input: Bounds of the min class\n",
    "\n",
    "        do: Create a set of antibodies\n",
    "\n",
    "        input: minority Dataframe \n",
    "\n",
    "        How:\n",
    "            Possibilities:\n",
    "            (As the Malhanabois paper does it) Take a random value between the bounds of the minority class feature as the datapoint\n",
    "\n",
    "            (Nikhil Just sample minority class based on imbalance rate (doesn't require bounds)\n",
    "\n",
    "            (Adam) Take a random value, as in the paper's method, but off of a weighted curve? as in we could randomize, \n",
    "                but add some preference for values close to the boundary, or close to the center, etc.\n",
    "                        -We could set this as a parameter, bell curve, linear. This same function could be a parameter in the mutation stage.\n",
    "                        -If the density within the bounds is concentrated on one side, add bias towards that side in the random value;\n",
    "        \n",
    "        Challenges: \n",
    "            How do we deal with the different data categories (e.g nominal, ordinal, and continuous)? Continuous is easy, just a number in a range. Ordinal is ???, nominal is difficult, even if one-hot encoded, we might random to have two values that should be exclusive (e.g an item being both blue and red). How do other imputation algorithms work with these problems? DO they even work with these problems?\n",
    "        output: Initial Population as a DF?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4.539317</td>\n",
       "      <td>5.021729</td>\n",
       "      <td>-7.042357</td>\n",
       "      <td>-7.428090</td>\n",
       "      <td>4.943687</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.300671</td>\n",
       "      <td>6.131065</td>\n",
       "      <td>-6.394796</td>\n",
       "      <td>-5.981102</td>\n",
       "      <td>4.579452</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-5.004336</td>\n",
       "      <td>4.473384</td>\n",
       "      <td>-6.048647</td>\n",
       "      <td>-5.556982</td>\n",
       "      <td>4.051438</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.732848</td>\n",
       "      <td>7.791876</td>\n",
       "      <td>-7.495527</td>\n",
       "      <td>-6.541127</td>\n",
       "      <td>3.910933</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-4.193859</td>\n",
       "      <td>5.393440</td>\n",
       "      <td>-5.317542</td>\n",
       "      <td>-5.605152</td>\n",
       "      <td>4.807354</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>5.349610</td>\n",
       "      <td>4.226061</td>\n",
       "      <td>-4.841005</td>\n",
       "      <td>-6.342083</td>\n",
       "      <td>4.820905</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>-5.247255</td>\n",
       "      <td>5.149173</td>\n",
       "      <td>-6.669314</td>\n",
       "      <td>-5.848687</td>\n",
       "      <td>3.793496</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>3.308685</td>\n",
       "      <td>5.513754</td>\n",
       "      <td>-3.805559</td>\n",
       "      <td>-5.564981</td>\n",
       "      <td>4.670373</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>-4.510472</td>\n",
       "      <td>4.712267</td>\n",
       "      <td>-4.550419</td>\n",
       "      <td>-3.915542</td>\n",
       "      <td>4.798225</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>-4.630100</td>\n",
       "      <td>4.954438</td>\n",
       "      <td>-4.243112</td>\n",
       "      <td>-3.235496</td>\n",
       "      <td>4.634826</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4    5\n",
       "0   -4.539317  5.021729 -7.042357 -7.428090  4.943687  0.0\n",
       "1    4.300671  6.131065 -6.394796 -5.981102  4.579452  1.0\n",
       "2   -5.004336  4.473384 -6.048647 -5.556982  4.051438  0.0\n",
       "3    2.732848  7.791876 -7.495527 -6.541127  3.910933  1.0\n",
       "4   -4.193859  5.393440 -5.317542 -5.605152  4.807354  0.0\n",
       "..        ...       ...       ...       ...       ...  ...\n",
       "295  5.349610  4.226061 -4.841005 -6.342083  4.820905  1.0\n",
       "296 -5.247255  5.149173 -6.669314 -5.848687  3.793496  0.0\n",
       "297  3.308685  5.513754 -3.805559 -5.564981  4.670373  1.0\n",
       "298 -4.510472  4.712267 -4.550419 -3.915542  4.798225  0.0\n",
       "299 -4.630100  4.954438 -4.243112 -3.235496  4.634826  0.0\n",
       "\n",
       "[300 rows x 6 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(\"./Data/GeneratedSyntheticData-NosielessInformativeEasy.csv\")\n",
    "\n",
    "columns = df.columns.to_list()\n",
    "columns_drop = columns.pop(-1)\n",
    "\n",
    "#drop NaN rows, could implement imputer as well\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "labels = df.drop(columns, axis=1)\n",
    "\n",
    "#df= df.drop(\"5\", axis=1)\n",
    "#df= df.drop(\"Unnamed: 0\", axis=1)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO Gaussian generation can be optimized by altering how the loops work, putting the col loop on the outside and pre-generated fmean, stdev for the col\n",
    "        #Currently it generates those values for every antibody\n",
    "        \n",
    "\n",
    "def get_bounds(minorityDF) -> dict:\n",
    "    out = {}\n",
    "    for col in minorityDF:\n",
    "        colMax = minorityDF[col].max()\n",
    "        colMin = minorityDF[col].min()\n",
    "        out[col] = (colMin, colMax)\n",
    "    return out\n",
    "\n",
    "#This only works for continuous values. We will have to code a version for binary fields (We assume any categorical columns have been encoded)\n",
    "\n",
    "####### Creation ################\n",
    "# minorityDF - dataframe containing the minority class\n",
    "# totalPopulation - The total number of antibodies to create\n",
    "# weightingFunction - Can choose between uniform, triangular, ...\n",
    "# mode - for use with a triangular function - set to the percentage of the range you wish to be most represented (between 0.0 and 1.0)\n",
    "def Creation(minorityDF, totalPopulation : int, binaryColumns : list, weightingFunction : str = \"uniform\", mode : float = 0.5): \n",
    "    \n",
    "    if(minorityDF.isnull().values.any()):\n",
    "        raise ValueError(\"Minority Class DataFrame contains NaN\")\n",
    "    \n",
    "    population = [] #Initializing the empty population\n",
    "    if mode < 0.0 or mode > 1:\n",
    "        raise Exception(\"mode must be between float value between 0.0 and 1.0\")\n",
    "    \n",
    "    if weightingFunction not in ('uniform', 'triangular', 'gaussian'):\n",
    "        raise Exception(\"Unknown function chosen, please use one of 'uniform', 'triangular', or 'gaussian'\")\n",
    "\n",
    "    bounds = get_bounds(minorityDF)\n",
    "    \n",
    "    if weightingFunction in [\"uniform\", \"triangular\"]: #If Generating via uniform or triangular distribution, loop through bounds of columns\n",
    "        for i in range(totalPopulation): #For every antibody to be created\n",
    "\n",
    "            antibody = [] #Initializing a single antibody\n",
    "            for key,bnd in bounds.items(): #Iterate through the columns/dimensions/features of the minority class for each antibody \n",
    "                if key in binaryColumns:\n",
    "                    antibody += [random.randint(int(bnd[0]),int(bnd[1]))]\n",
    "                else:\n",
    "                    if weightingFunction == \"uniform\":\n",
    "                        antibody += [round(random.uniform(bnd[0],bnd[1]),4)] #Add a random value between the lower and upper bounds to the antibody\n",
    "\n",
    "                    elif (weightingFunction == \"triangular\"):\n",
    "                        \n",
    "                        tri_tip = ( ((bnd[1]-bnd[0]) * mode) + bnd[0] ) #multiplying the difference by the percentage, plus the low bound gives us the point between the two, but percentile\n",
    "\n",
    "                        if tri_tip < bnd[0]: #Error checks to make sure that the emphasized point isn't outside the bounds\n",
    "                            tri_tip = bnd[0]\n",
    "                        elif tri_tip > bnd[1]:\n",
    "                            tri_tip = bnd[1]\n",
    "\n",
    "                        antibody += [round( random.triangular(bnd[0],bnd[1], tri_tip), 5)]\n",
    "\n",
    "            population+=[antibody] #add the created antibody to the population\n",
    "\n",
    "    elif (weightingFunction == 'gaussian'): #If Generating via Gaussian, loop through columns of dataframe\n",
    "\n",
    "        for i in range(totalPopulation): #For every antibody to be created\n",
    "\n",
    "            antibody = [] #Initializing a single antibody\n",
    "            for bnd in minorityDF: #Iterate over columns in the dataframe\n",
    "                values = minorityDF[bnd].tolist() #convert series to list\n",
    "                if bnd in binaryColumns:\n",
    "                    antibody += [random.randint(bounds[bnd][0],bounds[bnd][1])]\n",
    "                else:\n",
    "                    antibody += [round(random.gauss(fmean(values) , stdev(values)), 5)] #using median and stdeviation of values, radomize over gauss\n",
    "\n",
    "        \n",
    "            population+=[antibody] #add the created antibody to the population\n",
    "\n",
    "            \n",
    "    popDF = pd.DataFrame(population, columns = minorityDF.columns.values)\n",
    "    return popDF, bounds\n",
    "    \n",
    "\n",
    "#Creation(df,1000,['5'], weightingFunction='gaussian')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function For Experiments with bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fitness Function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requirements: Needs to be calced fast bc of multiple iterations\n",
    "Posiibilities: - Binary Classification F1 Score, Mahalanobis Distance?\n",
    "               - Other Types as well? : Linear Regression, Multiilabel Classification\n",
    "\n",
    "Do we just impute our values and then do something similar to StudentPerformance and see what happens? No bc we need input from the fitness function to do our generations.\n",
    "\n",
    "Is the data just our training set?\n",
    "Inputs: Model(initialized outside function or inside?) fit with data that has been encoded and the label\n",
    "\n",
    "Want to do kfold cv (not every loop bc very slow, once afterwards to evaluate)\n",
    "\n",
    "when we do k fold, call fitness funciton k times i.e. once for every train test split.\n",
    "\n",
    "if doing grid search, do it before calling this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculates the fitness score for one train/test split dataset\n",
    "# run on original dataset without random values first to be abe to compare\n",
    "\n",
    "def fitness( model, feat, label, iterations, scorer):\n",
    "    #scorer is the name of the function wee aree using to evaluate our dataset\n",
    "    #it should be a function with signature scorer(model, feature, label) which should return only a single value.\n",
    "    return cross_val_score(model, feat, label, cv = iterations, scoring = scorer)\n",
    "\n",
    "def distance( x, y, metric):\n",
    "    \n",
    "    #get the distance between two sets of data x and y, they should be the same size\n",
    "    #metric is the string metric to be used to measure distance\n",
    "\n",
    "    dist = DistanceMetric.get_metric(metric)\n",
    "    return dist.pairwise(x,y)\n",
    "    \n",
    "#Original features, original labels are the original df before any oversampling\n",
    "#Population_features, population_labels are the generated population we want to evaluate\n",
    "#Here scorer has to be a function that takes y_pred, y_true and returns a score, not implemented yet\n",
    "def fitnessBasic(model, original_features, original_labels, population_features, population_labels, scorer):\n",
    "\n",
    "    #train test split makes train set smaller, we should sample the population based on he difference of the majority class and minority class in origin_feat_train\n",
    "    origin_feat_train, origin_feat_test, origin_labels_train, origin_labels_test = train_test_split(original_features, original_labels, test_size=0.33)\n",
    "    \n",
    "    train_features = pd.concat([origin_feat_train, population_features],ignore_index=True)\n",
    "    train_labels = pd.concat([origin_labels_train, population_labels],ignore_index=True)\n",
    "\n",
    "    model.fit(train_features, train_labels.values.ravel())\n",
    "    predictions = model.predict(origin_feat_test)\n",
    "\n",
    "    #need more params?\n",
    "    #hard coded f1_score, find a way to pass in function for scoring?\n",
    "    score = f1_score(origin_labels_test.values.ravel(), predictions)\n",
    "    return score\n",
    "\n",
    "#Original features, original labels are the original df before any oversampling\n",
    "#Population_features, population_labels are the generated population we want to evaluate\n",
    "#Here scorer has to be a function that takes y_pred, y_true and returns a score, not implemented yet\n",
    "def fitnessCV(model, original_features, original_labels, population_features, population_labels, scorer, iterations):\n",
    "    #TODO: train_features or train_labels had 1 extra row, need to fix\n",
    "    #train test split makes train set smaller, we should sample the population based on he difference of the majority class and minority class in origin_feat_train\n",
    "    origin_feat_train, origin_feat_test, origin_labels_train, origin_labels_test = train_test_split(original_features, original_labels, test_size=0.33)\n",
    "    \n",
    "    train_features = pd.concat([origin_feat_train, population_features],ignore_index=True)\n",
    "    train_labels = pd.concat([origin_labels_train, population_labels],ignore_index=True)\n",
    "\n",
    "    #look into group parameter of cross_validate\n",
    "    #here scoring can be multiple values\n",
    "    \n",
    "    cval_scores = cross_validate(model, train_features, train_labels.values.ravel(), scoring = scorer, cv = iterations, return_train_score = True, return_estimator = True)\n",
    "\n",
    "    #look at format of scores, get estimators and use them to predict test\n",
    "\n",
    "    test_scores = []\n",
    "    cval_test_scores =cval_scores['test_score']\n",
    "    count = 0 \n",
    "    for estimator in cval_scores['estimator']:\n",
    "        \n",
    "        estimator.fit(train_features, train_labels.values.ravel())\n",
    "        predictions = estimator.predict(origin_feat_test)\n",
    "\n",
    "        #hard coded f1_score, find a way to pass in function for scoring?\n",
    "        score = f1_score(origin_labels_test, predictions) \n",
    "\n",
    "        #here I just took the mean of the 2 scores, could we use something else?\n",
    "        mean_score = (score + cval_test_scores[count])/2\n",
    "        count+=1\n",
    "        test_scores.append(mean_score)\n",
    "    \n",
    "    #here I just took the mean of the array of all scores, could we use something else?\n",
    "    return fmean(test_scores)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mutation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Mutation ################\n",
    "def mutatePopulation (antiPopulation, bounds, binaryColumns : list, mutationRate : float = 1.0):\n",
    "    #antiPopulation is the population of antibodies to be mutated\n",
    "    #bounds is a dictionary of the bounds of each column in the population\n",
    "    #binaryColumns is a list of the columns that are binary\n",
    "    #mutationRate denotes how much the antibodies can mutate each round, 1.0 is the default, 0.0 is no mutation, 2.0 is double mutation rate\n",
    "    #returns a new mutated population of antibodies\n",
    "    antiPopulation = antiPopulation.copy()\n",
    "    for col in antiPopulation:\n",
    "        if bounds[col][0] == bounds[col][1]:\n",
    "            continue\n",
    "        elif col in binaryColumns: #Binary Columns must be handled differently than continuous\n",
    "            \n",
    "            antiPopulation[col] = antiPopulation[col].map(lambda x : (random.randint(0,1)))\n",
    "        else:\n",
    "            bnd_range = (bounds[col][1] - bounds[col][0])*mutationRate #total range of bounds is high - low\n",
    "\n",
    "            #Setting the low and high bounds to be centered around 0\n",
    "            hi_bnd = bnd_range/2 \n",
    "            low_bnd = (0-bnd_range/2)\n",
    "\n",
    "            #print(\"Low bound around 0 = \" + str(low_bnd) +\"| Hi bnd around 0 = \"+ str(hi_bnd))\n",
    "            #print(round(random.uniform(low_bnd,hi_bnd),4))\n",
    "\n",
    "            antiPopulation[col] = antiPopulation[col].map(lambda x : x+round(random.uniform(low_bnd,hi_bnd),4))\n",
    "        \n",
    "    return antiPopulation\n",
    "\n",
    "#First round: Compare the base dataset, to the dataset+the created/mutated points\n",
    "#\n",
    "\n",
    "def comparePopulations(population1, population2, labels1, labels2, estimator, iterations, scorer):\n",
    "\n",
    "    score1 = fmean(fitness(estimator, population1, labels1.values.ravel(), iterations, scorer))\n",
    "    score2 = fmean(fitness(estimator, population2, labels2.values.ravel(), iterations, scorer))\n",
    "\n",
    "    if score1 > score2:\n",
    "        winning_population = population1\n",
    "        winning_labels = labels1\n",
    "    else:\n",
    "        winning_population = population2\n",
    "        winning_labels = labels2\n",
    "\n",
    "    for col in winning_labels:\n",
    "        winning_population = winning_population.join(winning_labels[col])\n",
    "\n",
    "    return winning_population\n",
    "\n",
    "def comparePopulations2(population1, population2, labels1, labels2, estimator, iterations, scorer):\n",
    "    score1 = fmean(fitness(estimator, population1, labels1.values.ravel(), iterations, scorer))\n",
    "    score2 = fmean(fitness(estimator, population2, labels2.values.ravel(), iterations, scorer))\n",
    "    \n",
    "    print(\"score1: \" +str(score1))\n",
    "    print(\"score2: \" +str(score2))\n",
    "\n",
    "    if abs(score1 - score2) < 0.005:\n",
    "        return False\n",
    "    elif (score1>score2):\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "#takes in the previous population's score, will need to add variable in AIS to track this from previous round\n",
    "# original features and original labels are the original df split into features and labels\n",
    "# population features and population labels are the population df split into features and labels, this is the new population we mutated this round\n",
    "# estimator, iterations, scorer not changed from old compare populaitons\n",
    "def comparePopulationsCV(prev_score, original_features, original_labels, population_features, population_labels, estimator, iterations, scorer, min_change = 0.005):\n",
    "    score1 = prev_score\n",
    "    score2 = fitnessCV(estimator, original_features, original_labels, population_features, population_labels, scorer, iterations)\n",
    "    \n",
    "    # print(\"score1: \" +str(score1))\n",
    "    # print(\"score2: \" +str(score2))\n",
    "\n",
    "    #is 0.005 too big?\n",
    "    if abs(score1 - score2) < 0.005:\n",
    "        return False, score1\n",
    "    elif (score1>score2):\n",
    "        return False, score1\n",
    "    else:\n",
    "        return True, score2\n",
    "\n",
    "#need a comparePopulationsBasic for fitnessBasic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do we need this?\n",
    "create1 = Creation(df,10000,['5'], weightingFunction='uniform')\n",
    "create2 = Creation(df,10000,['5'], weightingFunction='uniform')\n",
    "\n",
    "pop1 = create1[0]\n",
    "pop2 = create2[0]\n",
    "bounds1 = create1[1]\n",
    "bounds2 = create2[1]\n",
    "columns1 = pop1.columns.to_list()\n",
    "columns1_drop = columns1.pop(-1)\n",
    "\n",
    "labels1 = pop1.drop(columns1, axis=1)\n",
    "pop1 = pop1.drop(columns1_drop, axis=1)\n",
    "\n",
    "columns2 = pop2.columns.to_list()\n",
    "columns2_drop = columns2.pop(-1)\n",
    "\n",
    "labels2 = pop2.drop(columns2, axis=1)\n",
    "pop2 = pop2.drop(columns2_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      5\n",
       "0     1\n",
       "1     0\n",
       "2     1\n",
       "3     0\n",
       "4     1\n",
       "...  ..\n",
       "9995  0\n",
       "9996  0\n",
       "9997  1\n",
       "9998  1\n",
       "9999  1\n",
       "\n",
       "[10000 rows x 1 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutatePopulation(labels1, bounds1, ['5'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4.539317</td>\n",
       "      <td>5.021729</td>\n",
       "      <td>-7.042357</td>\n",
       "      <td>-7.428090</td>\n",
       "      <td>4.943687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.300671</td>\n",
       "      <td>6.131065</td>\n",
       "      <td>-6.394796</td>\n",
       "      <td>-5.981102</td>\n",
       "      <td>4.579452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-5.004336</td>\n",
       "      <td>4.473384</td>\n",
       "      <td>-6.048647</td>\n",
       "      <td>-5.556982</td>\n",
       "      <td>4.051438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.732848</td>\n",
       "      <td>7.791876</td>\n",
       "      <td>-7.495527</td>\n",
       "      <td>-6.541127</td>\n",
       "      <td>3.910933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-4.193859</td>\n",
       "      <td>5.393440</td>\n",
       "      <td>-5.317542</td>\n",
       "      <td>-5.605152</td>\n",
       "      <td>4.807354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>5.349610</td>\n",
       "      <td>4.226061</td>\n",
       "      <td>-4.841005</td>\n",
       "      <td>-6.342083</td>\n",
       "      <td>4.820905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>-5.247255</td>\n",
       "      <td>5.149173</td>\n",
       "      <td>-6.669314</td>\n",
       "      <td>-5.848687</td>\n",
       "      <td>3.793496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>3.308685</td>\n",
       "      <td>5.513754</td>\n",
       "      <td>-3.805559</td>\n",
       "      <td>-5.564981</td>\n",
       "      <td>4.670373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>-4.510472</td>\n",
       "      <td>4.712267</td>\n",
       "      <td>-4.550419</td>\n",
       "      <td>-3.915542</td>\n",
       "      <td>4.798225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>-4.630100</td>\n",
       "      <td>4.954438</td>\n",
       "      <td>-4.243112</td>\n",
       "      <td>-3.235496</td>\n",
       "      <td>4.634826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4\n",
       "0   -4.539317  5.021729 -7.042357 -7.428090  4.943687\n",
       "1    4.300671  6.131065 -6.394796 -5.981102  4.579452\n",
       "2   -5.004336  4.473384 -6.048647 -5.556982  4.051438\n",
       "3    2.732848  7.791876 -7.495527 -6.541127  3.910933\n",
       "4   -4.193859  5.393440 -5.317542 -5.605152  4.807354\n",
       "..        ...       ...       ...       ...       ...\n",
       "295  5.349610  4.226061 -4.841005 -6.342083  4.820905\n",
       "296 -5.247255  5.149173 -6.669314 -5.848687  3.793496\n",
       "297  3.308685  5.513754 -3.805559 -5.564981  4.670373\n",
       "298 -4.510472  4.712267 -4.550419 -3.915542  4.798225\n",
       "299 -4.630100  4.954438 -4.243112 -3.235496  4.634826\n",
       "\n",
       "[300 rows x 5 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TODO : add parameter that defines which column is the label\n",
    "#separate a df into features and labels\n",
    "def separate_df(df, label_col):\n",
    "\n",
    "    columns = df.columns.to_list()\n",
    "    columns_drop = columns.pop(columns.index(label_col))\n",
    "    labels = df.drop(columns, axis=1)\n",
    "    features = df.drop(columns_drop, axis=1)\n",
    "\n",
    "    return features, labels\n",
    "\n",
    "joe = pd.read_csv(\"./Data/GeneratedSyntheticData-NosielessInformativeEasy.csv\")\n",
    "feat,labels = separate_df(joe, '5')\n",
    "feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getBinaryColumns(df) -> list:\n",
    "        return list(df.columns[df.nunique() == 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractBinaryMinorityClass( preparedFeatures, labels) -> pd.DataFrame:\n",
    "        #preparedFeatures is the dataframe of features, labels is the dataframe of labels\n",
    "        #returns a dataframe of the minority class\n",
    "        #get counts of each class from labels\n",
    "        for col in labels:\n",
    "                counts = labels[col].value_counts()\n",
    "                #get the minority class\n",
    "                minorityLabel = counts.idxmin()\n",
    "\n",
    "        minorityClass = labels[labels == minorityLabel]\n",
    "        minorityClass = minorityClass.dropna()\n",
    "        minorityClass = minorityClass.index.values\n",
    "        minorityClass = preparedFeatures.loc[minorityClass]\n",
    "        minorityClass[labels.columns[0]]=minorityLabel\n",
    "        return minorityClass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#takes a population, generates its LOF score, ranks the data by it and splits it into n_blocks groups of similar data\n",
    "def lof(original_df, population, n_neighbor:int = 20, n_blocks:int = 4):\n",
    "\n",
    "    size = len(original_df.index)\n",
    "\n",
    "    df = pd.concat([original_df,population],ignore_index=True)\n",
    "    lof = LocalOutlierFactor(n_neighbors = n_neighbor)\n",
    "    \n",
    "    y_pred = lof.fit_predict(df)\n",
    "    X_scores = lof.negative_outlier_factor_\n",
    "\n",
    "    df[\"lof\"]=X_scores\n",
    "    population_with_lof = population.copy()\n",
    "    population_with_lof[\"lof\"] = X_scores[size:]\n",
    "\n",
    "    population_with_lof = population_with_lof.sort_values(by = ['lof'], ignore_index=True)\n",
    "    population_with_lof = population_with_lof.drop(columns=['lof'])\n",
    "\n",
    "    sizeof_block = int(len(population_with_lof.index)/n_blocks)\n",
    "    i = 0 \n",
    "    j = int(0)\n",
    "    result = []\n",
    "    \n",
    "    while(i < n_blocks):\n",
    "        k = int(j+ sizeof_block)\n",
    "        p = population_with_lof.iloc[j:k]\n",
    "        result.append(p)\n",
    "        #result.append(population[j:k])\n",
    "        j+=sizeof_block\n",
    "        i+=1\n",
    "    \n",
    "\n",
    "    return result\n",
    "\n",
    "def get_best_population(df, original_features, original_labels, antibody_population, previous_result, label, model, K_folds, scorer):\n",
    "    \n",
    "    result = lof(df, antibody_population)\n",
    "    \n",
    "    \n",
    "    p1 = pd.concat([result[0],result[1],result[2],previous_result[3]],ignore_index=True)\n",
    "    p1_features, p1_labels = separate_df(p1, label_col=label)\n",
    "    p1_score = fitnessCV(model, original_features, original_labels, p1_features, p1_labels, scorer, K_folds)\n",
    "\n",
    "    p2 = pd.concat([result[0],previous_result[1],result[2],result[3]],ignore_index=True)\n",
    "    p2_features, p2_labels = separate_df(p2, label_col=label)\n",
    "    p2_score = fitnessCV(model, original_features, original_labels, p2_features, p2_labels, scorer, K_folds)\n",
    "\n",
    "    p3 = pd.concat([result[0],result[1],previous_result[2],result[3]],ignore_index=True)\n",
    "    p3_features, p3_labels = separate_df(p3, label_col=label)\n",
    "    p3_score = fitnessCV(model, original_features, original_labels, p3_features, p3_labels, scorer, K_folds)\n",
    "\n",
    "    p4 = pd.concat([previous_result[0],result[1],result[2],result[3]],ignore_index=True)\n",
    "    p4_features, p4_labels = separate_df(p4, label_col=label)\n",
    "    p4_score = fitnessCV(model, original_features, original_labels, p4_features, p4_labels, scorer, K_folds)\n",
    "\n",
    "    scores = [p1_score,p2_score,p3_score,p4_score]\n",
    "    max_score = max(scores)\n",
    "\n",
    "    if(max_score == p1_score):\n",
    "        return p1, p1_score\n",
    "        \n",
    "    if(max_score == p2_score):\n",
    "        return p2, p2_score\n",
    "\n",
    "    if(max_score == p3_score):\n",
    "        return p3, p3_score\n",
    "    \n",
    "    if(max_score == p4_score):\n",
    "        return p4, p4_score\n",
    "\n",
    "def comparePopulations_lof( population_score, old_score, min_change):\n",
    "    print(\"old_score: \" +str(old_score))\n",
    "    print(\"population_score: \" +str(population_score))\n",
    "    if abs(population_score - old_score) < min_change:\n",
    "        return False, old_score\n",
    "    elif (old_score > population_score):\n",
    "        return False, old_score\n",
    "    else:\n",
    "        return True, population_score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#minorityDF      - the minority dataframe\n",
    "#df              - the original dataframe\n",
    "#max_rounds      - the maximum number of rounds(loops) of AIS \n",
    "#stopping_cond   - the number of rounds without significant changes to accuracy before stopping the function\n",
    "#totalPopulation - the number of elements we want to add to the minority class\n",
    "#model           - the model to be used to evaluate the dataset during AIS\n",
    "#K-folds         - the number of segments for k-fold cross validation\n",
    "#scorer          - the scoring metric when evaluating the dataset\n",
    "\n",
    "def AIS(minorityDF,df, label, max_rounds, stopping_cond, totalPopulation, model, K_folds, scorer,  min_change = 0.05, use_lof : bool = True):\n",
    "\n",
    "        #add code to find binary columns for creation\n",
    "        binaryColumns = getBinaryColumns(minorityDF)\n",
    "\n",
    "        current_population, bounds = Creation(minorityDF,totalPopulation,binaryColumns, weightingFunction='uniform')\n",
    "        \n",
    "        antibody_population = mutatePopulation(current_population,bounds,binaryColumns)\n",
    "        \n",
    "        count = 0\n",
    "        no_change = 0\n",
    "\n",
    "        original_gen, original_labels = separate_df(df, label)\n",
    "        #created population split into features and labels\n",
    "        current_gen, current_labels = separate_df(current_population, label_col=label)\n",
    "\n",
    "        \n",
    "        current_score = fitnessCV(model, original_gen, original_labels, current_gen, current_labels, scorer, K_folds)\n",
    "\n",
    "        # #the next generation antibody population concatenated to the original dataframe\n",
    "        # next_df = pd.concat([df,antibody_population],ignore_index=True) #TODO:REMOVE\n",
    "        #next_df split into features and labels\n",
    "        next_gen, next_labels = separate_df(antibody_population, label_col=label)\n",
    "\n",
    "        if(use_lof==False):\n",
    "            while( (count < max_rounds) and (no_change < stopping_cond) ):\n",
    "                count+=1\n",
    "         \n",
    "                change_flg, score = comparePopulationsCV(current_score, original_gen, original_labels, next_gen, next_labels, model, K_folds, scorer, min_change)\n",
    "                if (change_flg):\n",
    "                    \n",
    "                    no_change = 0\n",
    "\n",
    "                    current_population = antibody_population.copy()\n",
    "\n",
    "                    #need to update bounds\n",
    "                    bounds = get_bounds(current_population)\n",
    "                    antibody_population = mutatePopulation(current_population,bounds,['5'])\n",
    "                    next_gen, next_labels = separate_df(antibody_population, label_col=label)\n",
    "                    \n",
    "                else:\n",
    "                 \n",
    "                    no_change+=1\n",
    "\n",
    "                    bounds = get_bounds(current_population)\n",
    "                    antibody_population = mutatePopulation(current_population,bounds,['5'])\n",
    "                    next_gen, next_labels = separate_df(antibody_population, label_col=label)\n",
    "                    \n",
    "                current_score = score #Score will only change if the new population is better than the old population\n",
    "        \n",
    "        else:\n",
    "            current_population_lof = lof(df, current_population)\n",
    "            while( (count < max_rounds) and (no_change < stopping_cond) ):\n",
    "\n",
    "                count+=1\n",
    "                \n",
    "                best_population, best_population_score = get_best_population(df, original_gen, original_labels, antibody_population, current_population_lof, label, model, K_folds, scorer)\n",
    "                \n",
    "                change_flg, score = comparePopulations_lof(best_population_score, current_score, min_change)\n",
    "                if (change_flg):\n",
    "\n",
    "                    no_change = 0\n",
    "\n",
    "                    current_population = best_population.copy()\n",
    "                    current_population_lof = lof(df, current_population)\n",
    "\n",
    "                    #need to update bounds\n",
    "                    bounds = get_bounds(current_population)\n",
    "                    antibody_population = mutatePopulation(current_population,bounds,['5'])\n",
    "                    \n",
    "                    \n",
    "                else:\n",
    "\n",
    "                    no_change+=1\n",
    "\n",
    "                    bounds = get_bounds(current_population)\n",
    "                    \n",
    "                    antibody_population = mutatePopulation(current_population,bounds,['5'])\n",
    "                    \n",
    "                current_score = score #Score will only change if the new population is better than the old population\n",
    "\n",
    "        return current_population, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AIS_Resample( preparedDF, labels, max_rounds, stopping_cond, model, K_folds, scorer):\n",
    "        #preparedDF is the dataframe of features, labels is the dataframe of labels\n",
    "        minorityDF = extractBinaryMinorityClass(preparedDF, labels)\n",
    "        \n",
    "        #PreparedDF + Labels = the overall Population\n",
    "        overallPopulation = pd.concat([preparedDF,labels],axis=1)\n",
    "        #The number of elements we want to add to the minority class\n",
    "        requiredPopulation = len(overallPopulation) - (len(minorityDF)*2)\n",
    "        \n",
    "        oversamples,_ = AIS(minorityDF,overallPopulation,labels.columns, max_rounds,stopping_cond,requiredPopulation,model,K_folds,scorer)\n",
    "        concatDF = pd.concat([overallPopulation,oversamples],ignore_index=True)\n",
    "        return (separate_df(concatDF, labels.columns[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "population_score: 0.8731698923035717\n",
      "old_score: 0.7979061333456109\n",
      "population_score: 0.875709898806452\n",
      "old_score: 0.8731698923035717\n",
      "population_score: 0.8709319439668833\n",
      "old_score: 0.8731698923035717\n",
      "population_score: 0.8699401627707586\n",
      "old_score: 0.8731698923035717\n",
      "population_score: 0.868927213404862\n",
      "old_score: 0.8731698923035717\n",
      "population_score: 0.9147254902378308\n",
      "old_score: 0.8731698923035717\n",
      "population_score: 0.8869767415245905\n",
      "old_score: 0.8731698923035717\n",
      "population_score: 0.8650425144779497\n",
      "old_score: 0.8731698923035717\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/nikhil/Documents/GitHub/Artificial-Immune-System-For-Class-Imbalance/AIS.ipynb Cell 20\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nikhil/Documents/GitHub/Artificial-Immune-System-For-Class-Imbalance/AIS.ipynb#X24sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m randomForest \u001b[39m=\u001b[39m RandomForestClassifier()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nikhil/Documents/GitHub/Artificial-Immune-System-For-Class-Imbalance/AIS.ipynb#X24sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m \u001b[39m# AIS_Resample(data, labels, 20, 5, randomForest, 5, 'f1')\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/nikhil/Documents/GitHub/Artificial-Immune-System-For-Class-Imbalance/AIS.ipynb#X24sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m x \u001b[39m=\u001b[39m AIS_Resample(data, labels, \u001b[39m20\u001b[39;49m, \u001b[39m10\u001b[39;49m, randomForest, \u001b[39m5\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mf1\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "\u001b[1;32m/Users/nikhil/Documents/GitHub/Artificial-Immune-System-For-Class-Imbalance/AIS.ipynb Cell 20\u001b[0m in \u001b[0;36mAIS_Resample\u001b[0;34m(preparedDF, labels, max_rounds, stopping_cond, model, K_folds, scorer)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nikhil/Documents/GitHub/Artificial-Immune-System-For-Class-Imbalance/AIS.ipynb#X24sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m#The number of elements we want to add to the minority class\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nikhil/Documents/GitHub/Artificial-Immune-System-For-Class-Imbalance/AIS.ipynb#X24sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m requiredPopulation \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(overallPopulation) \u001b[39m-\u001b[39m (\u001b[39mlen\u001b[39m(minorityDF)\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/nikhil/Documents/GitHub/Artificial-Immune-System-For-Class-Imbalance/AIS.ipynb#X24sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m oversamples,_ \u001b[39m=\u001b[39m AIS(minorityDF,overallPopulation,labels\u001b[39m.\u001b[39;49mcolumns, max_rounds,stopping_cond,requiredPopulation,model,K_folds,scorer)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nikhil/Documents/GitHub/Artificial-Immune-System-For-Class-Imbalance/AIS.ipynb#X24sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m concatDF \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([overallPopulation,oversamples],ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nikhil/Documents/GitHub/Artificial-Immune-System-For-Class-Imbalance/AIS.ipynb#X24sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mreturn\u001b[39;00m (separate_df(concatDF, labels\u001b[39m.\u001b[39mcolumns[\u001b[39m0\u001b[39m]))\n",
      "\u001b[1;32m/Users/nikhil/Documents/GitHub/Artificial-Immune-System-For-Class-Imbalance/AIS.ipynb Cell 20\u001b[0m in \u001b[0;36mAIS\u001b[0;34m(minorityDF, df, label, max_rounds, stopping_cond, totalPopulation, model, K_folds, scorer, min_change, use_lof)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nikhil/Documents/GitHub/Artificial-Immune-System-For-Class-Imbalance/AIS.ipynb#X24sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m \u001b[39mwhile\u001b[39;00m( (count \u001b[39m<\u001b[39m max_rounds) \u001b[39mand\u001b[39;00m (no_change \u001b[39m<\u001b[39m stopping_cond) ):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nikhil/Documents/GitHub/Artificial-Immune-System-For-Class-Imbalance/AIS.ipynb#X24sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m     count\u001b[39m+\u001b[39m\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/nikhil/Documents/GitHub/Artificial-Immune-System-For-Class-Imbalance/AIS.ipynb#X24sZmlsZQ%3D%3D?line=67'>68</a>\u001b[0m     best_population, best_population_score \u001b[39m=\u001b[39m get_best_population(df, original_gen, original_labels, antibody_population, current_population_lof, label, model, K_folds, scorer)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nikhil/Documents/GitHub/Artificial-Immune-System-For-Class-Imbalance/AIS.ipynb#X24sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m     change_flg, score \u001b[39m=\u001b[39m comparePopulations_lof(best_population_score, current_score, min_change)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nikhil/Documents/GitHub/Artificial-Immune-System-For-Class-Imbalance/AIS.ipynb#X24sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m     \u001b[39mif\u001b[39;00m (change_flg):\n",
      "\u001b[1;32m/Users/nikhil/Documents/GitHub/Artificial-Immune-System-For-Class-Imbalance/AIS.ipynb Cell 20\u001b[0m in \u001b[0;36mget_best_population\u001b[0;34m(df, original_features, original_labels, antibody_population, previous_result, label, model, K_folds, scorer)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nikhil/Documents/GitHub/Artificial-Immune-System-For-Class-Imbalance/AIS.ipynb#X24sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m p2 \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([result[\u001b[39m0\u001b[39m],previous_result[\u001b[39m1\u001b[39m],result[\u001b[39m2\u001b[39m],result[\u001b[39m3\u001b[39m]],ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nikhil/Documents/GitHub/Artificial-Immune-System-For-Class-Imbalance/AIS.ipynb#X24sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m p2_features, p2_labels \u001b[39m=\u001b[39m separate_df(p2, label_col\u001b[39m=\u001b[39mlabel)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/nikhil/Documents/GitHub/Artificial-Immune-System-For-Class-Imbalance/AIS.ipynb#X24sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m p2_score \u001b[39m=\u001b[39m fitnessCV(model, original_features, original_labels, p2_features, p2_labels, scorer, K_folds)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nikhil/Documents/GitHub/Artificial-Immune-System-For-Class-Imbalance/AIS.ipynb#X24sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m p3 \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([result[\u001b[39m0\u001b[39m],result[\u001b[39m1\u001b[39m],previous_result[\u001b[39m2\u001b[39m],result[\u001b[39m3\u001b[39m]],ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nikhil/Documents/GitHub/Artificial-Immune-System-For-Class-Imbalance/AIS.ipynb#X24sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m p3_features, p3_labels \u001b[39m=\u001b[39m separate_df(p3, label_col\u001b[39m=\u001b[39mlabel)\n",
      "\u001b[1;32m/Users/nikhil/Documents/GitHub/Artificial-Immune-System-For-Class-Imbalance/AIS.ipynb Cell 20\u001b[0m in \u001b[0;36mfitnessCV\u001b[0;34m(model, original_features, original_labels, population_features, population_labels, scorer, iterations)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nikhil/Documents/GitHub/Artificial-Immune-System-For-Class-Imbalance/AIS.ipynb#X24sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m count \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nikhil/Documents/GitHub/Artificial-Immune-System-For-Class-Imbalance/AIS.ipynb#X24sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m \u001b[39mfor\u001b[39;00m estimator \u001b[39min\u001b[39;00m cval_scores[\u001b[39m'\u001b[39m\u001b[39mestimator\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/nikhil/Documents/GitHub/Artificial-Immune-System-For-Class-Imbalance/AIS.ipynb#X24sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m     estimator\u001b[39m.\u001b[39;49mfit(train_features, train_labels\u001b[39m.\u001b[39;49mvalues\u001b[39m.\u001b[39;49mravel())\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nikhil/Documents/GitHub/Artificial-Immune-System-For-Class-Imbalance/AIS.ipynb#X24sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m     predictions \u001b[39m=\u001b[39m estimator\u001b[39m.\u001b[39mpredict(origin_feat_test)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nikhil/Documents/GitHub/Artificial-Immune-System-For-Class-Imbalance/AIS.ipynb#X24sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m     \u001b[39m#hard coded f1_score, find a way to pass in function for scoring?\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:450\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    439\u001b[0m trees \u001b[39m=\u001b[39m [\n\u001b[1;32m    440\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(append\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[1;32m    441\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_more_estimators)\n\u001b[1;32m    442\u001b[0m ]\n\u001b[1;32m    444\u001b[0m \u001b[39m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[1;32m    445\u001b[0m \u001b[39m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \u001b[39m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[1;32m    447\u001b[0m \u001b[39m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[1;32m    448\u001b[0m \u001b[39m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[1;32m    449\u001b[0m \u001b[39m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[0;32m--> 450\u001b[0m trees \u001b[39m=\u001b[39m Parallel(\n\u001b[1;32m    451\u001b[0m     n_jobs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mn_jobs,\n\u001b[1;32m    452\u001b[0m     verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    453\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m_joblib_parallel_args(prefer\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mthreads\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    454\u001b[0m )(\n\u001b[1;32m    455\u001b[0m     delayed(_parallel_build_trees)(\n\u001b[1;32m    456\u001b[0m         t,\n\u001b[1;32m    457\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[1;32m    458\u001b[0m         X,\n\u001b[1;32m    459\u001b[0m         y,\n\u001b[1;32m    460\u001b[0m         sample_weight,\n\u001b[1;32m    461\u001b[0m         i,\n\u001b[1;32m    462\u001b[0m         \u001b[39mlen\u001b[39;49m(trees),\n\u001b[1;32m    463\u001b[0m         verbose\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mverbose,\n\u001b[1;32m    464\u001b[0m         class_weight\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclass_weight,\n\u001b[1;32m    465\u001b[0m         n_samples_bootstrap\u001b[39m=\u001b[39;49mn_samples_bootstrap,\n\u001b[1;32m    466\u001b[0m     )\n\u001b[1;32m    467\u001b[0m     \u001b[39mfor\u001b[39;49;00m i, t \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(trees)\n\u001b[1;32m    468\u001b[0m )\n\u001b[1;32m    470\u001b[0m \u001b[39m# Collect newly grown trees\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimators_\u001b[39m.\u001b[39mextend(trees)\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/joblib/parallel.py:1046\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1044\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1046\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1047\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1050\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1051\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1052\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/joblib/parallel.py:861\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    860\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 861\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    862\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/joblib/parallel.py:779\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    778\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 779\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    780\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    781\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    782\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py:572\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    570\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 572\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/joblib/parallel.py:262\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    259\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    261\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 262\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    263\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py:216\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    215\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[0;32m--> 216\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:172\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    170\u001b[0m     curr_sample_weight \u001b[39m=\u001b[39m sample_weight\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m--> 172\u001b[0m indices \u001b[39m=\u001b[39m _generate_sample_indices(\n\u001b[1;32m    173\u001b[0m     tree\u001b[39m.\u001b[39;49mrandom_state, n_samples, n_samples_bootstrap\n\u001b[1;32m    174\u001b[0m )\n\u001b[1;32m    175\u001b[0m sample_counts \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mbincount(indices, minlength\u001b[39m=\u001b[39mn_samples)\n\u001b[1;32m    176\u001b[0m curr_sample_weight \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m sample_counts\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:128\u001b[0m, in \u001b[0;36m_generate_sample_indices\u001b[0;34m(random_state, n_samples, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_generate_sample_indices\u001b[39m(random_state, n_samples, n_samples_bootstrap):\n\u001b[1;32m    125\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \u001b[39m    Private function used to _parallel_build_trees function.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 128\u001b[0m     random_instance \u001b[39m=\u001b[39m check_random_state(random_state)\n\u001b[1;32m    129\u001b[0m     sample_indices \u001b[39m=\u001b[39m random_instance\u001b[39m.\u001b[39mrandint(\u001b[39m0\u001b[39m, n_samples, n_samples_bootstrap)\n\u001b[1;32m    131\u001b[0m     \u001b[39mreturn\u001b[39;00m sample_indices\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/sklearn/utils/validation.py:1057\u001b[0m, in \u001b[0;36mcheck_random_state\u001b[0;34m(seed)\u001b[0m\n\u001b[1;32m   1055\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mmtrand\u001b[39m.\u001b[39m_rand\n\u001b[1;32m   1056\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(seed, numbers\u001b[39m.\u001b[39mIntegral):\n\u001b[0;32m-> 1057\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49mrandom\u001b[39m.\u001b[39;49mRandomState(seed)\n\u001b[1;32m   1058\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(seed, np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mRandomState):\n\u001b[1;32m   1059\u001b[0m     \u001b[39mreturn\u001b[39;00m seed\n",
      "File \u001b[0;32mmtrand.pyx:184\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_mt19937.pyx:130\u001b[0m, in \u001b[0;36mnumpy.random._mt19937.MT19937.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/contextlib.py:79\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[1;32m     77\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minner\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds):\n\u001b[1;32m     78\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 79\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#TEST BLOCK \n",
    "\n",
    "#not imbalanced\n",
    "#df= pd.read_csv(\"./Data/GeneratedSyntheticData-NosiyEasy.csv\",index_col=0)\n",
    "\n",
    "#Gets a perfect score always\n",
    "#df= pd.read_csv(\"./Data/GeneratedSyntheticData-NosieLessInformativeEasy.csv\") \n",
    "\n",
    "#Gets a perfect score after a few iterations\n",
    "df = pd.read_csv(\"./Data/GeneratedSyntheticData-NosieLessInformativeHard.csv\",index_col=0)\n",
    "df.dropna()\n",
    "\n",
    "#not imbalanced\n",
    "#df = pd.read_csv(\"./Data/GeneratedSyntheticData-NosiyHard.csv\",index_col=0)\n",
    "\n",
    "minority = df[df['5']==1] \n",
    "majority = df[df['5']==0]\n",
    "\n",
    "data, labels = separate_df(df, '5')\n",
    "# initial_population, bounds = Creation(minority,120,['5'], weightingFunction='uniform')\n",
    "\n",
    "# antibody_population = mutatePopulation(initial_population,bounds,['5'],1.0)\n",
    "\n",
    "# current_df = pd.concat([df,initial_population],ignore_index=True)\n",
    "# current_gen, current_labels = separate_df(current_df, '5')\n",
    "\n",
    "\n",
    "# next_df = pd.concat([df,antibody_population],ignore_index=True)\n",
    "# next_gen, next_labels = separate_df(next_df, '5')\n",
    "\n",
    "randomForest = RandomForestClassifier()\n",
    "\n",
    "# AIS_Resample(data, labels, 20, 5, randomForest, 5, 'f1')\n",
    "\n",
    "x = AIS_Resample(data, labels, 20, 10, randomForest, 5, 'f1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing datasets with no oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "separate_df() missing 1 required positional argument: 'label_col'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/nikhil/Documents/GitHub/Artificial-Immune-System-For-Class-Imbalance/AIS.ipynb Cell 21\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nikhil/Documents/GitHub/Artificial-Immune-System-For-Class-Imbalance/AIS.ipynb#X26sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m minority \u001b[39m=\u001b[39m df[df[\u001b[39m'\u001b[39m\u001b[39m5\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m==\u001b[39m\u001b[39m1\u001b[39m] \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nikhil/Documents/GitHub/Artificial-Immune-System-For-Class-Imbalance/AIS.ipynb#X26sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m majority \u001b[39m=\u001b[39m df[df[\u001b[39m'\u001b[39m\u001b[39m5\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m==\u001b[39m\u001b[39m0\u001b[39m]\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/nikhil/Documents/GitHub/Artificial-Immune-System-For-Class-Imbalance/AIS.ipynb#X26sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m joe, mama \u001b[39m=\u001b[39m separate_df(df)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nikhil/Documents/GitHub/Artificial-Immune-System-For-Class-Imbalance/AIS.ipynb#X26sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m score1 \u001b[39m=\u001b[39m fitness(randomForest, joe, mama\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mravel(), \u001b[39m5\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mf1_macro\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nikhil/Documents/GitHub/Artificial-Immune-System-For-Class-Imbalance/AIS.ipynb#X26sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m score1\n",
      "\u001b[0;31mTypeError\u001b[0m: separate_df() missing 1 required positional argument: 'label_col'"
     ]
    }
   ],
   "source": [
    "#df = pd.read_csv(\"./Data/GeneratedSyntheticData-NosiyHard.csv\",index_col=0)\n",
    "df= pd.read_csv(\"./Data/GeneratedSyntheticData-NosieLessInformativeHard.csv\") \n",
    "\n",
    "minority = df[df['5']==1] \n",
    "majority = df[df['5']==0]\n",
    "\n",
    "joe, mama = separate_df(df)\n",
    "score1 = fitness(randomForest, joe, mama.values.ravel(), 5, 'f1_macro')\n",
    "score1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing new fitness functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "separate_df() missing 1 required positional argument: 'label_col'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/nikhil/Documents/GitHub/Artificial-Immune-System-For-Class-Imbalance/AIS.ipynb Cell 23\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/nikhil/Documents/GitHub/Artificial-Immune-System-For-Class-Imbalance/AIS.ipynb#X31sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m initial_population, bounds \u001b[39m=\u001b[39m Creation(minority,\u001b[39m120\u001b[39m,[\u001b[39m'\u001b[39m\u001b[39m5\u001b[39m\u001b[39m'\u001b[39m], weightingFunction\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39muniform\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nikhil/Documents/GitHub/Artificial-Immune-System-For-Class-Imbalance/AIS.ipynb#X31sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m antibody_population \u001b[39m=\u001b[39m mutatePopulation(initial_population,bounds,[\u001b[39m'\u001b[39m\u001b[39m5\u001b[39m\u001b[39m'\u001b[39m],\u001b[39m1.0\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/nikhil/Documents/GitHub/Artificial-Immune-System-For-Class-Imbalance/AIS.ipynb#X31sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m current_gen, current_labels \u001b[39m=\u001b[39m separate_df(initial_population)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nikhil/Documents/GitHub/Artificial-Immune-System-For-Class-Imbalance/AIS.ipynb#X31sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m next_gen, next_labels \u001b[39m=\u001b[39m separate_df(antibody_population)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nikhil/Documents/GitHub/Artificial-Immune-System-For-Class-Imbalance/AIS.ipynb#X31sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m original_feat, original_label \u001b[39m=\u001b[39m separate_df(df)\n",
      "\u001b[0;31mTypeError\u001b[0m: separate_df() missing 1 required positional argument: 'label_col'"
     ]
    }
   ],
   "source": [
    "df= pd.read_csv(\"./Data/GeneratedSyntheticData-NosieLessInformativeHard.csv\",index_col=0)\n",
    "\n",
    "randomForest = RandomForestClassifier()\n",
    "\n",
    "minority = df[df['5']==1] \n",
    "majority = df[df['5']==0]\n",
    "\n",
    "\n",
    "initial_population, bounds = Creation(minority,120,['5'], weightingFunction='uniform')\n",
    "\n",
    "antibody_population = mutatePopulation(initial_population,bounds,['5'],1.0)\n",
    "\n",
    "\n",
    "current_gen, current_labels = separate_df(initial_population)\n",
    "\n",
    "next_gen, next_labels = separate_df(antibody_population)\n",
    "\n",
    "original_feat, original_label = separate_df(df)\n",
    "\n",
    "\n",
    "\n",
    "#x = fitness2(randomForest, original_feat, original_label, next_gen, next_labels, \"not_implemented_yet\")\n",
    "\n",
    "scores = fitnessCV(randomForest, original_feat, original_label, next_gen, next_labels, 'f1', 5)\n",
    "scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying out LOF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "separate_df() missing 1 required positional argument: 'label_col'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/nikhil/Documents/GitHub/Artificial-Immune-System-For-Class-Imbalance/AIS.ipynb Cell 25\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nikhil/Documents/GitHub/Artificial-Immune-System-For-Class-Imbalance/AIS.ipynb#X33sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m antibody_population \u001b[39m=\u001b[39m mutatePopulation(initial_population,bounds,[\u001b[39m'\u001b[39m\u001b[39m5\u001b[39m\u001b[39m'\u001b[39m],\u001b[39m1.0\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nikhil/Documents/GitHub/Artificial-Immune-System-For-Class-Imbalance/AIS.ipynb#X33sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m current_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([df,initial_population],ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/nikhil/Documents/GitHub/Artificial-Immune-System-For-Class-Imbalance/AIS.ipynb#X33sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m current_gen, current_labels \u001b[39m=\u001b[39m separate_df(current_df)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nikhil/Documents/GitHub/Artificial-Immune-System-For-Class-Imbalance/AIS.ipynb#X33sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m next_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat([df,antibody_population],ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nikhil/Documents/GitHub/Artificial-Immune-System-For-Class-Imbalance/AIS.ipynb#X33sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m next_gen, next_labels \u001b[39m=\u001b[39m separate_df(next_df)\n",
      "\u001b[0;31mTypeError\u001b[0m: separate_df() missing 1 required positional argument: 'label_col'"
     ]
    }
   ],
   "source": [
    "df= pd.read_csv(\"./Data/GeneratedSyntheticData-NosieLessInformativeHard.csv\",index_col=0) \n",
    "\n",
    "size = len(df.index)\n",
    "minority = df[df['5']==1] \n",
    "majority = df[df['5']==0]\n",
    "\n",
    "\n",
    "initial_population, bounds = Creation(minority,120,['5'], weightingFunction='uniform')\n",
    "\n",
    "antibody_population = mutatePopulation(initial_population,bounds,['5'],1.0)\n",
    "\n",
    "current_df = pd.concat([df,initial_population],ignore_index=True)\n",
    "current_gen, current_labels = separate_df(current_df)\n",
    "\n",
    "\n",
    "next_df = pd.concat([df,antibody_population],ignore_index=True)\n",
    "next_gen, next_labels = separate_df(next_df)\n",
    "\n",
    "clf = LocalOutlierFactor(n_neighbors=20)\n",
    "\n",
    "y_pred = clf.fit_predict(next_df)\n",
    "#n_errors = (y_pred != ground_truth).sum()\n",
    "X_scores = clf.negative_outlier_factor_\n",
    "\n",
    "outliers = (X_scores < -2).sum()\n",
    "outliers\n",
    "next_df[\"lof\"]=X_scores\n",
    "\n",
    "#use size of original df\n",
    "\n",
    "antibody_population[\"lof\"] = X_scores[size:]\n",
    "#print(antibody_population)\n",
    "#print(next_df[300:])\n",
    "#sorted_df = next_df.sort_values(by = ['lof'], ignore_index=True)\n",
    "#sorted_df\n",
    "sorted_pop = antibody_population.sort_values(by = ['lof'], ignore_index=True)\n",
    "sorted_pop\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST LOF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(          0       1       2       3       4  5\n",
       " 0   -0.8432 -3.5282 -0.0501  2.5187 -0.5025  1\n",
       " 1    1.2280  2.2951  3.2678 -3.2986  0.8151  1\n",
       " 2    1.7260 -2.4066  3.8643 -3.2133  1.7390  1\n",
       " 3    1.4017 -0.2919  4.6156 -2.6526 -0.3847  1\n",
       " 4    0.4966 -1.4200  1.1175  2.0849  0.1040  1\n",
       " ..      ...     ...     ...     ...     ... ..\n",
       " 115 -3.2798  0.7419  2.7816  0.9615  1.1917  1\n",
       " 116 -2.3698  1.6707  0.8360  1.0882  1.1563  1\n",
       " 117 -3.2923 -0.9204  2.7438  0.7083  0.7086  1\n",
       " 118 -1.0064 -0.4529  1.5155 -3.1937  1.4584  1\n",
       " 119 -3.0842 -0.1180  0.2250 -1.6448  1.1125  1\n",
       " \n",
       " [120 rows x 6 columns],\n",
       " 0.8754321352496983)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv(\"./Data/GeneratedSyntheticData-NosieLessInformativeHard.csv\",index_col=0) \n",
    "\n",
    "size = len(df.index)\n",
    "minority = df[df['5']==1] \n",
    "majority = df[df['5']==0]\n",
    "\n",
    "initial_population, bounds = Creation(minority,120,['5'], weightingFunction='uniform')\n",
    "\n",
    "antibody_population = mutatePopulation(initial_population,bounds,['5'],1.0)\n",
    "\n",
    "current_df = pd.concat([df,initial_population],ignore_index=True)\n",
    "current_gen, current_labels = separate_df(current_df,'5')\n",
    "\n",
    "next_df = pd.concat([df,antibody_population],ignore_index=True)\n",
    "next_gen, next_labels = separate_df(next_df,'5')\n",
    "\n",
    "original_gen, original_labels = separate_df(df,'5')\n",
    "\n",
    "previous = lof(df, initial_population)\n",
    "randomForest = RandomForestClassifier()\n",
    "rizz = get_best_population(df, original_gen, original_labels, antibody_population, previous, original_labels.columns, randomForest, 5, 'f1' )\n",
    "rizz\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6bb1f13dc7b0d3bf69b993e5cf5bb75fcd3ebfcdc503afb75b077e5881bff171"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
